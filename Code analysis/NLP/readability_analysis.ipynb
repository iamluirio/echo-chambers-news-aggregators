{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the “Readability” of a text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readability metrics have numerous uses. A writer might use the metrics to objectively assess the complexity of his work to determine whether it’s written at a level appropriate for his intended audience. An educational software firm might use readability metrics to recommend level-appropriate content for its students."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, I work on the latter. As a result, I’ve written a Python package, py-readability-metrics that assesses the readability of a given text, using a variety of today’s most popular readability metrics. These include:\n",
    "\n",
    "- Flesch Kincaid Grade Level\n",
    "\n",
    "- Flesch Reading Ease\n",
    "\n",
    "- Dale Chall Readability\n",
    "\n",
    "- Automated Readability Index (ARI)\n",
    "\n",
    "- Coleman Liau Index\n",
    "\n",
    "- Gunning Fog\n",
    "\n",
    "- SMOG\n",
    "\n",
    "- Linear Write\n",
    "\n",
    "Given a text, each of the above metrics calculate a score indicating the difficulty of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from readability import Readability\n",
    "import spacy\n",
    "import newspaper\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.foxnews.com/politics/republicans-respond-after-irs-whistleblower-says-hunter-biden-investigation-being-mishandled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(url):\n",
    "    # Create a newspaper Article object\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    # Download and parse the article\n",
    "    article.download()\n",
    "    article.parse()\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title = article.title.strip()\n",
    "    subtitle = article.meta_data.get(\"description\", \"\").strip()\n",
    "    description = article.meta_description.strip()\n",
    "    text = article.text.strip()\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{text}\"\n",
    "\n",
    "    # Return the concatenated string\n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = get_article_info(url)\n",
    "\n",
    "r = Readability(article)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flesch Kincaid Grade Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Army uses Flesch-Kincaid Grade Level for assessing the difficulty of technical manuals. The commonwealth of Pennsylvania uses Flesch-Kincaid Grade Level for scoring automobile insurance policies to ensure their texts are no higher than a ninth grade level of reading difficulty. Many other U.S. states also use Flesch-Kincaid Grade Level to score other legal documents such as business policies and financial forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.15103125495796\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "fk = r.flesch_kincaid()\n",
    "\n",
    "print(fk.score)\n",
    "print(fk.grade_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flesch Reading Ease"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Department of Defense uses the Reading Ease test as the standard test of readability for its documents and forms. Florida requires that life insurance policies have a Flesch Reading Ease score of 45 or greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.18228541964146\n",
      "difficult\n",
      "['college']\n"
     ]
    }
   ],
   "source": [
    "f = r.flesch()\n",
    "print(f.score)\n",
    "print(f.ease)\n",
    "print(f.grade_levels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dale Chall Readability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dale-Chall Formula is an accurate readability formula for the simple reason that it is based on the use of familiar words, rather than syllable or letter counts. Reading tests show that readers usually find it easier to read, process and recall a passage if they find the words familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.398427716960178\n",
      "['college_graduate']\n"
     ]
    }
   ],
   "source": [
    "dc = r.dale_chall()\n",
    "print(dc.score)\n",
    "print(dc.grade_levels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Readability Index (ARI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the other indices, the ARI, along with the Coleman-Liau, relies on a factor of characters per word, instead of the usual syllables per word. ARI is widely used on all types of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.76357171188323\n",
      "['college_graduate']\n",
      "[24, 100]\n"
     ]
    }
   ],
   "source": [
    "ari = r.ari()\n",
    "print(ari.score)\n",
    "print(ari.grade_levels)\n",
    "print(ari.ages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleman Liau Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coleman-Liau Formula usually gives a lower grade value than any of the Kincaid, ARI and Flesch values when applied to technical documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.40612565445026\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "cl = r.coleman_liau()\n",
    "print(cl.score)\n",
    "print(cl.grade_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gunning Fog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gunning fog index measures the readability of English writing. The index estimates the years of formal education needed to understand the text on a first reading. A fog index of 12 requires the reading level of a U.S. high school senior (around 18 years old)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.229192448040616\n",
      "college\n"
     ]
    }
   ],
   "source": [
    "gf = r.gunning_fog()\n",
    "print(gf.score)\n",
    "print(gf.grade_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOG Readability Formula (Simple Measure of Gobbledygook) is a popular method to use on health literacy materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.774802946060372\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "s = r.smog()\n",
    "print(s.score)\n",
    "print(s.grade_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPACHE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spache Readability Formula is used for Primary-Grade Reading Materials, published in 1953 in The Elementary School Journal. The Spache Formula is best used to calculate the difficulty of text that falls at the 3rd grade level or below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.425876725368871\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "s = r.spache()\n",
    "print(s.score)\n",
    "print(s.grade_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linsear Write"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linsear Write is a readability metric for English text, purportedly developed for the United States Air Force to help them calculate the readability of their technical manuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.636363636363637\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "lw = r.linsear_write()\n",
    "print(lw.score)\n",
    "print(lw.grade_level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

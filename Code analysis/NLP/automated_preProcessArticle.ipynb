{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65916b8a9900421ea07b0f20c262475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 17:09:02 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-04-21 17:09:03 INFO: File exists: /home/pierluigi/stanza_resources/en/default.zip\n",
      "2023-04-21 17:09:09 INFO: Finished downloading models and saved to /home/pierluigi/stanza_resources.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')  # Download the English model\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import newspaper\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 17:09:09 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ece5676e974fdab9458da01b88faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 17:09:10 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-04-21 17:09:10 INFO: Using device: cuda\n",
      "2023-04-21 17:09:10 INFO: Loading: tokenize\n",
      "2023-04-21 17:09:12 INFO: Loading: sentiment\n",
      "2023-04-21 17:09:13 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=False, max_split_size_mb=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MPQA lexicon\n",
    "lexicon = pd.read_csv(\"subjclueslen1-HLTEMNLP05.tff\", sep=\" \", header=None, \n",
    "                      names=[\"type\", \"len\", \"word\", \"pos\", \"stemmed\", \"polarity\", \"strength\"])\n",
    "\n",
    "lexicon[\"type\"] = lexicon[\"type\"].str[5:]\n",
    "lexicon[\"word\"] = lexicon[\"word\"].str[len(\"word1=\"):]\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].str[len(\"priorpolarity=\"):]\n",
    "cols_to_remove = [\"len\", \"pos\", \"stemmed\", \"strength\"]\n",
    "lexicon = lexicon.drop(columns=cols_to_remove)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"weaksubj\", 1)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"strongsubj\", 2)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"negative\", -1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"positive\", 1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"both\", 0)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"neutral\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.foxnews.com/politics/republicans-respond-after-irs-whistleblower-says-hunter-biden-investigation-being-mishandled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article(url):\n",
    "    # Create a newspaper Article object\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    # Download and parse the article\n",
    "    article.download()\n",
    "    article.parse()\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title = article.title.strip()\n",
    "    subtitle = article.meta_data.get(\"description\", \"\").strip()\n",
    "    description = article.meta_description.strip()\n",
    "    text = article.text.strip()\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{text}\"\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(article_text)\n",
    "    \n",
    "    # Identify the stop words for each sentence\n",
    "    num_stop_words_per_sentence = []\n",
    "    stop_words_per_sentence = []\n",
    "    filtered_sentences = []\n",
    "    num_words_per_sentence = []\n",
    "    avg_stop_words_per_sentence = []\n",
    "    total_words = 0\n",
    "\n",
    "    # Create a Porter stemmer object\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_sentences = []\n",
    "\n",
    "    # Process the text with the pipeline and extract the sentiment for each sentence\n",
    "    doc = nlp(text)\n",
    "    sentiment_scores = []\n",
    "\n",
    "    # initialize the Vader sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    v_scores_list = []\n",
    "\n",
    "    # MPQA analysis\n",
    "    mpqa_scores = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        all_words = len(words)\n",
    "        total_words += all_words\n",
    "        \n",
    "        # Identify the stop words in the sentence\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words_found = [word for word in words if word.lower() in stop_words]\n",
    "        all_stop_words = len(stop_words_found)\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        \n",
    "        # Add the number of stop words and filtered sentence to the output\n",
    "        num_stop_words = all_words - len(filtered_words)\n",
    "        num_stop_words_per_sentence.append(num_stop_words)\n",
    "        stop_words_per_sentence.append(stop_words_found)\n",
    "        filtered_sentences.append(\" \".join(filtered_words))\n",
    "        num_words_per_sentence.append(all_words)\n",
    "        \n",
    "        # Calculate the average number of stop words per sentence\n",
    "        avg_stop_words_per_sentence.append(num_stop_words / all_words)\n",
    "\n",
    "        # Perform stemming on each word using the Porter stemmer\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "        # Combine the stemmed words back into a single string\n",
    "        stemmed_sentence = ' '.join(stemmed_words)\n",
    "        stemmed_sentences.append(stemmed_sentence)\n",
    "        output_text = '\\n'.join(stemmed_sentences)\n",
    "\n",
    "        v_scores = analyzer.polarity_scores(sentence)\n",
    "        v_score_list = [v_scores['neg'], v_scores['neu'], v_scores['pos']]\n",
    "        v_scores_list.append(v_score_list)\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        sentiment_scores.append(sentence.sentiment)\n",
    "\n",
    "    for word in article_text.split():\n",
    "        word = word.strip().lower()\n",
    "        if word in lexicon.word.tolist():\n",
    "            polarity = lexicon[lexicon.word == word].polarity.values[0]\n",
    "            mpqa_scores.append(polarity)\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    num_stop_words = sum(num_stop_words_per_sentence)\n",
    "    num_sentences = len(sentences)\n",
    "    avg_stop_words_per_sentence_all = num_stop_words / num_sentences\n",
    "    max_stop_words_per_sentence = max(num_stop_words_per_sentence)\n",
    "    min_stop_words_per_sentence = min(num_stop_words_per_sentence)\n",
    "    avg_stop_words_per_word = num_stop_words / total_words\n",
    "    \n",
    "    # Calculate the average number of stop words per article\n",
    "    avg_stop_words_per_sentence_avg = sum(avg_stop_words_per_sentence) / len(avg_stop_words_per_sentence)\n",
    "\n",
    "    v_scores_array = np.array(v_scores_list)\n",
    "    v_avg_scores = np.mean(v_scores_array, axis=0)\n",
    "    v_max_scores = np.max(v_scores_array, axis=0)\n",
    "    v_min_scores = np.min(v_scores_array, axis=0)\n",
    "    v_std_scores = np.std(v_scores_array, axis=0)\n",
    "\n",
    "    mpqa_avg_score = np.mean(mpqa_scores)\n",
    "    mpqa_max_score = np.max(mpqa_scores)\n",
    "    mpqa_min_score = np.min(mpqa_scores)\n",
    "    mpqa_sd_score = np.std(mpqa_scores)\n",
    "\n",
    "    sentiwordnet_text = article_text.lower()\n",
    "    tokens = word_tokenize(sentiwordnet_text)\n",
    "    tokens = [token for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if not token in nltk.corpus.stopwords.words('english')]\n",
    "    sentiwordnet_scores = []\n",
    "\n",
    "    for token in tokens:\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        synsets = swn.senti_synsets(token)\n",
    "        for synset in synsets:\n",
    "            pos_score += synset.pos_score()\n",
    "            neg_score += synset.neg_score()\n",
    "        if pos_score > neg_score:\n",
    "            sentiment_score = 1\n",
    "        elif neg_score > pos_score:\n",
    "            sentiment_score = -1\n",
    "        else:\n",
    "            sentiment_score = 0\n",
    "        sentiwordnet_scores.append(sentiment_score)\n",
    "    assert(len(sentiwordnet_scores) == len(tokens))\n",
    "\n",
    "\n",
    "    # Return the output\n",
    "    return {\n",
    "        'num_stop_words': num_stop_words,\n",
    "        'total_words': total_words,\n",
    "        'stop_words_found': stop_words_found,\n",
    "        'all_stop_words': all_stop_words,\n",
    "        'avg_stop_words_per_sentence_all': avg_stop_words_per_sentence_all,\n",
    "        'max_stop_words_per_sentence': max_stop_words_per_sentence,\n",
    "        'min_stop_words_per_sentence': min_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_word': avg_stop_words_per_word,\n",
    "        'avg_stop_words_per_sentence': avg_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_sentence_avg': avg_stop_words_per_sentence_avg,\n",
    "        'filtered_sentences': filtered_sentences,\n",
    "        'stop_words_per_sentence': stop_words_per_sentence,\n",
    "        'num_words_per_sentence': num_words_per_sentence,\n",
    "        'num_stop_words_per_sentence': num_stop_words_per_sentence,\n",
    "        'output_text': output_text,\n",
    "        'sentiment_scores': sentiment_scores,\n",
    "        'v_avg_scores': v_avg_scores,\n",
    "        'v_max_scores': v_max_scores,\n",
    "        'v_min_scores': v_min_scores,\n",
    "        'v_std_scores': v_std_scores,\n",
    "        'mpqa_avg_score': mpqa_avg_score,\n",
    "        'mpqa_max_score': mpqa_max_score,\n",
    "        'mpqa_min_score': mpqa_min_score,\n",
    "        'mpqa_sd_score': mpqa_sd_score,\n",
    "        'tokens': tokens,\n",
    "        'sentiwordnet_scores': sentiwordnet_scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Republicans respond IRS whistleblower says Hunter Biden investigation mishandled Members Congress calling transparency Biden administration IRS whistleblower said investigation Hunter Biden mishandled .\n",
      "Total words: 38\n",
      "Filtered words: ['Republicans', 'respond', 'IRS', 'whistleblower', 'says', 'Hunter', 'Biden', 'investigation', 'mishandled', 'Members', 'Congress', 'calling', 'transparency', 'Biden', 'administration', 'IRS', 'whistleblower', 'said', 'investigation', 'Hunter', 'Biden', 'mishandled', '.']\n",
      "Number of filtered words: 23\n",
      "Stop words: ['after', 'is', 'being', 'of', 'are', 'for', 'more', 'from', 'the', 'after', 'an', 'an', 'into', 'is', 'being']\n",
      "Number of stop words: 15\n",
      "Average number of stop words per sentence: 0.39\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 2: Lawmakers Capitol Hill calling Biden administration held accountable `` blocking '' Congress public learning Biden family members ’ business deals China .\n",
      "Total words: 35\n",
      "Filtered words: ['Lawmakers', 'Capitol', 'Hill', 'calling', 'Biden', 'administration', 'held', 'accountable', '``', 'blocking', \"''\", 'Congress', 'public', 'learning', 'Biden', 'family', 'members', '’', 'business', 'deals', 'China', '.']\n",
      "Number of filtered words: 22\n",
      "Stop words: ['on', 'are', 'for', 'the', 'to', 'be', 'for', 'and', 'the', 'from', 'more', 'about', 'with']\n",
      "Number of stop words: 13\n",
      "Average number of stop words per sentence: 0.37\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 3: congressional outcries come whistleblower within Internal Revenue Service alleges investigation Hunter Biden mishandled Biden administration .\n",
      "Total words: 26\n",
      "Filtered words: ['congressional', 'outcries', 'come', 'whistleblower', 'within', 'Internal', 'Revenue', 'Service', 'alleges', 'investigation', 'Hunter', 'Biden', 'mishandled', 'Biden', 'administration', '.']\n",
      "Number of filtered words: 16\n",
      "Stop words: ['The', 'as', 'a', 'the', 'an', 'into', 'is', 'being', 'by', 'the']\n",
      "Number of stop words: 10\n",
      "Average number of stop words per sentence: 0.38\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 4: whistleblower also alleges `` clear conflicts interest '' investigation .\n",
      "Total words: 14\n",
      "Filtered words: ['whistleblower', 'also', 'alleges', '``', 'clear', 'conflicts', 'interest', \"''\", 'investigation', '.']\n",
      "Number of filtered words: 10\n",
      "Stop words: ['The', 'of', 'in', 'the']\n",
      "Number of stop words: 4\n",
      "Average number of stop words per sentence: 0.29\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 5: `` ’ deeply concerning Biden Administration may obstructing justice blocking efforts charge Hunter Biden tax violations , '' House Committee Oversight Accountability Chairman James Comer told Fox News Wednesday .\n",
      "Total words: 41\n",
      "Filtered words: ['``', '’', 'deeply', 'concerning', 'Biden', 'Administration', 'may', 'obstructing', 'justice', 'blocking', 'efforts', 'charge', 'Hunter', 'Biden', 'tax', 'violations', ',', \"''\", 'House', 'Committee', 'Oversight', 'Accountability', 'Chairman', 'James', 'Comer', 'told', 'Fox', 'News', 'Wednesday', '.']\n",
      "Number of filtered words: 30\n",
      "Stop words: ['It', 's', 'that', 'the', 'be', 'by', 'to', 'for', 'on', 'and', 'on']\n",
      "Number of stop words: 11\n",
      "Average number of stop words per sentence: 0.27\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 6: Comer , R-Ky. , also said `` deceptive , shady business schemes '' allowed Bidens make `` millions foreign adversaries like China . ''\n",
      "Total words: 28\n",
      "Filtered words: ['Comer', ',', 'R-Ky.', ',', 'also', 'said', '``', 'deceptive', ',', 'shady', 'business', 'schemes', \"''\", 'allowed', 'Bidens', 'make', '``', 'millions', 'foreign', 'adversaries', 'like', 'China', '.', \"''\"]\n",
      "Number of filtered words: 24\n",
      "Stop words: ['have', 'the', 'to', 'from']\n",
      "Number of stop words: 4\n",
      "Average number of stop words per sentence: 0.14\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 7: HUNTER BIDEN INVESTIGATION MISHANDLED , 'CLEAR CONFLICTS INTEREST ' : IRS WHISTLEBLOWER '' House Committee Oversight Accountability following Bidens ’ tangled web complex corporate financial records .\n",
      "Total words: 37\n",
      "Filtered words: ['HUNTER', 'BIDEN', 'INVESTIGATION', 'MISHANDLED', ',', \"'CLEAR\", 'CONFLICTS', 'INTEREST', \"'\", ':', 'IRS', 'WHISTLEBLOWER', \"''\", 'House', 'Committee', 'Oversight', 'Accountability', 'following', 'Bidens', '’', 'tangled', 'web', 'complex', 'corporate', 'financial', 'records', '.']\n",
      "Number of filtered words: 27\n",
      "Stop words: ['BEING', 'OF', 'The', 'on', 'and', 'has', 'been', 'the', 'of', 'and']\n",
      "Number of stop words: 10\n",
      "Average number of stop words per sentence: 0.27\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 8: ’ clear investigation Hunter members Biden family engaged deceptive , shady business schemes avoid scrutiny made millions foreign adversaries like China , '' said .\n",
      "Total words: 40\n",
      "Filtered words: ['’', 'clear', 'investigation', 'Hunter', 'members', 'Biden', 'family', 'engaged', 'deceptive', ',', 'shady', 'business', 'schemes', 'avoid', 'scrutiny', 'made', 'millions', 'foreign', 'adversaries', 'like', 'China', ',', \"''\", 'said', '.']\n",
      "Number of filtered words: 25\n",
      "Stop words: ['It', 's', 'from', 'our', 'that', 'and', 'other', 'of', 'the', 'in', 'to', 'as', 'they', 'from', 'he']\n",
      "Number of stop words: 15\n",
      "Average number of stop words per sentence: 0.38\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 9: `` ’ wondering along heck DOJ IRS .\n",
      "Total words: 19\n",
      "Filtered words: ['``', '’', 'wondering', 'along', 'heck', 'DOJ', 'IRS', '.']\n",
      "Number of filtered words: 8\n",
      "Stop words: ['We', 've', 'been', 'all', 'where', 'the', 'the', 'and', 'the', 'have', 'been']\n",
      "Number of stop words: 11\n",
      "Average number of stop words per sentence: 0.58\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 10: appears Biden Administration may working overtime prevent Bidens facing consequences . ''\n",
      "Total words: 21\n",
      "Filtered words: ['appears', 'Biden', 'Administration', 'may', 'working', 'overtime', 'prevent', 'Bidens', 'facing', 'consequences', '.', \"''\"]\n",
      "Number of filtered words: 12\n",
      "Stop words: ['Now', 'it', 'the', 'have', 'been', 'to', 'the', 'from', 'any']\n",
      "Number of stop words: 9\n",
      "Average number of stop words per sentence: 0.43\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 11: Comer added , `` House Oversight Committee work hold accountable anyone Biden Administration may covering criminal activity .\n",
      "Total words: 27\n",
      "Filtered words: ['Comer', 'added', ',', '``', 'House', 'Oversight', 'Committee', 'work', 'hold', 'accountable', 'anyone', 'Biden', 'Administration', 'may', 'covering', 'criminal', 'activity', '.']\n",
      "Number of filtered words: 18\n",
      "Stop words: ['The', 'will', 'to', 'in', 'the', 'who', 'be', 'up', 'this']\n",
      "Number of stop words: 9\n",
      "Average number of stop words per sentence: 0.33\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 12: Oversight Committee also continue pursue investigation Biden family ’ business schemes determine President Biden national security compromised .\n",
      "Total words: 30\n",
      "Filtered words: ['Oversight', 'Committee', 'also', 'continue', 'pursue', 'investigation', 'Biden', 'family', '’', 'business', 'schemes', 'determine', 'President', 'Biden', 'national', 'security', 'compromised', '.']\n",
      "Number of filtered words: 18\n",
      "Stop words: ['The', 'will', 'to', 'our', 'into', 'the', 's', 'to', 'if', 'and', 'our', 'are']\n",
      "Number of stop words: 12\n",
      "Average number of stop words per sentence: 0.4\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 13: Americans demand answers , transparency , accountability . ''\n",
      "Total words: 10\n",
      "Filtered words: ['Americans', 'demand', 'answers', ',', 'transparency', ',', 'accountability', '.', \"''\"]\n",
      "Number of filtered words: 9\n",
      "Stop words: ['and']\n",
      "Number of stop words: 1\n",
      "Average number of stop words per sentence: 0.1\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 14: President Biden ’ son Hunter federal investigation since 2018 .\n",
      "Total words: 14\n",
      "Filtered words: ['President', 'Biden', '’', 'son', 'Hunter', 'federal', 'investigation', 'since', '2018', '.']\n",
      "Number of filtered words: 10\n",
      "Stop words: ['s', 'has', 'been', 'under']\n",
      "Number of stop words: 4\n",
      "Average number of stop words per sentence: 0.29\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 15: investigation concerns presence suspicious activity reports ( SARs ) regarding suspicious foreign transactions .\n",
      "Total words: 17\n",
      "Filtered words: ['investigation', 'concerns', 'presence', 'suspicious', 'activity', 'reports', '(', 'SARs', ')', 'regarding', 'suspicious', 'foreign', 'transactions', '.']\n",
      "Number of filtered words: 14\n",
      "Stop words: ['The', 'the', 'of']\n",
      "Number of stop words: 3\n",
      "Average number of stop words per sentence: 0.18\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 16: led Delaware U.S. Attorney David Weiss .\n",
      "Total words: 11\n",
      "Filtered words: ['led', 'Delaware', 'U.S.', 'Attorney', 'David', 'Weiss', '.']\n",
      "Number of filtered words: 7\n",
      "Stop words: ['It', 'is', 'being', 'by']\n",
      "Number of stop words: 4\n",
      "Average number of stop words per sentence: 0.36\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 17: Across Congress , Sen. Ted Cruz Wednesday called Treasury Secretary Janet Yellen publicly release SARs found among Biden family ’ tax records .\n",
      "Total words: 29\n",
      "Filtered words: ['Across', 'Congress', ',', 'Sen.', 'Ted', 'Cruz', 'Wednesday', 'called', 'Treasury', 'Secretary', 'Janet', 'Yellen', 'publicly', 'release', 'SARs', 'found', 'among', 'Biden', 'family', '’', 'tax', 'records', '.']\n",
      "Number of filtered words: 23\n",
      "Stop words: ['on', 'for', 'to', 'the', 'the', 's']\n",
      "Number of stop words: 6\n",
      "Average number of stop words per sentence: 0.21\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 18: `` ’ national security reason keep private , '' Cruz , R-Texas , said episode podcast .\n",
      "Total words: 26\n",
      "Filtered words: ['``', '’', 'national', 'security', 'reason', 'keep', 'private', ',', \"''\", 'Cruz', ',', 'R-Texas', ',', 'said', 'episode', 'podcast', '.']\n",
      "Number of filtered words: 17\n",
      "Stop words: ['There', 's', 'no', 'to', 'them', 'during', 'an', 'of', 'his']\n",
      "Number of stop words: 9\n",
      "Average number of stop words per sentence: 0.35\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 19: `` ’ reason whatsoever want part political cover-up . ''\n",
      "Total words: 21\n",
      "Filtered words: ['``', '’', 'reason', 'whatsoever', 'want', 'part', 'political', 'cover-up', '.', \"''\"]\n",
      "Number of filtered words: 10\n",
      "Stop words: ['There', 's', 'no', 'other', 'than', 'if', 'you', 'to', 'be', 'of', 'a']\n",
      "Number of stop words: 11\n",
      "Average number of stop words per sentence: 0.52\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 20: SIX ADDITIONAL BIDEN FAMILY MEMBERS ‘ MAY BENEFITED ’ HUNTER BUSINESS DEALINGS SARs alone indicate wrongdoing criminal activity could indicator behavior .\n",
      "Total words: 32\n",
      "Filtered words: ['SIX', 'ADDITIONAL', 'BIDEN', 'FAMILY', 'MEMBERS', '‘', 'MAY', 'BENEFITED', '’', 'HUNTER', 'BUSINESS', 'DEALINGS', 'SARs', 'alone', 'indicate', 'wrongdoing', 'criminal', 'activity', 'could', 'indicator', 'behavior', '.']\n",
      "Number of filtered words: 22\n",
      "Stop words: ['HAVE', 'FROM', 'do', 'not', 'or', 'but', 'be', 'an', 'of', 'such']\n",
      "Number of stop words: 10\n",
      "Average number of stop words per sentence: 0.31\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 21: `` U.S. Department Treasury needs release every single suspicious activity report Biden family , '' Cruz said Wednesday .\n",
      "Total words: 25\n",
      "Filtered words: ['``', 'U.S.', 'Department', 'Treasury', 'needs', 'release', 'every', 'single', 'suspicious', 'activity', 'report', 'Biden', 'family', ',', \"''\", 'Cruz', 'said', 'Wednesday', '.']\n",
      "Number of filtered words: 19\n",
      "Stop words: ['The', 'of', 'to', 'on', 'the', 'on']\n",
      "Number of stop words: 6\n",
      "Average number of stop words per sentence: 0.24\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 22: `` Janet Yellen , choice : either actively covering potential evidence corruption releasing every one American people . ''\n",
      "Total words: 31\n",
      "Filtered words: ['``', 'Janet', 'Yellen', ',', 'choice', ':', 'either', 'actively', 'covering', 'potential', 'evidence', 'corruption', 'releasing', 'every', 'one', 'American', 'people', '.', \"''\"]\n",
      "Number of filtered words: 19\n",
      "Stop words: ['you', 'have', 'a', 'You', 'are', 'up', 'of', 'or', 'of', 'them', 'to', 'the']\n",
      "Number of stop words: 12\n",
      "Average number of stop words per sentence: 0.39\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 23: According Cruz , American public privy learning whether presidential family guilty fraud abuses office — innocent .\n",
      "Total words: 32\n",
      "Filtered words: ['According', 'Cruz', ',', 'American', 'public', 'privy', 'learning', 'whether', 'presidential', 'family', 'guilty', 'fraud', 'abuses', 'office', '—', 'innocent', '.']\n",
      "Number of filtered words: 17\n",
      "Stop words: ['to', 'the', 'should', 'be', 'to', 'the', 'is', 'of', 'or', 'other', 'of', 'or', 'if', 'he', 'is']\n",
      "Number of stop words: 15\n",
      "Average number of stop words per sentence: 0.47\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 24: BIDEN FAMILY RECEIVED $ 1M HUNTER ASSOCIATE 2017 CHINA WIRE : HOUSE OVERSIGHT Texas Republican said Biden administration `` let American people decide '' criminal activity conducted .\n",
      "Total words: 38\n",
      "Filtered words: ['BIDEN', 'FAMILY', 'RECEIVED', '$', '1M', 'HUNTER', 'ASSOCIATE', '2017', 'CHINA', 'WIRE', ':', 'HOUSE', 'OVERSIGHT', 'Texas', 'Republican', 'said', 'Biden', 'administration', '``', 'let', 'American', 'people', 'decide', \"''\", 'criminal', 'activity', 'conducted', '.']\n",
      "Number of filtered words: 28\n",
      "Stop words: ['MORE', 'THAN', 'FROM', 'AFTER', 'The', 'the', 'should', 'the', 'if', 'was']\n",
      "Number of stop words: 10\n",
      "Average number of stop words per sentence: 0.26\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 25: added , `` benign , release reports . ''\n",
      "Total words: 14\n",
      "Filtered words: ['added', ',', '``', 'benign', ',', 'release', 'reports', '.', \"''\"]\n",
      "Number of filtered words: 9\n",
      "Stop words: ['He', 'If', 'this', 'is', 'the']\n",
      "Number of stop words: 5\n",
      "Average number of stop words per sentence: 0.36\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 26: `` Secretary Yellen , release every single suspicious activity report Biden family , '' Cruz said .\n",
      "Total words: 19\n",
      "Filtered words: ['``', 'Secretary', 'Yellen', ',', 'release', 'every', 'single', 'suspicious', 'activity', 'report', 'Biden', 'family', ',', \"''\", 'Cruz', 'said', '.']\n",
      "Number of filtered words: 17\n",
      "Stop words: ['on', 'the']\n",
      "Number of stop words: 2\n",
      "Average number of stop words per sentence: 0.11\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 27: continued .\n",
      "Total words: 3\n",
      "Filtered words: ['continued', '.']\n",
      "Number of filtered words: 2\n",
      "Stop words: ['He']\n",
      "Number of stop words: 1\n",
      "Average number of stop words per sentence: 0.33\n",
      "Sentiment score: 0\n",
      "\n",
      "\n",
      "Sentence 28: `` ’ release reports , complicit cover-up . ''\n",
      "Total words: 18\n",
      "Filtered words: ['``', '’', 'release', 'reports', ',', 'complicit', 'cover-up', '.', \"''\"]\n",
      "Number of filtered words: 9\n",
      "Stop words: ['If', 'she', 'doesn', 't', 'those', 'she', 'is', 'in', 'the']\n",
      "Number of stop words: 9\n",
      "Average number of stop words per sentence: 0.5\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 29: letter dated April 19 , 2023 , attorney Mark D. Lytle told members Congress client overseeing `` ongoing sensitive investigation high-profile , controversial subject since early 2020 would like make protected whistleblower disclosures Congress . ''\n",
      "Total words: 52\n",
      "Filtered words: ['letter', 'dated', 'April', '19', ',', '2023', ',', 'attorney', 'Mark', 'D.', 'Lytle', 'told', 'members', 'Congress', 'client', 'overseeing', '``', 'ongoing', 'sensitive', 'investigation', 'high-profile', ',', 'controversial', 'subject', 'since', 'early', '2020', 'would', 'like', 'make', 'protected', 'whistleblower', 'disclosures', 'Congress', '.', \"''\"]\n",
      "Number of filtered words: 36\n",
      "Stop words: ['In', 'a', 'of', 'that', 'a', 'of', 'his', 'has', 'been', 'the', 'and', 'of', 'a', 'and', 'to', 'to']\n",
      "Number of stop words: 16\n",
      "Average number of stop words per sentence: 0.31\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 30: client allegedly aware facts case `` contradict sworn testimony Congress senior political appointee . ''\n",
      "Total words: 26\n",
      "Filtered words: ['client', 'allegedly', 'aware', 'facts', 'case', '``', 'contradict', 'sworn', 'testimony', 'Congress', 'senior', 'political', 'appointee', '.', \"''\"]\n",
      "Number of filtered words: 15\n",
      "Stop words: ['And', 'that', 'the', 'is', 'of', 'of', 'the', 'that', 'to', 'by', 'a']\n",
      "Number of stop words: 11\n",
      "Average number of stop words per sentence: 0.42\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 31: CLICK GET FOX NEWS APP Lytle works Washington , D.C. , -based law firm Nixon Peabody LLP .\n",
      "Total words: 23\n",
      "Filtered words: ['CLICK', 'GET', 'FOX', 'NEWS', 'APP', 'Lytle', 'works', 'Washington', ',', 'D.C.', ',', '-based', 'law', 'firm', 'Nixon', 'Peabody', 'LLP', '.']\n",
      "Number of filtered words: 18\n",
      "Stop words: ['HERE', 'TO', 'THE', 'for', 'the']\n",
      "Number of stop words: 5\n",
      "Average number of stop words per sentence: 0.22\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 32: Neither Hunter Biden member family charged crime relating SARs .\n",
      "Total words: 20\n",
      "Filtered words: ['Neither', 'Hunter', 'Biden', 'member', 'family', 'charged', 'crime', 'relating', 'SARs', '.']\n",
      "Number of filtered words: 10\n",
      "Stop words: ['nor', 'any', 'of', 'his', 'has', 'been', 'with', 'a', 'to', 'the']\n",
      "Number of stop words: 10\n",
      "Average number of stop words per sentence: 0.5\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Sentence 33: Fox News ' Patrick Ward , Greg Wehner contributed report .\n",
      "Total words: 13\n",
      "Filtered words: ['Fox', 'News', \"'\", 'Patrick', 'Ward', ',', 'Greg', 'Wehner', 'contributed', 'report', '.']\n",
      "Number of filtered words: 11\n",
      "Stop words: ['to', 'this']\n",
      "Number of stop words: 2\n",
      "Average number of stop words per sentence: 0.15\n",
      "Sentiment score: 1\n",
      "\n",
      "\n",
      "Total number of words: 830\n",
      "Total number of stop words: 275\n",
      "Maximum number of stop words per sentence: 16\n",
      "Minimum number of stop words per sentence: 1\n",
      "Average number of stop words per article: 0.33\n",
      "\n",
      "Average of sentiment score for all sentences: 0.7948717948717948\n",
      "Maximum sentiment score: 1\n",
      "Minimum sentiment score: 0\n",
      "Standard deviation: 0.4090738692453054\n",
      "\n",
      "Vader average scores: [0.07775758 0.86757576 0.05457576]\n",
      "Vader maximum scores: [0.294 1.    0.346]\n",
      "Vader minimum scores: [0.    0.494 0.   ]\n",
      "Vader standard deviation scores: [0.08812698 0.1209152  0.07819983]\n",
      "\n",
      "MPQA average scores: -0.1864406779661017\n",
      "MPQA maximum scores: 1\n",
      "MPQA minimum scores: -1\n",
      "MPQA standard deviation scores: 0.8532008778747944\n",
      "\n",
      "1. Token: republicans, Sentiment Score: 0\n",
      "2. Token: respond, Sentiment Score: 1\n",
      "3. Token: irs, Sentiment Score: 0\n",
      "4. Token: whistleblower, Sentiment Score: 0\n",
      "5. Token: says, Sentiment Score: 1\n",
      "6. Token: hunter, Sentiment Score: -1\n",
      "7. Token: biden, Sentiment Score: 0\n",
      "8. Token: investigation, Sentiment Score: 1\n",
      "9. Token: mishandled, Sentiment Score: -1\n",
      "10. Token: members, Sentiment Score: 0\n",
      "11. Token: congress, Sentiment Score: 0\n",
      "12. Token: calling, Sentiment Score: 1\n",
      "13. Token: transparency, Sentiment Score: 1\n",
      "14. Token: biden, Sentiment Score: 0\n",
      "15. Token: administration, Sentiment Score: 1\n",
      "16. Token: irs, Sentiment Score: 0\n",
      "17. Token: whistleblower, Sentiment Score: 0\n",
      "18. Token: said, Sentiment Score: 1\n",
      "19. Token: investigation, Sentiment Score: 1\n",
      "20. Token: hunter, Sentiment Score: -1\n",
      "21. Token: biden, Sentiment Score: 0\n",
      "22. Token: mishandled, Sentiment Score: -1\n",
      "23. Token: lawmakers, Sentiment Score: 0\n",
      "24. Token: capitol, Sentiment Score: 0\n",
      "25. Token: hill, Sentiment Score: 0\n",
      "26. Token: calling, Sentiment Score: 1\n",
      "27. Token: biden, Sentiment Score: 0\n",
      "28. Token: administration, Sentiment Score: 1\n",
      "29. Token: held, Sentiment Score: 1\n",
      "30. Token: accountable, Sentiment Score: 0\n",
      "31. Token: blocking, Sentiment Score: -1\n",
      "32. Token: congress, Sentiment Score: 0\n",
      "33. Token: public, Sentiment Score: -1\n",
      "34. Token: learning, Sentiment Score: 1\n",
      "35. Token: biden, Sentiment Score: 0\n",
      "36. Token: family, Sentiment Score: 0\n",
      "37. Token: members, Sentiment Score: 0\n",
      "38. Token: business, Sentiment Score: 1\n",
      "39. Token: deals, Sentiment Score: 0\n",
      "40. Token: china, Sentiment Score: 1\n",
      "41. Token: congressional, Sentiment Score: 0\n",
      "42. Token: outcries, Sentiment Score: -1\n",
      "43. Token: come, Sentiment Score: 1\n",
      "44. Token: whistleblower, Sentiment Score: 0\n",
      "45. Token: within, Sentiment Score: 0\n",
      "46. Token: internal, Sentiment Score: 1\n",
      "47. Token: revenue, Sentiment Score: 1\n",
      "48. Token: service, Sentiment Score: -1\n",
      "49. Token: alleges, Sentiment Score: 0\n",
      "50. Token: investigation, Sentiment Score: 1\n",
      "51. Token: hunter, Sentiment Score: -1\n",
      "52. Token: biden, Sentiment Score: 0\n",
      "53. Token: mishandled, Sentiment Score: -1\n",
      "54. Token: biden, Sentiment Score: 0\n",
      "55. Token: administration, Sentiment Score: 1\n",
      "56. Token: whistleblower, Sentiment Score: 0\n",
      "57. Token: also, Sentiment Score: 0\n",
      "58. Token: alleges, Sentiment Score: 0\n",
      "59. Token: clear, Sentiment Score: 1\n",
      "60. Token: conflicts, Sentiment Score: -1\n",
      "61. Token: interest, Sentiment Score: 1\n",
      "62. Token: investigation, Sentiment Score: 1\n",
      "63. Token: deeply, Sentiment Score: 0\n",
      "64. Token: concerning, Sentiment Score: 1\n",
      "65. Token: biden, Sentiment Score: 0\n",
      "66. Token: administration, Sentiment Score: 1\n",
      "67. Token: may, Sentiment Score: 0\n",
      "68. Token: obstructing, Sentiment Score: 0\n",
      "69. Token: justice, Sentiment Score: 1\n",
      "70. Token: blocking, Sentiment Score: -1\n",
      "71. Token: efforts, Sentiment Score: 1\n",
      "72. Token: charge, Sentiment Score: -1\n",
      "73. Token: hunter, Sentiment Score: -1\n",
      "74. Token: biden, Sentiment Score: 0\n",
      "75. Token: tax, Sentiment Score: 0\n",
      "76. Token: violations, Sentiment Score: -1\n",
      "77. Token: house, Sentiment Score: 0\n",
      "78. Token: committee, Sentiment Score: 0\n",
      "79. Token: oversight, Sentiment Score: -1\n",
      "80. Token: accountability, Sentiment Score: 0\n",
      "81. Token: chairman, Sentiment Score: 0\n",
      "82. Token: james, Sentiment Score: -1\n",
      "83. Token: comer, Sentiment Score: 1\n",
      "84. Token: told, Sentiment Score: 1\n",
      "85. Token: fox, Sentiment Score: -1\n",
      "86. Token: news, Sentiment Score: 1\n",
      "87. Token: wednesday, Sentiment Score: 0\n",
      "88. Token: comer, Sentiment Score: 1\n",
      "89. Token: also, Sentiment Score: 0\n",
      "90. Token: said, Sentiment Score: 1\n",
      "91. Token: deceptive, Sentiment Score: -1\n",
      "92. Token: shady, Sentiment Score: -1\n",
      "93. Token: business, Sentiment Score: 1\n",
      "94. Token: schemes, Sentiment Score: 1\n",
      "95. Token: allowed, Sentiment Score: 1\n",
      "96. Token: bidens, Sentiment Score: 0\n",
      "97. Token: make, Sentiment Score: 1\n",
      "98. Token: millions, Sentiment Score: -1\n",
      "99. Token: foreign, Sentiment Score: -1\n",
      "100. Token: adversaries, Sentiment Score: 0\n",
      "101. Token: like, Sentiment Score: 1\n",
      "102. Token: china, Sentiment Score: 1\n",
      "103. Token: hunter, Sentiment Score: -1\n",
      "104. Token: biden, Sentiment Score: 0\n",
      "105. Token: investigation, Sentiment Score: 1\n",
      "106. Token: mishandled, Sentiment Score: -1\n",
      "107. Token: conflicts, Sentiment Score: -1\n",
      "108. Token: interest, Sentiment Score: 1\n",
      "109. Token: irs, Sentiment Score: 0\n",
      "110. Token: whistleblower, Sentiment Score: 0\n",
      "111. Token: house, Sentiment Score: 0\n",
      "112. Token: committee, Sentiment Score: 0\n",
      "113. Token: oversight, Sentiment Score: -1\n",
      "114. Token: accountability, Sentiment Score: 0\n",
      "115. Token: following, Sentiment Score: 1\n",
      "116. Token: bidens, Sentiment Score: 0\n",
      "117. Token: tangled, Sentiment Score: 1\n",
      "118. Token: web, Sentiment Score: 1\n",
      "119. Token: complex, Sentiment Score: -1\n",
      "120. Token: corporate, Sentiment Score: -1\n",
      "121. Token: financial, Sentiment Score: 1\n",
      "122. Token: records, Sentiment Score: 1\n",
      "123. Token: clear, Sentiment Score: 1\n",
      "124. Token: investigation, Sentiment Score: 1\n",
      "125. Token: hunter, Sentiment Score: -1\n",
      "126. Token: members, Sentiment Score: 0\n",
      "127. Token: biden, Sentiment Score: 0\n",
      "128. Token: family, Sentiment Score: 0\n",
      "129. Token: engaged, Sentiment Score: 1\n",
      "130. Token: deceptive, Sentiment Score: -1\n",
      "131. Token: shady, Sentiment Score: -1\n",
      "132. Token: business, Sentiment Score: 1\n",
      "133. Token: schemes, Sentiment Score: 1\n",
      "134. Token: avoid, Sentiment Score: -1\n",
      "135. Token: scrutiny, Sentiment Score: 1\n",
      "136. Token: made, Sentiment Score: 1\n",
      "137. Token: millions, Sentiment Score: -1\n",
      "138. Token: foreign, Sentiment Score: -1\n",
      "139. Token: adversaries, Sentiment Score: 0\n",
      "140. Token: like, Sentiment Score: 1\n",
      "141. Token: china, Sentiment Score: 1\n",
      "142. Token: said, Sentiment Score: 1\n",
      "143. Token: wondering, Sentiment Score: 1\n",
      "144. Token: along, Sentiment Score: 0\n",
      "145. Token: heck, Sentiment Score: 0\n",
      "146. Token: doj, Sentiment Score: 0\n",
      "147. Token: irs, Sentiment Score: 0\n",
      "148. Token: appears, Sentiment Score: 0\n",
      "149. Token: biden, Sentiment Score: 0\n",
      "150. Token: administration, Sentiment Score: 1\n",
      "151. Token: may, Sentiment Score: 0\n",
      "152. Token: working, Sentiment Score: 1\n",
      "153. Token: overtime, Sentiment Score: 0\n",
      "154. Token: prevent, Sentiment Score: 1\n",
      "155. Token: bidens, Sentiment Score: 0\n",
      "156. Token: facing, Sentiment Score: -1\n",
      "157. Token: consequences, Sentiment Score: 1\n",
      "158. Token: comer, Sentiment Score: 1\n",
      "159. Token: added, Sentiment Score: 1\n",
      "160. Token: house, Sentiment Score: 0\n",
      "161. Token: oversight, Sentiment Score: -1\n",
      "162. Token: committee, Sentiment Score: 0\n",
      "163. Token: work, Sentiment Score: 1\n",
      "164. Token: hold, Sentiment Score: 1\n",
      "165. Token: accountable, Sentiment Score: 0\n",
      "166. Token: anyone, Sentiment Score: 0\n",
      "167. Token: biden, Sentiment Score: 0\n",
      "168. Token: administration, Sentiment Score: 1\n",
      "169. Token: may, Sentiment Score: 0\n",
      "170. Token: covering, Sentiment Score: 1\n",
      "171. Token: criminal, Sentiment Score: -1\n",
      "172. Token: activity, Sentiment Score: 1\n",
      "173. Token: oversight, Sentiment Score: -1\n",
      "174. Token: committee, Sentiment Score: 0\n",
      "175. Token: also, Sentiment Score: 0\n",
      "176. Token: continue, Sentiment Score: 0\n",
      "177. Token: pursue, Sentiment Score: 0\n",
      "178. Token: investigation, Sentiment Score: 1\n",
      "179. Token: biden, Sentiment Score: 0\n",
      "180. Token: family, Sentiment Score: 0\n",
      "181. Token: business, Sentiment Score: 1\n",
      "182. Token: schemes, Sentiment Score: 1\n",
      "183. Token: determine, Sentiment Score: -1\n",
      "184. Token: president, Sentiment Score: 0\n",
      "185. Token: biden, Sentiment Score: 0\n",
      "186. Token: national, Sentiment Score: 0\n",
      "187. Token: security, Sentiment Score: 1\n",
      "188. Token: compromised, Sentiment Score: -1\n",
      "189. Token: americans, Sentiment Score: 0\n",
      "190. Token: demand, Sentiment Score: -1\n",
      "191. Token: answers, Sentiment Score: -1\n",
      "192. Token: transparency, Sentiment Score: 1\n",
      "193. Token: accountability, Sentiment Score: 0\n",
      "194. Token: president, Sentiment Score: 0\n",
      "195. Token: biden, Sentiment Score: 0\n",
      "196. Token: son, Sentiment Score: 0\n",
      "197. Token: hunter, Sentiment Score: -1\n",
      "198. Token: federal, Sentiment Score: 0\n",
      "199. Token: investigation, Sentiment Score: 1\n",
      "200. Token: since, Sentiment Score: 0\n",
      "201. Token: investigation, Sentiment Score: 1\n",
      "202. Token: concerns, Sentiment Score: 1\n",
      "203. Token: presence, Sentiment Score: 1\n",
      "204. Token: suspicious, Sentiment Score: -1\n",
      "205. Token: activity, Sentiment Score: 1\n",
      "206. Token: reports, Sentiment Score: 1\n",
      "207. Token: sars, Sentiment Score: -1\n",
      "208. Token: regarding, Sentiment Score: 1\n",
      "209. Token: suspicious, Sentiment Score: -1\n",
      "210. Token: foreign, Sentiment Score: -1\n",
      "211. Token: transactions, Sentiment Score: 0\n",
      "212. Token: led, Sentiment Score: 1\n",
      "213. Token: delaware, Sentiment Score: 0\n",
      "214. Token: attorney, Sentiment Score: 0\n",
      "215. Token: david, Sentiment Score: 0\n",
      "216. Token: weiss, Sentiment Score: 0\n",
      "217. Token: across, Sentiment Score: 0\n",
      "218. Token: congress, Sentiment Score: 0\n",
      "219. Token: ted, Sentiment Score: -1\n",
      "220. Token: cruz, Sentiment Score: 0\n",
      "221. Token: wednesday, Sentiment Score: 0\n",
      "222. Token: called, Sentiment Score: 1\n",
      "223. Token: treasury, Sentiment Score: 1\n",
      "224. Token: secretary, Sentiment Score: 0\n",
      "225. Token: janet, Sentiment Score: 0\n",
      "226. Token: yellen, Sentiment Score: 0\n",
      "227. Token: publicly, Sentiment Score: 0\n",
      "228. Token: release, Sentiment Score: 1\n",
      "229. Token: sars, Sentiment Score: -1\n",
      "230. Token: found, Sentiment Score: 1\n",
      "231. Token: among, Sentiment Score: 0\n",
      "232. Token: biden, Sentiment Score: 0\n",
      "233. Token: family, Sentiment Score: 0\n",
      "234. Token: tax, Sentiment Score: 0\n",
      "235. Token: records, Sentiment Score: 1\n",
      "236. Token: national, Sentiment Score: 0\n",
      "237. Token: security, Sentiment Score: 1\n",
      "238. Token: reason, Sentiment Score: 1\n",
      "239. Token: keep, Sentiment Score: -1\n",
      "240. Token: private, Sentiment Score: 1\n",
      "241. Token: cruz, Sentiment Score: 0\n",
      "242. Token: said, Sentiment Score: 1\n",
      "243. Token: episode, Sentiment Score: 0\n",
      "244. Token: podcast, Sentiment Score: 0\n",
      "245. Token: reason, Sentiment Score: 1\n",
      "246. Token: whatsoever, Sentiment Score: 0\n",
      "247. Token: want, Sentiment Score: 0\n",
      "248. Token: part, Sentiment Score: 0\n",
      "249. Token: political, Sentiment Score: 0\n",
      "250. Token: six, Sentiment Score: 0\n",
      "251. Token: additional, Sentiment Score: 0\n",
      "252. Token: biden, Sentiment Score: 0\n",
      "253. Token: family, Sentiment Score: 0\n",
      "254. Token: members, Sentiment Score: 0\n",
      "255. Token: may, Sentiment Score: 0\n",
      "256. Token: benefited, Sentiment Score: 1\n",
      "257. Token: hunter, Sentiment Score: -1\n",
      "258. Token: business, Sentiment Score: 1\n",
      "259. Token: dealings, Sentiment Score: 0\n",
      "260. Token: sars, Sentiment Score: -1\n",
      "261. Token: alone, Sentiment Score: 1\n",
      "262. Token: indicate, Sentiment Score: 0\n",
      "263. Token: wrongdoing, Sentiment Score: 1\n",
      "264. Token: criminal, Sentiment Score: -1\n",
      "265. Token: activity, Sentiment Score: 1\n",
      "266. Token: could, Sentiment Score: 0\n",
      "267. Token: indicator, Sentiment Score: 1\n",
      "268. Token: behavior, Sentiment Score: 1\n",
      "269. Token: department, Sentiment Score: 0\n",
      "270. Token: treasury, Sentiment Score: 1\n",
      "271. Token: needs, Sentiment Score: -1\n",
      "272. Token: release, Sentiment Score: 1\n",
      "273. Token: every, Sentiment Score: 1\n",
      "274. Token: single, Sentiment Score: -1\n",
      "275. Token: suspicious, Sentiment Score: -1\n",
      "276. Token: activity, Sentiment Score: 1\n",
      "277. Token: report, Sentiment Score: 1\n",
      "278. Token: biden, Sentiment Score: 0\n",
      "279. Token: family, Sentiment Score: 0\n",
      "280. Token: cruz, Sentiment Score: 0\n",
      "281. Token: said, Sentiment Score: 1\n",
      "282. Token: wednesday, Sentiment Score: 0\n",
      "283. Token: janet, Sentiment Score: 0\n",
      "284. Token: yellen, Sentiment Score: 0\n",
      "285. Token: choice, Sentiment Score: 1\n",
      "286. Token: either, Sentiment Score: 0\n",
      "287. Token: actively, Sentiment Score: 1\n",
      "288. Token: covering, Sentiment Score: 1\n",
      "289. Token: potential, Sentiment Score: -1\n",
      "290. Token: evidence, Sentiment Score: 0\n",
      "291. Token: corruption, Sentiment Score: 1\n",
      "292. Token: releasing, Sentiment Score: 1\n",
      "293. Token: every, Sentiment Score: 1\n",
      "294. Token: one, Sentiment Score: 1\n",
      "295. Token: american, Sentiment Score: 0\n",
      "296. Token: people, Sentiment Score: 0\n",
      "297. Token: according, Sentiment Score: 1\n",
      "298. Token: cruz, Sentiment Score: 0\n",
      "299. Token: american, Sentiment Score: 0\n",
      "300. Token: public, Sentiment Score: -1\n",
      "301. Token: privy, Sentiment Score: 1\n",
      "302. Token: learning, Sentiment Score: 1\n",
      "303. Token: whether, Sentiment Score: 0\n",
      "304. Token: presidential, Sentiment Score: -1\n",
      "305. Token: family, Sentiment Score: 0\n",
      "306. Token: guilty, Sentiment Score: -1\n",
      "307. Token: fraud, Sentiment Score: -1\n",
      "308. Token: abuses, Sentiment Score: -1\n",
      "309. Token: office, Sentiment Score: 0\n",
      "310. Token: innocent, Sentiment Score: 1\n",
      "311. Token: biden, Sentiment Score: 0\n",
      "312. Token: family, Sentiment Score: 0\n",
      "313. Token: received, Sentiment Score: 1\n",
      "314. Token: 1m, Sentiment Score: 0\n",
      "315. Token: hunter, Sentiment Score: -1\n",
      "316. Token: associate, Sentiment Score: -1\n",
      "317. Token: 2017, Sentiment Score: 0\n",
      "318. Token: china, Sentiment Score: 1\n",
      "319. Token: wire, Sentiment Score: 0\n",
      "320. Token: house, Sentiment Score: 0\n",
      "321. Token: oversight, Sentiment Score: -1\n",
      "322. Token: texas, Sentiment Score: 0\n",
      "323. Token: republican, Sentiment Score: 0\n",
      "324. Token: said, Sentiment Score: 1\n",
      "325. Token: biden, Sentiment Score: 0\n",
      "326. Token: administration, Sentiment Score: 1\n",
      "327. Token: let, Sentiment Score: -1\n",
      "328. Token: american, Sentiment Score: 0\n",
      "329. Token: people, Sentiment Score: 0\n",
      "330. Token: decide, Sentiment Score: 0\n",
      "331. Token: criminal, Sentiment Score: -1\n",
      "332. Token: activity, Sentiment Score: 1\n",
      "333. Token: conducted, Sentiment Score: 1\n",
      "334. Token: added, Sentiment Score: 1\n",
      "335. Token: benign, Sentiment Score: 1\n",
      "336. Token: release, Sentiment Score: 1\n",
      "337. Token: reports, Sentiment Score: 1\n",
      "338. Token: secretary, Sentiment Score: 0\n",
      "339. Token: yellen, Sentiment Score: 0\n",
      "340. Token: release, Sentiment Score: 1\n",
      "341. Token: every, Sentiment Score: 1\n",
      "342. Token: single, Sentiment Score: -1\n",
      "343. Token: suspicious, Sentiment Score: -1\n",
      "344. Token: activity, Sentiment Score: 1\n",
      "345. Token: report, Sentiment Score: 1\n",
      "346. Token: biden, Sentiment Score: 0\n",
      "347. Token: family, Sentiment Score: 0\n",
      "348. Token: cruz, Sentiment Score: 0\n",
      "349. Token: said, Sentiment Score: 1\n",
      "350. Token: continued, Sentiment Score: -1\n",
      "351. Token: release, Sentiment Score: 1\n",
      "352. Token: reports, Sentiment Score: 1\n",
      "353. Token: complicit, Sentiment Score: 0\n",
      "354. Token: letter, Sentiment Score: 0\n",
      "355. Token: dated, Sentiment Score: -1\n",
      "356. Token: april, Sentiment Score: 0\n",
      "357. Token: 19, Sentiment Score: 0\n",
      "358. Token: 2023, Sentiment Score: 0\n",
      "359. Token: attorney, Sentiment Score: 0\n",
      "360. Token: mark, Sentiment Score: 1\n",
      "361. Token: lytle, Sentiment Score: 0\n",
      "362. Token: told, Sentiment Score: 1\n",
      "363. Token: members, Sentiment Score: 0\n",
      "364. Token: congress, Sentiment Score: 0\n",
      "365. Token: client, Sentiment Score: 0\n",
      "366. Token: overseeing, Sentiment Score: 0\n",
      "367. Token: ongoing, Sentiment Score: 0\n",
      "368. Token: sensitive, Sentiment Score: -1\n",
      "369. Token: investigation, Sentiment Score: 1\n",
      "370. Token: controversial, Sentiment Score: 1\n",
      "371. Token: subject, Sentiment Score: -1\n",
      "372. Token: since, Sentiment Score: 0\n",
      "373. Token: early, Sentiment Score: 1\n",
      "374. Token: 2020, Sentiment Score: 0\n",
      "375. Token: would, Sentiment Score: 0\n",
      "376. Token: like, Sentiment Score: 1\n",
      "377. Token: make, Sentiment Score: 1\n",
      "378. Token: protected, Sentiment Score: -1\n",
      "379. Token: whistleblower, Sentiment Score: 0\n",
      "380. Token: disclosures, Sentiment Score: 0\n",
      "381. Token: congress, Sentiment Score: 0\n",
      "382. Token: client, Sentiment Score: 0\n",
      "383. Token: allegedly, Sentiment Score: 0\n",
      "384. Token: aware, Sentiment Score: 1\n",
      "385. Token: facts, Sentiment Score: 1\n",
      "386. Token: case, Sentiment Score: 1\n",
      "387. Token: contradict, Sentiment Score: -1\n",
      "388. Token: sworn, Sentiment Score: 1\n",
      "389. Token: testimony, Sentiment Score: 1\n",
      "390. Token: congress, Sentiment Score: 0\n",
      "391. Token: senior, Sentiment Score: 1\n",
      "392. Token: political, Sentiment Score: 0\n",
      "393. Token: appointee, Sentiment Score: 0\n",
      "394. Token: click, Sentiment Score: 1\n",
      "395. Token: get, Sentiment Score: 1\n",
      "396. Token: fox, Sentiment Score: -1\n",
      "397. Token: news, Sentiment Score: 1\n",
      "398. Token: app, Sentiment Score: 0\n",
      "399. Token: lytle, Sentiment Score: 0\n",
      "400. Token: works, Sentiment Score: 1\n",
      "401. Token: washington, Sentiment Score: 0\n",
      "402. Token: law, Sentiment Score: 1\n",
      "403. Token: firm, Sentiment Score: -1\n",
      "404. Token: nixon, Sentiment Score: 0\n",
      "405. Token: peabody, Sentiment Score: 0\n",
      "406. Token: llp, Sentiment Score: 0\n",
      "407. Token: neither, Sentiment Score: -1\n",
      "408. Token: hunter, Sentiment Score: -1\n",
      "409. Token: biden, Sentiment Score: 0\n",
      "410. Token: member, Sentiment Score: 0\n",
      "411. Token: family, Sentiment Score: 0\n",
      "412. Token: charged, Sentiment Score: 1\n",
      "413. Token: crime, Sentiment Score: -1\n",
      "414. Token: relating, Sentiment Score: 1\n",
      "415. Token: sars, Sentiment Score: -1\n",
      "416. Token: fox, Sentiment Score: -1\n",
      "417. Token: news, Sentiment Score: 1\n",
      "418. Token: patrick, Sentiment Score: 0\n",
      "419. Token: ward, Sentiment Score: -1\n",
      "420. Token: greg, Sentiment Score: 0\n",
      "421. Token: wehner, Sentiment Score: 0\n",
      "422. Token: contributed, Sentiment Score: 1\n",
      "423. Token: report, Sentiment Score: 1\n",
      "\n",
      "Stemmed text:\n",
      "republican respond after ir whistleblow say hunter biden investig is be mishandl member of congress are call for more transpar from the biden administr after an ir whistleblow said an investig into hunter biden is be mishandl .\n",
      "lawmak on capitol hill are call for the biden administr to be held account for `` block '' congress and the public from learn more about biden famili member ’ busi deal with china .\n",
      "the congression outcri come as a whistleblow within the intern revenu servic alleg an investig into hunter biden is be mishandl by the biden administr .\n",
      "the whistleblow also alleg `` clear conflict of interest '' in the investig .\n",
      "`` it ’ s deepli concern that the biden administr may be obstruct justic by block effort to charg hunter biden for tax violat , '' hous committe on oversight and account chairman jame comer told fox new on wednesday .\n",
      "comer , r-ky. , also said `` decept , shadi busi scheme '' have allow the biden to make `` million from foreign adversari like china . ''\n",
      "hunter biden investig be mishandl , 'clear conflict of interest ' : ir whistleblow '' the hous committe on oversight and account ha been follow the biden ’ tangl web of complex corpor and financi record .\n",
      "it ’ s clear from our investig that hunter and other member of the biden famili engag in decept , shadi busi scheme to avoid scrutini as they made million from foreign adversari like china , '' he said .\n",
      "`` we ’ ve been wonder all along where the heck the doj and the ir have been .\n",
      "now it appear the biden administr may have been work overtim to prevent the biden from face ani consequ . ''\n",
      "comer ad , `` the hous oversight committe will work to hold account anyon in the biden administr who may be cover up thi crimin activ .\n",
      "the oversight committe will also continu to pursu our investig into the biden famili ’ s busi scheme to determin if presid biden and our nation secur are compromis .\n",
      "american demand answer , transpar , and account . ''\n",
      "presid biden ’ s son hunter ha been under feder investig sinc 2018 .\n",
      "the investig concern the presenc of suspici activ report ( sar ) regard suspici foreign transact .\n",
      "it is be led by delawar u.s. attorney david weiss .\n",
      "across congress , sen. ted cruz on wednesday call for treasuri secretari janet yellen to publicli releas the sar found among the biden famili ’ s tax record .\n",
      "`` there ’ s no nation secur reason to keep them privat , '' cruz , r-texa , said dure an episod of hi podcast .\n",
      "`` there ’ s no reason whatsoev other than if you want to be part of a polit cover-up . ''\n",
      "six addit biden famili member ‘ may have benefit ’ from hunter busi deal sar alon do not indic wrongdo or crimin activ but could be an indic of such behavior .\n",
      "`` the u.s. depart of treasuri need to releas everi singl suspici activ report on the biden famili , '' cruz said on wednesday .\n",
      "`` janet yellen , you have a choic : you are either activ cover up potenti evid of corrupt or releas everi one of them to the american peopl . ''\n",
      "accord to cruz , the american public should be privi to learn whether the presidenti famili is guilti of fraud or other abus of offic — or if he is innoc .\n",
      "biden famili receiv more than $ 1m from hunter associ after 2017 china wire : hous oversight the texa republican said the biden administr should `` let the american peopl decid '' if crimin activ wa conduct .\n",
      "he ad , `` if thi is benign , releas the report . ''\n",
      "`` secretari yellen , releas everi singl suspici activ report on the biden famili , '' cruz said .\n",
      "he continu .\n",
      "`` if she doesn ’ t releas those report , she is complicit in the cover-up . ''\n",
      "in a letter date april 19 , 2023 , attorney mark d. lytl told member of congress that a client of hi ha been overse the `` ongo and sensit investig of a high-profil , controversi subject sinc earli 2020 and would like to make protect whistleblow disclosur to congress . ''\n",
      "and that the client is allegedli awar of fact of the case that `` contradict sworn testimoni to congress by a senior polit appointe . ''\n",
      "click here to get the fox new app lytl work for the washington , d.c. , -base law firm nixon peabodi llp .\n",
      "neither hunter biden nor ani member of hi famili ha been charg with a crime relat to the sar .\n",
      "fox new ' patrick ward , greg wehner contribut to thi report .\n"
     ]
    }
   ],
   "source": [
    "# Call the function to preprocess the article\n",
    "results = preprocess_article(url)\n",
    "\n",
    "# Print the information for each sentence\n",
    "for i, sentence in enumerate(results['filtered_sentences']):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")\n",
    "    print(f\"Total words: {results['num_words_per_sentence'][i]}\")\n",
    "    print(f\"Filtered words: {sentence.split()}\")\n",
    "    print(f\"Number of filtered words: {len(sentence.split())}\")\n",
    "    print(f\"Stop words: {results['stop_words_per_sentence'][i]}\")\n",
    "    print(f\"Number of stop words: {results['num_stop_words_per_sentence'][i]}\")\n",
    "    print(f\"Average number of stop words per sentence: {round(results['avg_stop_words_per_sentence'][i], 2)}\")\n",
    "    print(f\"Sentiment score: {results['sentiment_scores'][i]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the general statistics on stop words\n",
    "print(f\"Total number of words: {results['total_words']}\")\n",
    "print(f\"Total number of stop words: {results['num_stop_words']}\")\n",
    "print(f\"Maximum number of stop words per sentence: {results['max_stop_words_per_sentence']}\")\n",
    "print(f\"Minimum number of stop words per sentence: {results['min_stop_words_per_sentence']}\")\n",
    "print(f\"Average number of stop words per article: {round(results['avg_stop_words_per_sentence_avg'], 2)}\")\n",
    "print()\n",
    "print(f\"Average of sentiment score for all sentences: {sum(results['sentiment_scores']) / len(results['sentiment_scores'])}\")\n",
    "print(f\"Maximum sentiment score: {max(results['sentiment_scores'])}\")\n",
    "print(f\"Minimum sentiment score: {min(results['sentiment_scores'])}\")\n",
    "print(f\"Standard deviation: {statistics.stdev(results['sentiment_scores'])}\")\n",
    "print()\n",
    "print(f\"Vader average scores: {results['v_avg_scores']}\")\n",
    "print(f\"Vader maximum scores: {results['v_max_scores']}\")\n",
    "print(f\"Vader minimum scores: {results['v_min_scores']}\")\n",
    "print(f\"Vader standard deviation scores: {results['v_std_scores']}\")\n",
    "print()\n",
    "print(f\"MPQA average scores: {results['mpqa_avg_score']}\")\n",
    "print(f\"MPQA maximum scores: {results['mpqa_max_score']}\")\n",
    "print(f\"MPQA minimum scores: {results['mpqa_min_score']}\")\n",
    "print(f\"MPQA standard deviation scores: {results['mpqa_sd_score']}\")\n",
    "\n",
    "print()\n",
    "for i, token in enumerate(results['tokens']):\n",
    "        print(f\"{i+1}. Token: {token}, Sentiment Score: {results['sentiwordnet_scores'][i]}\")\n",
    "\n",
    "print()\n",
    "print(\"Stemmed text:\")\n",
    "print(f\"{results['output_text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Pre-processing Text Article, and saving the score in a txt file for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b29fb8692b4e9c92a5e2c79e305350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 17:52:29 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-04-30 17:52:30 INFO: File exists: /home/pierluigi/stanza_resources/en/default.zip\n",
      "2023-04-30 17:52:36 INFO: Finished downloading models and saved to /home/pierluigi/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')  # Download the English model\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "import spacy\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import newspaper\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 17:52:37 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63119d00820b48219913771f42155e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 17:52:38 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-04-30 17:52:38 INFO: Using device: cpu\n",
      "2023-04-30 17:52:38 INFO: Loading: tokenize\n",
      "2023-04-30 17:52:38 INFO: Loading: sentiment\n",
      "2023-04-30 17:52:38 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Setting the use_gpu=False, it uses the CPU instead of the GPU for calculating stuff, and also for printing the results. And it couldn't run out of memory.\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=False, max_split_size_mb=15, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MPQA lexicon\n",
    "lexicon = pd.read_csv(\"/home/pierluigi/Documents/echo_chambers_intership/Code analysis/NLP/Single modules/subjclueslen1-HLTEMNLP05.tff\", sep=\" \", header=None, \n",
    "                      names=[\"type\", \"len\", \"word\", \"pos\", \"stemmed\", \"polarity\", \"strength\"])\n",
    "\n",
    "lexicon[\"type\"] = lexicon[\"type\"].str[5:]\n",
    "lexicon[\"word\"] = lexicon[\"word\"].str[len(\"word1=\"):]\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].str[len(\"priorpolarity=\"):]\n",
    "cols_to_remove = [\"len\", \"pos\", \"stemmed\", \"strength\"]\n",
    "lexicon = lexicon.drop(columns=cols_to_remove)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"weaksubj\", 1)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"strongsubj\", 2)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"negative\", -1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"positive\", 1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"both\", 0)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"neutral\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article(url):\n",
    "    # Create a newspaper Article object\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    # Download and parse the article\n",
    "    article.download()\n",
    "    article.parse()\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title = article.title.strip()\n",
    "    subtitle = article.meta_data.get(\"description\", \"\").strip()\n",
    "    description = article.meta_description.strip()\n",
    "    text = article.text.strip()\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{text}\"\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(article_text)\n",
    "    \n",
    "    # Identify the stop words for each sentence\n",
    "    num_stop_words_per_sentence = []\n",
    "    stop_words_per_sentence = []\n",
    "    filtered_sentences = []\n",
    "    filtered_words = []\n",
    "    num_words_per_sentence = []\n",
    "    avg_stop_words_per_sentence = []\n",
    "    total_words = 0\n",
    "\n",
    "    # Create a Porter stemmer object\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_sentences = []\n",
    "\n",
    "    # Process the text with the pipeline and extract the sentiment for each sentence\n",
    "    doc = nlp(text)\n",
    "    s_sentiment_scores = []\n",
    "\n",
    "    # initialize the Vader sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    v_scores_list = []\n",
    "\n",
    "    # MPQA analysis\n",
    "    mpqa_scores = []\n",
    "\n",
    "    # POS tagging adjectives\n",
    "    total_adjectives = 0\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        all_words = len(words)\n",
    "        total_words += all_words\n",
    "        \n",
    "        # Identify the stop words in the sentence\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words_found = [word for word in words if word.lower() in stop_words]\n",
    "        all_stop_words = len(stop_words_found)\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        \n",
    "        # Add the number of stop words and filtered sentence to the output\n",
    "        num_stop_words = all_words - len(filtered_words)\n",
    "        num_stop_words_per_sentence.append(num_stop_words)\n",
    "        stop_words_per_sentence.append(stop_words_found)\n",
    "        filtered_sentences.append(\" \".join(filtered_words))\n",
    "        num_words_per_sentence.append(all_words)\n",
    "        \n",
    "        # Calculate the average number of stop words per sentence\n",
    "        avg_stop_words_per_sentence.append(num_stop_words / all_words)\n",
    "\n",
    "        # Perform stemming on each word using the Porter stemmer\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "        # Combine the stemmed words back into a single string\n",
    "        stemmed_sentence = ' '.join(stemmed_words)\n",
    "        stemmed_sentences.append(stemmed_sentence)\n",
    "\n",
    "        v_scores = analyzer.polarity_scores(sentence)\n",
    "        v_score_list = [v_scores['neg'], v_scores['neu'], v_scores['pos']]\n",
    "        v_scores_list.append(v_score_list)\n",
    "\n",
    "        #POS tagging calculations\n",
    "        tagged_words = pos_tag(words)\n",
    "        num_adjectives = len([word for word, tag in tagged_words if tag.startswith('JJ')])\n",
    "        total_adjectives += num_adjectives\n",
    "\n",
    "    # Sentiment analysis using Stanza library\n",
    "    for sentence in doc.sentences:\n",
    "        s_sentiment_scores.append(sentence.sentiment)\n",
    "\n",
    "    # Sentiwordnet scores\n",
    "    sentiwordnet_final_score = 0\n",
    "    \n",
    "    # Loop through each word in the text\n",
    "    sentiment_score = 0\n",
    "    num_synsets = 0\n",
    "\n",
    "    for word in article_text.split():\n",
    "        word = word.strip().lower()\n",
    "        if word in lexicon.word.tolist():\n",
    "            polarity = lexicon[lexicon.word == word].polarity.values[0]\n",
    "            mpqa_scores.append(polarity)\n",
    "        \n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) > 0:\n",
    "            synset = synsets[0]\n",
    "            senti_synset = swn.senti_synset(synset.name())\n",
    "            sentiment_score += senti_synset.pos_score() - senti_synset.neg_score()\n",
    "            num_synsets += 1\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    num_stop_words = sum(num_stop_words_per_sentence)\n",
    "    num_sentences = len(sentences)\n",
    "    avg_stop_words_per_sentence_all = num_stop_words / num_sentences\n",
    "    max_stop_words_per_sentence = max(num_stop_words_per_sentence)\n",
    "    min_stop_words_per_sentence = min(num_stop_words_per_sentence)\n",
    "    avg_stop_words_per_word = num_stop_words / total_words\n",
    "    \n",
    "    # Calculate the average number of stop words per article\n",
    "    avg_stop_words_per_sentence_avg = sum(avg_stop_words_per_sentence) / len(avg_stop_words_per_sentence)\n",
    "    \n",
    "    # Vader scores\n",
    "    v_scores_array = np.array(v_scores_list)\n",
    "    v_avg_scores = np.mean(v_scores_array, axis=0)\n",
    "    v_max_scores = np.max(v_scores_array, axis=0)\n",
    "    v_min_scores = np.min(v_scores_array, axis=0)\n",
    "    v_std_scores = np.std(v_scores_array, axis=0)\n",
    "\n",
    "    # MPQA scores\n",
    "    mpqa_avg_score = np.mean(mpqa_scores)\n",
    "    mpqa_max_score = np.max(mpqa_scores)\n",
    "    mpqa_min_score = np.min(mpqa_scores)\n",
    "    mpqa_sd_score = np.std(mpqa_scores)\n",
    "\n",
    "    # Calculate final score        \n",
    "    if num_synsets > 0:\n",
    "        sentiwordnet_final_score = sentiment_score / num_synsets\n",
    "    else:\n",
    "        sentiwordnet_final_score = 0\n",
    "\n",
    "    # Determine the readability of the text article\n",
    "    read = Readability(article_text)\n",
    "\n",
    "    # Flesch Kincaid Grade Level\n",
    "    flesch_kincaid = read.flesch_kincaid()\n",
    "\n",
    "    # Flesch Reading Ease\n",
    "    flesch_reading = read.flesch()\n",
    "\n",
    "    # Dale Chall Readability\n",
    "    dale_chall = read.dale_chall()\n",
    "\n",
    "    # Automated Readability Index (ARI)\n",
    "    ari = read.ari()\n",
    "\n",
    "    # Coleman Liau Index\n",
    "    coleman_liau = read.coleman_liau()\n",
    "\n",
    "    # Gunning Fog\n",
    "    gunning_fog = read.gunning_fog()\n",
    "\n",
    "    # SMOG: at least 30 sentences required. Uncomment if needed.\n",
    "    #smog = read.smog()\n",
    "\n",
    "    # SPACHE\n",
    "    spache = read.spache()\n",
    "\n",
    "    # Linsear Write\n",
    "    linsear_write = read.linsear_write()\n",
    "\n",
    "    # POS tagging \n",
    "    avg_adjectives = total_adjectives / total_words\n",
    "\n",
    "    # Gensim-LDA analysis\n",
    "    bigrams = list(nltk.bigrams(filtered_words))\n",
    "    lemmatized_bigrams = []\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        lemma1 = lemmatizer.lemmatize(bigram[0])\n",
    "        lemma2 = lemmatizer.lemmatize(bigram[1])\n",
    "        lemmatized_bigrams.append([lemma1, lemma2])\n",
    "    \n",
    "    # Create Dictionary \n",
    "    id2word = corpora.Dictionary(lemmatized_bigrams) \n",
    "\n",
    "    # Create Corpus \n",
    "    texts = lemmatized_bigrams\n",
    "\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    doc_lda = lda_model[corpus]\n",
    "\n",
    "    # Compute perplexity\n",
    "    perplexity_lda = lda_model.log_perplexity(corpus)\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts = lemmatized_bigrams, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "    # Visualize the topics\n",
    "    #pyLDAvis.enable_notebook(local=True)\n",
    "    #vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    # pyLDAvis.display(vis)\n",
    "    #pyLDAvis.save_html(vis, 'lda_f{title}plot.html')\n",
    "\n",
    "    # Return the output\n",
    "    return {\n",
    "        'title': title,\n",
    "        'num_stop_words': num_stop_words,\n",
    "        'total_words': total_words,\n",
    "        'stop_words_found': stop_words_found,\n",
    "        'all_stop_words': all_stop_words,\n",
    "        'avg_stop_words_per_sentence_all': avg_stop_words_per_sentence_all,\n",
    "        'max_stop_words_per_sentence': max_stop_words_per_sentence,\n",
    "        'min_stop_words_per_sentence': min_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_word': avg_stop_words_per_word,\n",
    "        'avg_stop_words_per_sentence': avg_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_sentence_avg': avg_stop_words_per_sentence_avg,\n",
    "        'filtered_sentences': filtered_sentences,\n",
    "        'stop_words_per_sentence': stop_words_per_sentence,\n",
    "        'num_words_per_sentence': num_words_per_sentence,\n",
    "        'num_stop_words_per_sentence': num_stop_words_per_sentence,\n",
    "        's_sentiment_scores': s_sentiment_scores,\n",
    "        'v_avg_scores': v_avg_scores,\n",
    "        'v_max_scores': v_max_scores,\n",
    "        'v_min_scores': v_min_scores,\n",
    "        'v_std_scores': v_std_scores,\n",
    "        'mpqa_avg_score': mpqa_avg_score,\n",
    "        'mpqa_max_score': mpqa_max_score,\n",
    "        'mpqa_min_score': mpqa_min_score,\n",
    "        'mpqa_sd_score': mpqa_sd_score,\n",
    "        'sentiwordnet_final_score': sentiwordnet_final_score,\n",
    "        'flesch_kincaid_score': flesch_kincaid.score,\n",
    "        'flesch_kincaid_grade_level': flesch_kincaid.grade_level,\n",
    "        'flesch_reading_score': flesch_reading.score,\n",
    "        'flesch_reading_ease': flesch_reading.ease,\n",
    "        'dale_chall_score': dale_chall.score,\n",
    "        'dale_chall_grade_levels': dale_chall.grade_levels,\n",
    "        'ari_score': ari.score,\n",
    "        'ari_grade_level': ari.grade_levels,\n",
    "        'ari_ages': ari.ages,\n",
    "        'coleman_liau_score': coleman_liau.score,\n",
    "        'coleman_liau_grade_level': coleman_liau.grade_level,\n",
    "        'gunning_fog_score': gunning_fog.score,\n",
    "        'gunning_fog_grade_level': gunning_fog.grade_level,\n",
    "        #'smog_score': smog.score,\n",
    "        #'smog_grade_level': smog.grade_level,\n",
    "        'spache_score': spache.score,\n",
    "        'spache_grade_level': spache.grade_level,\n",
    "        'linsear_write_score': linsear_write.score,\n",
    "        'linsear_write_grade_level': linsear_write.grade_level,\n",
    "        'total_adjectives': total_adjectives,\n",
    "        'avg_adjectives': avg_adjectives,\n",
    "        'lda_model': lda_model,\n",
    "        'perplexity_lda': perplexity_lda,\n",
    "        'coherence_lda': coherence_lda,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_articles(urls, directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    for url in urls:\n",
    "        results = preprocess_article(url)\n",
    "        # Write preprocessed article to a separate file for each URL\n",
    "        file_path = f'{directory}/{results[\"title\"]}.txt'\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            # Save the information for each sentence to the file\n",
    "            for i, sentence in enumerate(results['filtered_sentences']):\n",
    "                f.write(f\"Sentence {i+1}: {sentence}\\n\")\n",
    "                f.write(f\"Total words: {results['num_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Filtered words: {sentence.split()}\\n\")\n",
    "                f.write(f\"Number of filtered words: {len(sentence.split())}\\n\")\n",
    "                f.write(f\"Stop words: {results['stop_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Number of stop words: {results['num_stop_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Average number of stop words per sentence: {round(results['avg_stop_words_per_sentence'][i], 2)}\\n\")\n",
    "                f.write(f\"Sentiment score: {results['s_sentiment_scores'][i]}\\n\\n\")\n",
    "\n",
    "            # Save the general statistics on stop words to the file\n",
    "            f.write(f\"Total number of words: {results['total_words']}\\n\")\n",
    "            f.write(f\"Total number of stop words: {results['num_stop_words']}\\n\")\n",
    "            f.write(f\"Maximum number of stop words per sentence: {results['max_stop_words_per_sentence']}\\n\")\n",
    "            f.write(f\"Minimum number of stop words per sentence: {results['min_stop_words_per_sentence']}\\n\")\n",
    "            f.write(f\"Average number of stop words per article: {round(results['avg_stop_words_per_sentence_avg'], 2)}\\n\")\n",
    "\n",
    "            # Print POS tagging operations\n",
    "            f.write(f\"Total adjectives: {results['total_adjectives']}\\n\")\n",
    "            f.write(f\"Average number of adjectives in the article: {results['avg_adjectives']:.2f}\\n\\n\")\n",
    "            \n",
    "            # Stanza sentiment scores\n",
    "            f.write(f\"Stanza Average of sentiment score for all sentences: {sum(results['s_sentiment_scores']) / len(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Maximum sentiment score: {max(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Minimum sentiment score: {min(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Standard deviation: {statistics.stdev(results['s_sentiment_scores'])}\\n\\n\")\n",
    "\n",
    "            # Vader sentiment scores\n",
    "            f.write(f\"Vader average scores: {results['v_avg_scores']}\\n\")\n",
    "            f.write(f\"Vader maximum scores: {results['v_max_scores']}\\n\")\n",
    "            f.write(f\"Vader minimum scores: {results['v_min_scores']}\\n\")\n",
    "            f.write(f\"Vader standard deviation scores: {results['v_std_scores']}\\n\\n\")\n",
    "\n",
    "            # MPQA sentiment scores\n",
    "            f.write(f\"MPQA average scores: {results['mpqa_avg_score']}\\n\")\n",
    "            f.write(f\"MPQA maximum scores: {results['mpqa_max_score']}\\n\")\n",
    "            f.write(f\"MPQA minimum scores: {results['mpqa_min_score']}\\n\")\n",
    "            f.write(f\"MPQA standard deviation scores: {results['mpqa_sd_score']}\\n\\n\")\n",
    "\n",
    "            # Sentiword sentiment scores\n",
    "            f.write(f\"Sentiwordnet score: {results['sentiwordnet_final_score']} (from -1 to 1, and score of 0 indicates a neutral sentiment.)\\n\\n\")\n",
    "            \n",
    "            # Flesch_Kincaid scores\n",
    "            f.write(f\"Flesch-Kincaid score: {results['flesch_kincaid_score']}\\n\")\n",
    "            f.write(f\"The estimated reading level of the article is: {results['flesch_kincaid_grade_level']}\\n\\n\") \n",
    "\n",
    "            # Flesch Reading ease scores\n",
    "            f.write(f\"Flesch Reading Ease score: {results['flesch_reading_score']}\\n\")\n",
    "            f.write(f\"The article is classified as: {results['flesch_reading_ease']}\\n\\n\")\n",
    "\n",
    "            # Print the Dale-Chall scores\n",
    "            f.write(f\"Dale-Chall Readability score: {results['dale_chall_score']}\\n\")\n",
    "            # Print the estimated grade levels for comprehension\n",
    "            f.write(f\"The estimated comprehension level for different grade levels is: {results['dale_chall_grade_levels']}\\n\\n\")\n",
    "\n",
    "            # Print the ARI scores\n",
    "            f.write(f\"Automated Readability Index (ARI) score: {results['ari_score']}, which corresponds to a grade level of {results['ari_grade_level']}.\\n\")\n",
    "            f.write(f\"This means that the text can be read by someone who is around {results['ari_ages']} years old.\\n\\n\")\n",
    "\n",
    "            # Print the Coleman-Liau scores\n",
    "            f.write(f\"Coleman-Liau Index Score: {results['coleman_liau_score']}\\n\")\n",
    "            f.write(f\"Estimated Grade Level: {results['coleman_liau_grade_level']}\\n\\n\")\n",
    "\n",
    "            # Print the Gunning Fog scores\n",
    "            f.write(f\"Gunning Fog score: {results['gunning_fog_score']}\\n\")\n",
    "            f.write(f\"The estimated grade level for comprehension is: {results['gunning_fog_grade_level']}\\n\\n\")\n",
    "\n",
    "            # Print the SMOG scores\n",
    "            #f.write(f\"SMOG score: {results['smog_score']}. This corresponds to a grade level of {results['smog_grade_level']}.\")\n",
    "            \n",
    "            # Print the SPACHE scores\n",
    "            f.write(f\"SPACHE score: {results['spache_score']}\\n\")\n",
    "            f.write(f\"This corresponds to a grade level of {results['spache_grade_level']}.\\n\\n\")\n",
    "\n",
    "            # Print the Linsear Write Index scores\n",
    "            f.write(f\"Linsear Write Index score: {results['linsear_write_score']}\\n\")\n",
    "            f.write(\"Approximate grade level equivalent: {}\\n\\n\".format(results['linsear_write_grade_level']))\n",
    "\n",
    "            # Gensim-LDA analysis\n",
    "            f.write(f\"Perplexity (how well the LDA model predicts the corpus) of the article: {results['perplexity_lda']}\\n\")\n",
    "            f.write(f\"Coherence (how coherent the topics are) of the article: {results['coherence_lda']}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m urls \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mhttps://www.foxnews.com/politics/republicans-respond-after-irs-whistleblower-says-hunter-biden-investigation-being-mishandled\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://news.yahoo.com/alabama-education-director-ousted-over-234450832.html\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://news.yahoo.com/samantha-cameron-remind-david-steer-050000235.html\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m preprocess_articles(urls, directory\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpreprocessed articles\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m, in \u001b[0;36mpreprocess_articles\u001b[0;34m(urls, directory)\u001b[0m\n\u001b[1;32m      8\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     11\u001b[0m     \u001b[39m# Save the information for each sentence to the file\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mfor\u001b[39;00m i, (sentence, length) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(results[\u001b[39m'\u001b[39m\u001b[39mfiltered_sentences\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     13\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSentence \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00msentence\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal words: \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m'\u001b[39m\u001b[39mnum_words_per_sentence\u001b[39m\u001b[39m'\u001b[39m][i]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "urls = ['https://www.foxnews.com/politics/republicans-respond-after-irs-whistleblower-says-hunter-biden-investigation-being-mishandled',\n",
    "        'https://news.yahoo.com/alabama-education-director-ousted-over-234450832.html',\n",
    "        'https://news.yahoo.com/samantha-cameron-remind-david-steer-050000235.html']\n",
    "\n",
    "preprocess_articles(urls, directory='preprocessed articles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Pre-processing Text Article, and saving the score in a txt file for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ff03dec20941c6b1a555ff817b3a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 17:21:50 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-05-03 17:21:52 INFO: File exists: /home/pierluigi/stanza_resources/en/default.zip\n",
      "2023-05-03 17:21:58 INFO: Finished downloading models and saved to /home/pierluigi/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')  # Download the English model\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "import spacy\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "import newspaper\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 17:21:58 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38524bc08aff48538aa6126d7c9766f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 17:21:59 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-05-03 17:21:59 INFO: Using device: cpu\n",
      "2023-05-03 17:21:59 INFO: Loading: tokenize\n",
      "2023-05-03 17:21:59 INFO: Loading: sentiment\n",
      "2023-05-03 17:22:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Setting the use_gpu=False, it uses the CPU instead of the GPU for calculating stuff, and also for printing the results. And it couldn't run out of memory.\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=False, max_split_size_mb=15, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MPQA lexicon\n",
    "lexicon = pd.read_csv(\"/home/pierluigi/Documents/echo_chambers_intership/Code analysis/NLP/Single modules/subjclueslen1-HLTEMNLP05.tff\", sep=\" \", header=None, \n",
    "                      names=[\"type\", \"len\", \"word\", \"pos\", \"stemmed\", \"polarity\", \"strength\"])\n",
    "\n",
    "lexicon[\"type\"] = lexicon[\"type\"].str[5:]\n",
    "lexicon[\"word\"] = lexicon[\"word\"].str[len(\"word1=\"):]\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].str[len(\"priorpolarity=\"):]\n",
    "cols_to_remove = [\"len\", \"pos\", \"stemmed\", \"strength\"]\n",
    "lexicon = lexicon.drop(columns=cols_to_remove)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"weaksubj\", 1)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"strongsubj\", 2)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"negative\", -1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"positive\", 1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"both\", 0)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"neutral\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(url):\n",
    "    # Create a newspaper Article object\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    # Download and parse the article\n",
    "    article.download()\n",
    "    article.parse()\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title = article.title.strip()\n",
    "    subtitle = article.meta_data.get(\"description\", \"\").strip()\n",
    "    description = article.meta_description.strip()\n",
    "    text = article.text.strip()\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{text}\"\n",
    "\n",
    "    # Return the concatenated string\n",
    "    return article_text, title, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(article):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    num_stop_words_per_sentence = []\n",
    "    stop_words_per_sentence = []\n",
    "    filtered_sentences = []\n",
    "    filtered_words = []\n",
    "    num_words_per_sentence = []\n",
    "    avg_stop_words_per_sentence = []\n",
    "    total_words = 0\n",
    "    total_adjectives = 0\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        all_words = len(words)\n",
    "        total_words += all_words\n",
    "        \n",
    "        # Identify the stop words in the sentence\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words_found = [word for word in words if word.lower() in stop_words]\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        \n",
    "        # Add the number of stop words and filtered sentence to the output\n",
    "        num_stop_words = all_words - len(filtered_words)\n",
    "        num_stop_words_per_sentence.append(num_stop_words)\n",
    "        stop_words_per_sentence.append(stop_words_found)\n",
    "        filtered_sentences.append(\" \".join(filtered_words))\n",
    "        num_words_per_sentence.append(all_words)\n",
    "        \n",
    "        # Calculate the average number of stop words per sentence\n",
    "        avg_stop_words_per_sentence.append(num_stop_words / all_words)\n",
    "\n",
    "        #POS tagging calculations\n",
    "        tagged_words = pos_tag(words)\n",
    "        num_adjectives = len([word for word, tag in tagged_words if tag.startswith('JJ')])\n",
    "        total_adjectives += num_adjectives\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    num_stop_words = sum(num_stop_words_per_sentence)\n",
    "    max_stop_words_per_sentence = max(num_stop_words_per_sentence)\n",
    "    min_stop_words_per_sentence = min(num_stop_words_per_sentence)\n",
    "    \n",
    "    # Calculate the average number of stop words per article\n",
    "    avg_stop_words_per_sentence_avg = sum(avg_stop_words_per_sentence) / len(avg_stop_words_per_sentence)\n",
    "    \n",
    "    # POS tagging \n",
    "    avg_adjectives = total_adjectives / total_words\n",
    "\n",
    "    return sentences, filtered_words, filtered_sentences, stop_words_per_sentence, num_stop_words_per_sentence, avg_stop_words_per_sentence, total_words, num_stop_words, max_stop_words_per_sentence, min_stop_words_per_sentence, avg_stop_words_per_sentence_avg, num_words_per_sentence, total_adjectives, avg_adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_sentiment_analysis(text):\n",
    "    doc = nlp(text)\n",
    "    s_sentiment_scores = []\n",
    "\n",
    "    # Sentiment analysis using Stanza library\n",
    "    for sentence in doc.sentences:\n",
    "        s_sentiment_scores.append(sentence.sentiment)\n",
    "    \n",
    "    return s_sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_sentiment_analysis(sentences):\n",
    "    # initialize the Vader sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    v_scores_list = []\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        v_scores = analyzer.polarity_scores(sentence)\n",
    "        v_score_list = [v_scores['neg'], v_scores['neu'], v_scores['pos']]\n",
    "        v_scores_list.append(v_score_list)\n",
    "    \n",
    "    # Vader scores\n",
    "    v_scores_array = np.array(v_scores_list)\n",
    "    v_avg_scores = np.mean(v_scores_array, axis=0)\n",
    "    v_max_scores = np.max(v_scores_array, axis=0)\n",
    "    v_min_scores = np.min(v_scores_array, axis=0)\n",
    "    v_std_scores = np.std(v_scores_array, axis=0)\n",
    "\n",
    "    return v_avg_scores, v_max_scores, v_min_scores, v_std_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpqa_sentiment_analysis(article):\n",
    "    mpqa_scores = []\n",
    "\n",
    "    for word in article.split():\n",
    "        word = word.strip().lower()\n",
    "        if word in lexicon.word.tolist():\n",
    "            polarity = lexicon[lexicon.word == word].polarity.values[0]\n",
    "            mpqa_scores.append(polarity)\n",
    "        \n",
    "    # MPQA scores\n",
    "    mpqa_avg_score = np.mean(mpqa_scores)\n",
    "    mpqa_max_score = np.max(mpqa_scores)\n",
    "    mpqa_min_score = np.min(mpqa_scores)\n",
    "    mpqa_sd_score = np.std(mpqa_scores)\n",
    "\n",
    "    return mpqa_avg_score, mpqa_max_score, mpqa_min_score, mpqa_sd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiwordnet_sentiment_analysis(article):\n",
    "    sentiwordnet_final_score = 0\n",
    "\n",
    "    # Loop through each word in the text\n",
    "    sentiment_score = 0\n",
    "    num_synsets = 0\n",
    "\n",
    "    for word in article.split():\n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) > 0:\n",
    "            synset = synsets[0]\n",
    "            senti_synset = swn.senti_synset(synset.name())\n",
    "            sentiment_score += senti_synset.pos_score() - senti_synset.neg_score()\n",
    "            num_synsets += 1\n",
    "    \n",
    "    # Calculate final score        \n",
    "    if num_synsets > 0:\n",
    "        sentiwordnet_final_score = sentiment_score / num_synsets\n",
    "    else:\n",
    "        sentiwordnet_final_score = 0\n",
    "    \n",
    "    return sentiwordnet_final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability_analysis(article):\n",
    "    read = Readability(article)\n",
    "    metrics = {}\n",
    "\n",
    "    # Flesch Kincaid\n",
    "    metrics['flesch_kincaid'] = read.flesch_kincaid()\n",
    "\n",
    "    # Flesch Reading Ease\n",
    "    metrics['flesch_reading'] = read.flesch()\n",
    "\n",
    "    # Dale Chall Readability\n",
    "    metrics['dale_chall'] = read.dale_chall()\n",
    "\n",
    "    # Automated Readability Index (ARI)\n",
    "    metrics['ari'] = read.ari()\n",
    "\n",
    "    # Coleman Liau Index\n",
    "    metrics['coleman_liau'] = read.coleman_liau()\n",
    "\n",
    "    # Gunning Fog\n",
    "    metrics['gunning_fog'] = read.gunning_fog()\n",
    "\n",
    "    # SMOG: at least 30 sentences required. Uncomment if needed.\n",
    "    # metrics['smog'] = read.smog()\n",
    "\n",
    "    # SPACHE\n",
    "    metrics['spache'] = read.spache()\n",
    "\n",
    "    # Linsear Write\n",
    "    metrics['linsear_write'] = read.linsear_write()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_lda_algorithm(filtered_words):\n",
    "    # Gensim-LDA analysis\n",
    "    bigrams = list(nltk.bigrams(filtered_words))\n",
    "    lemmatized_bigrams = []\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        lemma1 = lemmatizer.lemmatize(bigram[0])\n",
    "        lemma2 = lemmatizer.lemmatize(bigram[1])\n",
    "        lemmatized_bigrams.append([lemma1, lemma2])\n",
    "    \n",
    "    # Create Dictionary \n",
    "    id2word = corpora.Dictionary(lemmatized_bigrams) \n",
    "\n",
    "    # Create Corpus \n",
    "    texts = lemmatized_bigrams\n",
    "\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    doc_lda = lda_model[corpus]\n",
    "\n",
    "    # Compute perplexity\n",
    "    perplexity_lda = lda_model.log_perplexity(corpus)\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts = lemmatized_bigrams, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "    return lda_model, perplexity_lda, coherence_lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_tree(node, depth):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return max([walk_tree(child, depth + 1) for child in node.children], default=depth)\n",
    "    else:\n",
    "        return depth\n",
    "    \n",
    "def build_dependency_tree(article):\n",
    "    doc = nlp_spacy(article)\n",
    "    depths = {}\n",
    "    tree_lengths = {}\n",
    "    for sent in doc.sents:\n",
    "        root = sent.root\n",
    "        depth = walk_tree(root, 0)\n",
    "        depths[root.orth_] = depth\n",
    "        tree_lengths[sent.text.strip()] = depth\n",
    "\n",
    "    lengths = list(tree_lengths.values())\n",
    "    avg_length = sum(lengths) / len(lengths)\n",
    "    max_length = max(lengths)\n",
    "    min_length = min(lengths)\n",
    "    max_depth = max(depths.values())\n",
    "    max_depth_words = [word for word, depth in depths.items() if depth == max_depth]\n",
    "    return tree_lengths, max_depth, max_depth_words, avg_length, max_length, min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(url):\n",
    "    article, title, text =  get_article_info(url)\n",
    "    sentences, filtered_words, filtered_sentences, stop_words_per_sentence, num_stop_words_per_sentence, avg_stop_words_per_sentence, total_words, num_stop_words, max_stop_words_per_sentence, min_stop_words_per_sentence, avg_stop_words_per_sentence_avg, num_words_per_sentence, total_adjectives, avg_adjectives  = preprocess_text(article)\n",
    "    s_sentiment_scores = stanza_sentiment_analysis(text)\n",
    "    v_avg_scores, v_max_scores, v_min_scores, v_std_scores = vader_sentiment_analysis(sentences)\n",
    "    mpqa_avg_score, mpqa_max_score, mpqa_min_score, mpqa_sd_score = mpqa_sentiment_analysis(article)\n",
    "    sentiwordnet_final_score = sentiwordnet_sentiment_analysis(article)\n",
    "    metrics = readability_analysis(article)\n",
    "    lda_model, perplexity_lda, coherence_lda = gensim_lda_algorithm(filtered_words)\n",
    "    tree_lengths, max_depth, max_depth_words, avg_length, max_length, min_length = build_dependency_tree(article)\n",
    "    return {\n",
    "        'title': title,\n",
    "        'num_stop_words': num_stop_words,\n",
    "        'total_words': total_words,\n",
    "        'max_stop_words_per_sentence': max_stop_words_per_sentence,\n",
    "        'min_stop_words_per_sentence': min_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_sentence': avg_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_sentence_avg': avg_stop_words_per_sentence_avg,\n",
    "        'filtered_sentences': filtered_sentences,\n",
    "        'stop_words_per_sentence': stop_words_per_sentence,\n",
    "        'num_words_per_sentence': num_words_per_sentence,\n",
    "        'num_stop_words_per_sentence': num_stop_words_per_sentence,\n",
    "        'total_adjectives': total_adjectives,\n",
    "        'avg_adjectives': avg_adjectives,\n",
    "        's_sentiment_scores': s_sentiment_scores,\n",
    "        'v_avg_scores': v_avg_scores,\n",
    "        'v_max_scores': v_max_scores,\n",
    "        'v_min_scores': v_min_scores,\n",
    "        'v_std_scores': v_std_scores,\n",
    "        'mpqa_avg_score': mpqa_avg_score,\n",
    "        'mpqa_max_score': mpqa_max_score,\n",
    "        'mpqa_min_score': mpqa_min_score,\n",
    "        'mpqa_sd_score': mpqa_sd_score,\n",
    "        'sentiwordnet_final_score': sentiwordnet_final_score,\n",
    "        'metrics': metrics,\n",
    "        'lda_model': lda_model,\n",
    "        'perplexity_lda': perplexity_lda,\n",
    "        'coherence_lda': coherence_lda,\n",
    "        'tree_lengths': tree_lengths,\n",
    "        'max_depth': max_depth,\n",
    "        'max_depth_words': max_depth_words,\n",
    "        'avg_length': avg_length,\n",
    "        'max_length': max_length,\n",
    "        'min_length': min_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_old(urls, directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        results = process_article(url)\n",
    "        # Write preprocessed article to a separate file for each URL\n",
    "        file_path = f'{directory}/{results[\"title\"]}.txt'\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            # Save the information for each sentence to the file\n",
    "            for i, sentence in enumerate(results['filtered_sentences']):\n",
    "                f.write(f\"Sentence {i+1}: {sentence}\\n\")\n",
    "                f.write(f\"Total words: {results['num_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Filtered words: {sentence.split()}\\n\")\n",
    "                f.write(f\"Number of filtered words: {len(sentence.split())}\\n\")\n",
    "                f.write(f\"Stop words: {results['stop_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Number of stop words: {results['num_stop_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Average number of stop words per sentence: {round(results['avg_stop_words_per_sentence'][i], 2)}\\n\")\n",
    "                f.write(f\"Sentiment score: {results['s_sentiment_scores'][i]}\\n\\n\")\n",
    "                #f.write(f\"Depth: {results['tree_lengths'][i]}\\n\")\n",
    "                \n",
    "\n",
    "            # Save the general statistics on stop words to the file\n",
    "            f.write(f\"Total number of words: {results['total_words']}\\n\")\n",
    "            f.write(f\"Total number of stop words: {results['num_stop_words']}\\n\")\n",
    "            f.write(f\"Maximum number of stop words per sentence: {results['max_stop_words_per_sentence']}\\n\")\n",
    "            f.write(f\"Minimum number of stop words per sentence: {results['min_stop_words_per_sentence']}\\n\")\n",
    "            f.write(f\"Average number of stop words per article: {round(results['avg_stop_words_per_sentence_avg'], 2)}\\n\")\n",
    "\n",
    "            # Print POS tagging operations\n",
    "            f.write(f\"Total adjectives: {results['total_adjectives']}\\n\")\n",
    "            f.write(f\"Average number of adjectives in the article: {results['avg_adjectives']:.2f}\\n\\n\")\n",
    "            \n",
    "            # Stanza sentiment scores\n",
    "            f.write(f\"Stanza Average of sentiment score for all sentences: {sum(results['s_sentiment_scores']) / len(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Maximum sentiment score: {max(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Minimum sentiment score: {min(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Standard deviation: {statistics.stdev(results['s_sentiment_scores'])}\\n\\n\")\n",
    "\n",
    "            # Vader sentiment scores\n",
    "            f.write(f\"Vader average scores: {results['v_avg_scores']}\\n\")\n",
    "            f.write(f\"Vader maximum scores: {results['v_max_scores']}\\n\")\n",
    "            f.write(f\"Vader minimum scores: {results['v_min_scores']}\\n\")\n",
    "            f.write(f\"Vader standard deviation scores: {results['v_std_scores']}\\n\\n\")\n",
    "\n",
    "            # MPQA sentiment scores\n",
    "            f.write(f\"MPQA average scores: {results['mpqa_avg_score']}\\n\")\n",
    "            f.write(f\"MPQA maximum scores: {results['mpqa_max_score']}\\n\")\n",
    "            f.write(f\"MPQA minimum scores: {results['mpqa_min_score']}\\n\")\n",
    "            f.write(f\"MPQA standard deviation scores: {results['mpqa_sd_score']}\\n\\n\")\n",
    "\n",
    "            # Sentiword sentiment scores\n",
    "            f.write(f\"Sentiwordnet score: {results['sentiwordnet_final_score']} (from -1 to 1, and score of 0 indicates a neutral sentiment.)\\n\\n\")\n",
    "            \n",
    "            # Flesch_Kincaid scores\n",
    "            f.write(f\"Flesch-Kincaid score: {results['metrics']['flesch_kincaid'].score}\\n\")\n",
    "            f.write(f\"The estimated reading level of the article is: {results['metrics']['flesch_kincaid'].grade_level}\\n\\n\") \n",
    "\n",
    "            # Flesch Reading ease scores\n",
    "            f.write(f\"Flesch Reading Ease score: {results['metrics']['flesch_reading'].score}\\n\")\n",
    "            f.write(f\"The article is classified as: {results['metrics']['flesch_reading'].ease}\\n\\n\")\n",
    "\n",
    "            # Print the Dale-Chall scores\n",
    "            f.write(f\"Dale-Chall Readability score: {results['metrics']['dale_chall'].score}\\n\")\n",
    "            # Print the estimated grade levels for comprehension\n",
    "            f.write(f\"The estimated comprehension level for different grade levels is: {results['metrics']['dale_chall'].grade_levels}\\n\\n\")\n",
    "\n",
    "            # Print the ARI scores\n",
    "            f.write(f\"Automated Readability Index (ARI) score: {results['metrics']['ari'].score}, which corresponds to a grade level of {results['metrics']['ari'].grade_levels}.\\n\")\n",
    "            f.write(f\"This means that the text can be read by someone who is around {results['metrics']['ari'].ages} years old.\\n\\n\")\n",
    "\n",
    "            # Print the Coleman-Liau scores\n",
    "            f.write(f\"Coleman-Liau Index Score: {results['metrics']['coleman_liau'].score}\\n\")\n",
    "            f.write(f\"Estimated Grade Level: {results['metrics']['coleman_liau'].grade_level}\\n\\n\")\n",
    "\n",
    "            # Print the Gunning Fog scores\n",
    "            f.write(f\"Gunning Fog score: {results['metrics']['gunning_fog'].score}\\n\")\n",
    "            f.write(f\"The estimated grade level for comprehension is: {results['metrics']['gunning_fog'].grade_level}\\n\\n\")\n",
    "\n",
    "            # Print the SMOG scores\n",
    "            #f.write(f\"SMOG score: {results['metrics']['smog'].score}. This corresponds to a grade level of {results['metrics']['smog'].grade_level}.\")\n",
    "            \n",
    "            # Print the SPACHE scores\n",
    "            f.write(f\"SPACHE score: {results['metrics']['spache'].score}\\n\")\n",
    "            f.write(f\"This corresponds to a grade level of {results['metrics']['spache'].grade_level}.\\n\\n\")\n",
    "\n",
    "            # Print the Linsear Write Index scores\n",
    "            f.write(f\"Linsear Write Index score: {results['metrics']['linsear_write'].score}\\n\")\n",
    "            f.write(\"Approximate grade level equivalent: {}\\n\\n\".format(results['metrics']['linsear_write'].grade_level))\n",
    "\n",
    "            # Gensim-LDA analysis\n",
    "            f.write(f\"Perplexity (how well the LDA model predicts the corpus) of the article: {results['perplexity_lda']}\\n\")\n",
    "            f.write(f\"Coherence (how coherent the topics are) of the article: {results['coherence_lda']}\\n\\n\")\n",
    "\n",
    "            # Dependency tree height\n",
    "            f.write(f\"Max tree depth: {results['max_depth']}\\n\")\n",
    "            f.write(f\"Words at max depth: {', '.join(results['max_depth_words'])}\\n\")\n",
    "            f.write(f\"Average tree length: {results['avg_length']:.2f}\\n\")\n",
    "            f.write(f\"Maximum tree length: {results['max_length']}\\n\")\n",
    "            f.write(f\"Minimum tree length: {results['min_length']}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(urls, directory):\n",
    "    # Preprocessed directory \n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        results = process_article(url)\n",
    "\n",
    "        # Create a directory for the article\n",
    "        article_directory = f'{directory}/{results[\"title\"]}'\n",
    "        os.makedirs(article_directory, exist_ok=True)\n",
    "\n",
    "        # Create a list to store the information for each sentence\n",
    "        sentence_info = []\n",
    "\n",
    "        # Append the information for each sentence to the list\n",
    "        for i, sentence in enumerate(results['filtered_sentences']):\n",
    "            sentences_info = {\n",
    "                'Sentence': f'Sentence {i+1}',\n",
    "                'Total words': results['num_words_per_sentence'][i],\n",
    "                'Filtered words': sentence.split(),\n",
    "                'Number of filtered words': len(sentence.split()),\n",
    "                'Stop words': results['stop_words_per_sentence'][i],\n",
    "                'Number of stop words': results['num_stop_words_per_sentence'][i],\n",
    "                'Average number of stop words per sentence': round(results['avg_stop_words_per_sentence'][i], 2),\n",
    "                'Sentiment score': results['s_sentiment_scores'][i]\n",
    "            }\n",
    "            sentence_info.append(sentences_info)\n",
    "\n",
    "        # Create a list to store the general statistics on stop words\n",
    "        general_stats = [\n",
    "            {\n",
    "                'Total number of words': results['total_words'],\n",
    "                'Total number of stop words': results['num_stop_words'],\n",
    "                'Maximum number of stop words per sentence': results['max_stop_words_per_sentence'],\n",
    "                'Minimum number of stop words per sentence': results['min_stop_words_per_sentence'],\n",
    "                'Average number of stop words per article': round(results['avg_stop_words_per_sentence_avg'], 2)\n",
    "            }\n",
    "        ]   \n",
    "\n",
    "        # Create a list to store the POS tagging operations\n",
    "        pos_tagging_ops = [\n",
    "            {\n",
    "                'Total adjectives': results['total_adjectives'],\n",
    "                'Average number of adjectives in the article': round(results['avg_adjectives'], 2)\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Create a list to store the sentiment scores\n",
    "        sentiment_scores = [\n",
    "            {\n",
    "                'Stanza Average of sentiment score for all sentences': sum(results['s_sentiment_scores']) / len(results['s_sentiment_scores']),\n",
    "                'Stanza Maximum sentiment score': max(results['s_sentiment_scores']),\n",
    "                'Stanza Minimum sentiment score': min(results['s_sentiment_scores']),\n",
    "                'Stanza Standard deviation': statistics.stdev(results['s_sentiment_scores']),\n",
    "                'Vader average scores': results['v_avg_scores'],\n",
    "                'Vader maximum scores': results['v_max_scores'],\n",
    "                'Vader minimum scores': results['v_min_scores'],\n",
    "                'Vader standard deviation scores': results['v_std_scores'],\n",
    "                'MPQA average scores': results['mpqa_avg_score'],\n",
    "                'MPQA maximum scores': results['mpqa_max_score'],\n",
    "                'MPQA minimum scores': results['mpqa_min_score'],\n",
    "                'MPQA standard deviation scores': results['mpqa_sd_score'],\n",
    "                'Sentiwordnet score': results['sentiwordnet_final_score']\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Create a list to store the Flesch-Kincaid scores\n",
    "        readability_scores = [\n",
    "            {\n",
    "                'Flesch-Kincaid score': results['metrics']['flesch_kincaid'].score,\n",
    "                'Estimated reading level of the article': results['metrics']['flesch_kincaid'].grade_level,\n",
    "                'Flesch-Reading score': results['metrics']['flesch_reading'].score,\n",
    "                'The article is classified as': results['metrics']['flesch_reading'].ease,\n",
    "                'Dale-Chall Readability score': results['metrics']['dale_chall'].score,\n",
    "                'The estimated comprehension level for different grade levels': results['metrics']['dale_chall'].grade_levels,\n",
    "                'Automated Readability Index (ARI) score': results['metrics']['ari'].score, \n",
    "                'It corresponds to a grade level of': results['metrics']['ari'].grade_levels,\n",
    "                'This means that the text can be read by someone who is around': results['metrics']['ari'].ages,\n",
    "                'Coleman-Liau Index Score': results['metrics']['coleman_liau'].score,\n",
    "                'Estimated Grade Level': results['metrics']['coleman_liau'].grade_level,\n",
    "                'Gunning Fog score': results['metrics']['gunning_fog'].score,\n",
    "                'The estimated grade level for comprehension is': results['metrics']['gunning_fog'].grade_level,\n",
    "                'SPACHE score': results['metrics']['spache'].score,\n",
    "                'This corresponds to a grade level of': results['metrics']['spache'].grade_level,\n",
    "                'Linsear Write Index score': results['metrics']['linsear_write'].score,\n",
    "                'Approximate grade level equivalent': results['metrics']['linsear_write'].grade_level,\n",
    "                'Perplexity (how well the LDA model predicts the corpus) of the article': results['perplexity_lda'],\n",
    "                'Coherence (how coherent the topics are) of the article': results['coherence_lda']\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Create a list to store the dependency tree scores\n",
    "        dependency_tree_scores = [\n",
    "            {\n",
    "                'Max tree depth': results['max_depth'],\n",
    "                'Words at max depth': ', '.join(results['max_depth_words']),\n",
    "                'Average tree length': results['avg_length'],\n",
    "                'Maximum tree length': results['max_length'],\n",
    "                'Minimum tree length': results['min_length']\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        with open(f'{article_directory}/sentences_info.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = ['Sentence', 'Total words', 'Filtered words', 'Number of filtered words', 'Stop words', 'Number of stop words', 'Average number of stop words per sentence', 'Sentiment score']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            for sentence in sentence_info:\n",
    "                if isinstance(sentence, dict):\n",
    "                    writer.writerow(sentence)\n",
    "        # Print contents of the CSV file\n",
    "        with open(f'{article_directory}/sentences_info.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        # Print the contents of the CSV file as a formatted table\n",
    "        print(tabulate(rows, headers='keys'))\n",
    "        \n",
    "\n",
    "        # Write the general statistics on stop words to a CSV file\n",
    "        with open(f'{article_directory}/general_stats.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = ['Total number of words', 'Total number of stop words', 'Maximum number of stop words per sentence', 'Minimum number of stop words per sentence', 'Average number of stop words per article']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            for stats in general_stats:\n",
    "                writer.writerow(stats)\n",
    "        # Print contents of the CSV file\n",
    "        with open(f'{article_directory}/general_stats.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        # Print the contents of the CSV file as a formatted table\n",
    "        print(tabulate(rows, headers='keys'))\n",
    "\n",
    "        # Write the general statistics on POS tagging to a CSV file\n",
    "        with open(f'{article_directory}/pos_tagging.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = ['Total adjectives', 'Average number of adjectives in the article']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            for stats in pos_tagging_ops:\n",
    "                writer.writerow(stats)\n",
    "        # Print contents of the CSV file\n",
    "        with open(f'{article_directory}/pos_tagging.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        # Print the contents of the CSV file as a formatted table\n",
    "        print(tabulate(rows, headers='keys'))\n",
    "        \n",
    "\n",
    "        # Write the sentiment scores to a CSV file\n",
    "        with open(f'{article_directory}/sentiment_scores.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = ['Stanza Average of sentiment score for all sentences', 'Stanza Maximum sentiment score', 'Stanza Minimum sentiment score', 'Stanza Standard deviation', 'Vader average scores', 'Vader maximum scores', 'Vader minimum scores', 'Vader standard deviation scores', 'MPQA average scores', 'MPQA maximum scores', 'MPQA minimum scores', 'MPQA standard deviation scores', 'Sentiwordnet score']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            for stats in sentiment_scores:\n",
    "                writer.writerow(stats)\n",
    "        # Print contents of the CSV file\n",
    "        with open(f'{article_directory}/sentiment_scores.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        # Print the contents of the CSV file as a formatted table\n",
    "        print(tabulate(rows, headers='keys'))\n",
    "        \n",
    "        # Write the readability scores to a CSV file\n",
    "        with open(f'{article_directory}/readability_scores.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = ['Flesch-Kincaid score', 'Estimated reading level of the article', 'Flesch-Reading score', 'The article is classified as', 'Dale-Chall Readability score', 'The estimated comprehension level for different grade levels', 'Automated Readability Index (ARI) score', 'It corresponds to a grade level of', 'This means that the text can be read by someone who is around', 'Coleman-Liau Index Score', 'Estimated Grade Level', 'Gunning Fog score', 'The estimated grade level for comprehension is', 'SPACHE score', 'This corresponds to a grade level of', 'Linsear Write Index score', 'Approximate grade level equivalent', 'Perplexity (how well the LDA model predicts the corpus) of the article', 'Coherence (how coherent the topics are) of the article']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            for stats in readability_scores:\n",
    "                writer.writerow(stats)\n",
    "        # Print contents of the CSV file\n",
    "        with open(f'{article_directory}/readability_scores.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        # Print the contents of the CSV file as a formatted table\n",
    "        print(tabulate(rows, headers='keys'))\n",
    "        \n",
    "        # Write the dependency tree scores to a CSV file\n",
    "        with open(f'{article_directory}/dependency_tree_scores.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = ['Max tree depth', 'Words at max depth', ', ', 'Average tree length', 'Maximum tree length', 'Minimum tree length']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            if file.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            for stats in dependency_tree_scores:\n",
    "                writer.writerow(stats)\n",
    "        # Print contents of the CSV file\n",
    "        with open(f'{article_directory}/dependency_tree_scores.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        # Print the contents of the CSV file as a formatted table\n",
    "        print(tabulate(rows, headers='keys'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence       Total words  Filtered words                                                                                                                                                                                                                                                                                                                                                           Number of filtered words  Stop words                                                                                                         Number of stop words    Average number of stop words per sentence    Sentiment score\n",
      "-----------  -------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------  ---------------------------------------------------------------------------------------------------------------  ----------------------  -------------------------------------------  -----------------\n",
      "Sentence 1              38  ['Republicans', 'respond', 'IRS', 'whistleblower', 'says', 'Hunter', 'Biden', 'investigation', 'mishandled', 'Members', 'Congress', 'calling', 'transparency', 'Biden', 'administration', 'IRS', 'whistleblower', 'said', 'investigation', 'Hunter', 'Biden', 'mishandled', '.']                                                                                                               23  ['after', 'is', 'being', 'of', 'are', 'for', 'more', 'from', 'the', 'after', 'an', 'an', 'into', 'is', 'being']                      15                                         0.39                  0\n",
      "Sentence 2              35  ['Lawmakers', 'Capitol', 'Hill', 'calling', 'Biden', 'administration', 'held', 'accountable', '``', 'blocking', \"''\", 'Congress', 'public', 'learning', 'Biden', 'family', 'members', '’', 'business', 'deals', 'China', '.']                                                                                                                                                                  22  ['on', 'are', 'for', 'the', 'to', 'be', 'for', 'and', 'the', 'from', 'more', 'about', 'with']                                        13                                         0.37                  0\n",
      "Sentence 3              26  ['congressional', 'outcries', 'come', 'whistleblower', 'within', 'Internal', 'Revenue', 'Service', 'alleges', 'investigation', 'Hunter', 'Biden', 'mishandled', 'Biden', 'administration', '.']                                                                                                                                                                                                16  ['The', 'as', 'a', 'the', 'an', 'into', 'is', 'being', 'by', 'the']                                                                  10                                         0.38                  1\n",
      "Sentence 4              14  ['whistleblower', 'also', 'alleges', '``', 'clear', 'conflicts', 'interest', \"''\", 'investigation', '.']                                                                                                                                                                                                                                                                                       10  ['The', 'of', 'in', 'the']                                                                                                            4                                         0.29                  0\n",
      "Sentence 5              41  ['``', '’', 'deeply', 'concerning', 'Biden', 'Administration', 'may', 'obstructing', 'justice', 'blocking', 'efforts', 'charge', 'Hunter', 'Biden', 'tax', 'violations', ',', \"''\", 'House', 'Committee', 'Oversight', 'Accountability', 'Chairman', 'James', 'Comer', 'told', 'Fox', 'News', 'Wednesday', '.']                                                                                30  ['It', 's', 'that', 'the', 'be', 'by', 'to', 'for', 'on', 'and', 'on']                                                               11                                         0.27                  1\n",
      "Sentence 6              28  ['Comer', ',', 'R-Ky.', ',', 'also', 'said', '``', 'deceptive', ',', 'shady', 'business', 'schemes', \"''\", 'allowed', 'Bidens', 'make', '``', 'millions', 'foreign', 'adversaries', 'like', 'China', '.', \"''\"]                                                                                                                                                                                24  ['have', 'the', 'to', 'from']                                                                                                         4                                         0.14                  1\n",
      "Sentence 7              37  ['HUNTER', 'BIDEN', 'INVESTIGATION', 'MISHANDLED', ',', \"'CLEAR\", 'CONFLICTS', 'INTEREST', \"'\", ':', 'IRS', 'WHISTLEBLOWER', \"''\", 'House', 'Committee', 'Oversight', 'Accountability', 'following', 'Bidens', '’', 'tangled', 'web', 'complex', 'corporate', 'financial', 'records', '.']                                                                                                     27  ['BEING', 'OF', 'The', 'on', 'and', 'has', 'been', 'the', 'of', 'and']                                                               10                                         0.27                  1\n",
      "Sentence 8              40  ['’', 'clear', 'investigation', 'Hunter', 'members', 'Biden', 'family', 'engaged', 'deceptive', ',', 'shady', 'business', 'schemes', 'avoid', 'scrutiny', 'made', 'millions', 'foreign', 'adversaries', 'like', 'China', ',', \"''\", 'said', '.']                                                                                                                                               25  ['It', 's', 'from', 'our', 'that', 'and', 'other', 'of', 'the', 'in', 'to', 'as', 'they', 'from', 'he']                              15                                         0.38                  1\n",
      "Sentence 9              19  ['``', '’', 'wondering', 'along', 'heck', 'DOJ', 'IRS', '.']                                                                                                                                                                                                                                                                                                                                    8  ['We', 've', 'been', 'all', 'where', 'the', 'the', 'and', 'the', 'have', 'been']                                                     11                                         0.58                  1\n",
      "Sentence 10             21  ['appears', 'Biden', 'Administration', 'may', 'working', 'overtime', 'prevent', 'Bidens', 'facing', 'consequences', '.', \"''\"]                                                                                                                                                                                                                                                                 12  ['Now', 'it', 'the', 'have', 'been', 'to', 'the', 'from', 'any']                                                                      9                                         0.43                  1\n",
      "Sentence 11             27  ['Comer', 'added', ',', '``', 'House', 'Oversight', 'Committee', 'work', 'hold', 'accountable', 'anyone', 'Biden', 'Administration', 'may', 'covering', 'criminal', 'activity', '.']                                                                                                                                                                                                           18  ['The', 'will', 'to', 'in', 'the', 'who', 'be', 'up', 'this']                                                                         9                                         0.33                  0\n",
      "Sentence 12             30  ['Oversight', 'Committee', 'also', 'continue', 'pursue', 'investigation', 'Biden', 'family', '’', 'business', 'schemes', 'determine', 'President', 'Biden', 'national', 'security', 'compromised', '.']                                                                                                                                                                                        18  ['The', 'will', 'to', 'our', 'into', 'the', 's', 'to', 'if', 'and', 'our', 'are']                                                    12                                         0.4                   1\n",
      "Sentence 13             10  ['Americans', 'demand', 'answers', ',', 'transparency', ',', 'accountability', '.', \"''\"]                                                                                                                                                                                                                                                                                                       9  ['and']                                                                                                                               1                                         0.1                   1\n",
      "Sentence 14             14  ['President', 'Biden', '’', 'son', 'Hunter', 'federal', 'investigation', 'since', '2018', '.']                                                                                                                                                                                                                                                                                                 10  ['s', 'has', 'been', 'under']                                                                                                         4                                         0.29                  1\n",
      "Sentence 15             17  ['investigation', 'concerns', 'presence', 'suspicious', 'activity', 'reports', '(', 'SARs', ')', 'regarding', 'suspicious', 'foreign', 'transactions', '.']                                                                                                                                                                                                                                    14  ['The', 'the', 'of']                                                                                                                  3                                         0.18                  1\n",
      "Sentence 16             11  ['led', 'Delaware', 'U.S.', 'Attorney', 'David', 'Weiss', '.']                                                                                                                                                                                                                                                                                                                                  7  ['It', 'is', 'being', 'by']                                                                                                           4                                         0.36                  1\n",
      "Sentence 17             29  ['Across', 'Congress', ',', 'Sen.', 'Ted', 'Cruz', 'Wednesday', 'called', 'Treasury', 'Secretary', 'Janet', 'Yellen', 'publicly', 'release', 'SARs', 'found', 'among', 'Biden', 'family', '’', 'tax', 'records', '.']                                                                                                                                                                          23  ['on', 'for', 'to', 'the', 'the', 's']                                                                                                6                                         0.21                  1\n",
      "Sentence 18             26  ['``', '’', 'national', 'security', 'reason', 'keep', 'private', ',', \"''\", 'Cruz', ',', 'R-Texas', ',', 'said', 'episode', 'podcast', '.']                                                                                                                                                                                                                                                    17  ['There', 's', 'no', 'to', 'them', 'during', 'an', 'of', 'his']                                                                       9                                         0.35                  1\n",
      "Sentence 19             21  ['``', '’', 'reason', 'whatsoever', 'want', 'part', 'political', 'cover-up', '.', \"''\"]                                                                                                                                                                                                                                                                                                        10  ['There', 's', 'no', 'other', 'than', 'if', 'you', 'to', 'be', 'of', 'a']                                                            11                                         0.52                  1\n",
      "Sentence 20             32  ['SIX', 'ADDITIONAL', 'BIDEN', 'FAMILY', 'MEMBERS', '‘', 'MAY', 'BENEFITED', '’', 'HUNTER', 'BUSINESS', 'DEALINGS', 'SARs', 'alone', 'indicate', 'wrongdoing', 'criminal', 'activity', 'could', 'indicator', 'behavior', '.']                                                                                                                                                                  22  ['HAVE', 'FROM', 'do', 'not', 'or', 'but', 'be', 'an', 'of', 'such']                                                                 10                                         0.31                  1\n",
      "Sentence 21             25  ['``', 'U.S.', 'Department', 'Treasury', 'needs', 'release', 'every', 'single', 'suspicious', 'activity', 'report', 'Biden', 'family', ',', \"''\", 'Cruz', 'said', 'Wednesday', '.']                                                                                                                                                                                                            19  ['The', 'of', 'to', 'on', 'the', 'on']                                                                                                6                                         0.24                  0\n",
      "Sentence 22             31  ['``', 'Janet', 'Yellen', ',', 'choice', ':', 'either', 'actively', 'covering', 'potential', 'evidence', 'corruption', 'releasing', 'every', 'one', 'American', 'people', '.', \"''\"]                                                                                                                                                                                                           19  ['you', 'have', 'a', 'You', 'are', 'up', 'of', 'or', 'of', 'them', 'to', 'the']                                                      12                                         0.39                  1\n",
      "Sentence 23             32  ['According', 'Cruz', ',', 'American', 'public', 'privy', 'learning', 'whether', 'presidential', 'family', 'guilty', 'fraud', 'abuses', 'office', '—', 'innocent', '.']                                                                                                                                                                                                                        17  ['to', 'the', 'should', 'be', 'to', 'the', 'is', 'of', 'or', 'other', 'of', 'or', 'if', 'he', 'is']                                  15                                         0.47                  1\n",
      "Sentence 24             38  ['BIDEN', 'FAMILY', 'RECEIVED', '$', '1M', 'HUNTER', 'ASSOCIATE', '2017', 'CHINA', 'WIRE', ':', 'HOUSE', 'OVERSIGHT', 'Texas', 'Republican', 'said', 'Biden', 'administration', '``', 'let', 'American', 'people', 'decide', \"''\", 'criminal', 'activity', 'conducted', '.']                                                                                                                   28  ['MORE', 'THAN', 'FROM', 'AFTER', 'The', 'the', 'should', 'the', 'if', 'was']                                                        10                                         0.26                  1\n",
      "Sentence 25             14  ['added', ',', '``', 'benign', ',', 'release', 'reports', '.', \"''\"]                                                                                                                                                                                                                                                                                                                            9  ['He', 'If', 'this', 'is', 'the']                                                                                                     5                                         0.36                  0\n",
      "Sentence 26             19  ['``', 'Secretary', 'Yellen', ',', 'release', 'every', 'single', 'suspicious', 'activity', 'report', 'Biden', 'family', ',', \"''\", 'Cruz', 'said', '.']                                                                                                                                                                                                                                        17  ['on', 'the']                                                                                                                         2                                         0.11                  0\n",
      "Sentence 27              3  ['continued', '.']                                                                                                                                                                                                                                                                                                                                                                              2  ['He']                                                                                                                                1                                         0.33                  0\n",
      "Sentence 28             18  ['``', '’', 'release', 'reports', ',', 'complicit', 'cover-up', '.', \"''\"]                                                                                                                                                                                                                                                                                                                      9  ['If', 'she', 'doesn', 't', 'those', 'she', 'is', 'in', 'the']                                                                        9                                         0.5                   1\n",
      "Sentence 29             52  ['letter', 'dated', 'April', '19', ',', '2023', ',', 'attorney', 'Mark', 'D.', 'Lytle', 'told', 'members', 'Congress', 'client', 'overseeing', '``', 'ongoing', 'sensitive', 'investigation', 'high-profile', ',', 'controversial', 'subject', 'since', 'early', '2020', 'would', 'like', 'make', 'protected', 'whistleblower', 'disclosures', 'Congress', '.', \"''\"]                          36  ['In', 'a', 'of', 'that', 'a', 'of', 'his', 'has', 'been', 'the', 'and', 'of', 'a', 'and', 'to', 'to']                               16                                         0.31                  1\n",
      "Sentence 30             26  ['client', 'allegedly', 'aware', 'facts', 'case', '``', 'contradict', 'sworn', 'testimony', 'Congress', 'senior', 'political', 'appointee', '.', \"''\"]                                                                                                                                                                                                                                         15  ['And', 'that', 'the', 'is', 'of', 'of', 'the', 'that', 'to', 'by', 'a']                                                             11                                         0.42                  1\n",
      "Sentence 31             23  ['CLICK', 'GET', 'FOX', 'NEWS', 'APP', 'Lytle', 'works', 'Washington', ',', 'D.C.', ',', '-based', 'law', 'firm', 'Nixon', 'Peabody', 'LLP', '.']                                                                                                                                                                                                                                              18  ['HERE', 'TO', 'THE', 'for', 'the']                                                                                                   5                                         0.22                  1\n",
      "Sentence 32             20  ['Neither', 'Hunter', 'Biden', 'member', 'family', 'charged', 'crime', 'relating', 'SARs', '.']                                                                                                                                                                                                                                                                                                10  ['nor', 'any', 'of', 'his', 'has', 'been', 'with', 'a', 'to', 'the']                                                                 10                                         0.5                   1\n",
      "Sentence 33             13  ['Fox', 'News', \"'\", 'Patrick', 'Ward', ',', 'Greg', 'Wehner', 'contributed', 'report', '.']                                                                                                                                                                                                                                                                                                   11  ['to', 'this']                                                                                                                        2                                         0.15                  1\n",
      "  Total number of words    Total number of stop words    Maximum number of stop words per sentence    Minimum number of stop words per sentence    Average number of stop words per article\n",
      "-----------------------  ----------------------------  -------------------------------------------  -------------------------------------------  ------------------------------------------\n",
      "                    830                           275                                           16                                            1                                        0.33\n",
      "  Total adjectives    Average number of adjectives in the article\n",
      "------------------  ---------------------------------------------\n",
      "                61                                           0.07\n",
      "  Stanza Average of sentiment score for all sentences    Stanza Maximum sentiment score    Stanza Minimum sentiment score    Stanza Standard deviation  Vader average scores                Vader maximum scores    Vader minimum scores    Vader standard deviation scores       MPQA average scores    MPQA maximum scores    MPQA minimum scores    MPQA standard deviation scores    Sentiwordnet score\n",
      "-----------------------------------------------------  --------------------------------  --------------------------------  ---------------------------  ----------------------------------  ----------------------  ----------------------  ----------------------------------  ---------------------  ---------------------  ---------------------  --------------------------------  --------------------\n",
      "                                             0.794872                                 1                                 0                     0.409074  [0.07775758 0.86757576 0.05457576]  [0.294 1.    0.346]     [0.    0.494 0.   ]     [0.08812698 0.1209152  0.07819983]              -0.186441                      1                     -1                          0.853201           -0.00271739\n",
      "  Flesch-Kincaid score    Estimated reading level of the article    Flesch-Reading score  The article is classified as      Dale-Chall Readability score  The estimated comprehension level for different grade levels      Automated Readability Index (ARI) score  It corresponds to a grade level of    This means that the text can be read by someone who is around      Coleman-Liau Index Score    Estimated Grade Level    Gunning Fog score  The estimated grade level for comprehension is      SPACHE score    This corresponds to a grade level of    Linsear Write Index score    Approximate grade level equivalent    Perplexity (how well the LDA model predicts the corpus) of the article    Coherence (how coherent the topics are) of the article\n",
      "----------------------  ----------------------------------------  ----------------------  ------------------------------  ------------------------------  --------------------------------------------------------------  -----------------------------------------  ------------------------------------  ---------------------------------------------------------------  --------------------------  -----------------------  -------------------  ------------------------------------------------  --------------  --------------------------------------  ---------------------------  ------------------------------------  ------------------------------------------------------------------------  --------------------------------------------------------\n",
      "                14.151                                        14                 33.1823  difficult                                              11.3984  ['college_graduate']                                                                              13.7636  ['college_graduate']                  [24, 100]                                                                           12.4061                       12              15.2292  college                                                  8.42588                                       8                      16.6364                                    17                                                                  -4.49855                                                  0.580393\n",
      "  Max tree depth  Words at max depth    ,       Average tree length    Maximum tree length    Minimum tree length\n",
      "----------------  --------------------  ----  ---------------------  ---------------------  ---------------------\n",
      "              10  calling, be                               5.57576                     12                      1\n",
      "Sentence       Total words  Filtered words                                                                                                                                                                                                                                                                                                                                                                                                                                                     Number of filtered words  Stop words                                                                                                                                             Number of stop words    Average number of stop words per sentence    Sentiment score\n",
      "-----------  -------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------  ----------------------  -------------------------------------------  -----------------\n",
      "Sentence 1              13  ['Alabama', 'education', 'director', 'ousted', 'book', \"'s\", 'stance', 'race', 'Alabama', 'Gov', '.']                                                                                                                                                                                                                                                                                                                                                                                    11  ['over', 'on']                                                                                                                                                            2                                         0.15                  0\n",
      "Sentence 2              50  ['Kay', 'Ivey', 'Friday', 'announced', 'replaced', 'director', 'early', 'childhood', 'education', 'use', 'teacher', 'training', 'book', ',', 'written', 'nationally', 'recognized', 'education', 'group', ',', 'Republican', 'governor', 'denounced', 'teaching', '“', 'woke', 'concepts', \"''\", 'language', 'inclusion', 'structural', 'racism', '.']                                                                                                                                   33  ['on', 'she', 'her', 'of', 'over', 'the', 'of', 'a', 'by', 'a', 'that', 'the', 'as', 'because', 'of', 'about', 'and']                                                    17                                         0.34                  1\n",
      "Sentence 3              30  ['Barbara', 'Cooper', 'forced', 'head', 'Alabama', 'Department', 'Early', 'Childhood', 'Education', 'Ivey', 'expressed', 'concern', 'distribution', 'book', 'state-run', 'pre-kindergartens', '.']                                                                                                                                                                                                                                                                                       17  ['was', 'out', 'as', 'as', 'of', 'the', 'of', 'after', 'over', 'the', 'of', 'the', 'to']                                                                                 13                                         0.43                  1\n",
      "Sentence 4              28  ['Ivey', 'spokesperson', 'Gina', 'Maiola', 'identified', 'book', 'National', 'Association', 'Education', 'Young', 'Children', '(', 'NAEYC', ')', 'Developmentally', 'Appropriate', 'Practice', 'Book', ',', '4th', 'edition', '.']                                                                                                                                                                                                                                                       22  ['the', 'as', 'the', 'for', 'the', 'of']                                                                                                                                  6                                         0.21                  1\n",
      "Sentence 5              10  ['MONTGOMERY', ',', 'Ala.', '(', 'AP', ')', '—', 'Alabama', 'Gov', '.']                                                                                                                                                                                                                                                                                                                                                                                                                  10  []                                                                                                                                                                        0                                         0                     2\n",
      "Sentence 6              50  ['Kay', 'Ivey', 'Friday', 'announced', 'replaced', 'director', 'early', 'childhood', 'education', 'use', 'teacher', 'training', 'book', ',', 'written', 'nationally', 'recognized', 'education', 'group', ',', 'Republican', 'governor', 'denounced', 'teaching', '“', 'woke', 'concepts', \"''\", 'language', 'inclusion', 'structural', 'racism', '.']                                                                                                                                   33  ['on', 'she', 'her', 'of', 'over', 'the', 'of', 'a', 'by', 'a', 'that', 'the', 'as', 'because', 'of', 'about', 'and']                                                    17                                         0.34                  1\n",
      "Sentence 7              30  ['Barbara', 'Cooper', 'forced', 'head', 'Alabama', 'Department', 'Early', 'Childhood', 'Education', 'Ivey', 'expressed', 'concern', 'distribution', 'book', 'state-run', 'pre-kindergartens', '.']                                                                                                                                                                                                                                                                                       17  ['was', 'out', 'as', 'as', 'of', 'the', 'of', 'after', 'over', 'the', 'of', 'the', 'to']                                                                                 13                                         0.43                  0\n",
      "Sentence 8              28  ['Ivey', 'spokesperson', 'Gina', 'Maiola', 'identified', 'book', 'National', 'Association', 'Education', 'Young', 'Children', '(', 'NAEYC', ')', 'Developmentally', 'Appropriate', 'Practice', 'Book', ',', '4th', 'edition', '.']                                                                                                                                                                                                                                                       22  ['the', 'as', 'the', 'for', 'the', 'of']                                                                                                                                  6                                         0.21                  1\n",
      "Sentence 9              15  ['Maiola', 'said', 'understands', 'books', 'removed', 'state', 'classrooms', '.']                                                                                                                                                                                                                                                                                                                                                                                                         8  ['she', 'that', 'the', 'have', 'been', 'from', 'the']                                                                                                                     7                                         0.47                  1\n",
      "Sentence 10             30  ['“', 'education', 'Alabama', '’', 'children', 'top', 'priority', 'governor', ',', 'absolutely', 'room', 'distract', 'take', 'away', 'mission', '.']                                                                                                                                                                                                                                                                                                                                     16  ['The', 'of', 's', 'is', 'my', 'as', 'and', 'there', 'is', 'no', 'to', 'or', 'from', 'this']                                                                             14                                         0.47                  1\n",
      "Sentence 11             49  ['Let', 'crystal', 'clear', ':', 'Woke', 'concepts', 'zero', 'proper', 'education', 'divisive', 'core', 'place', 'Alabama', 'classrooms', 'age', 'level', ',', 'let', 'alone', 'youngest', 'learners', ',', \"''\", 'Ivey', 'said', 'statement', '.']                                                                                                                                                                                                                                      27  ['me', 'be', 'that', 'have', 'to', 'do', 'with', 'a', 'and', 'that', 'are', 'at', 'the', 'have', 'no', 'in', 'at', 'any', 'with', 'our', 'in', 'a']                      22                                         0.45                  1\n",
      "Sentence 12             36  ['Ivey', \"'s\", 'statement', 'comes', 'conservative', 'politicians', 'made', 'rallying', 'cry', 'decrying', 'so-called', '“', 'woke', '”', 'teachings', ',', 'schools', 'sometimes', 'emerging', 'flashpoint', 'diversity', 'training', 'parents', '’', 'rights', '.']                                                                                                                                                                                                                    26  ['as', 'have', 'a', 'out', 'of', 'with', 'as', 'a', 'over', 'and']                                                                                                       10                                         0.28                  1\n",
      "Sentence 13             50  ['governor', '’', 'office', 'said', 'Ivey', 'first', 'asked', 'Cooper', '“', 'send', 'memo', 'disavow', 'book', 'immediately', 'discontinue', 'use.', '”', 'Ivey', \"'s\", 'office', 'say', 'Cooper', 'responded', 'governor', 'made', 'decision', 'replace', 'Cooper', 'accepted', 'resignation', '.']                                                                                                                                                                                    31  ['The', 's', 'to', 'a', 'to', 'this', 'and', 'to', 'its', 'did', 'not', 'how', 'but', 'that', 'the', 'the', 'to', 'and', 'her']                                          19                                         0.38                  1\n",
      "Sentence 14              9  ['Cooper', 'could', 'immediately', 'reached', 'comment', '.']                                                                                                                                                                                                                                                                                                                                                                                                                             6  ['not', 'be', 'for']                                                                                                                                                      3                                         0.33                  1\n",
      "Sentence 15             10  ['book', 'guide', 'early', 'childhood', 'educators', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                 6  ['The', 'is', 'a', 'for']                                                                                                                                                 4                                         0.4                   1\n",
      "Sentence 16              9  ['curriculum', 'taught', 'children', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                 4  ['It', 'is', 'not', 'a', 'to']                                                                                                                                            5                                         0.56                  1\n",
      "Sentence 17             49  ['governor', '’', 'office', ',', 'press', 'release', ',', 'cited', 'two', 'examples', 'book', '—', 'one', 'discussing', 'white', 'privilege', '“', 'United', 'States', 'built', 'systemic', 'structural', 'racism', '”', 'another', 'Ivey', \"'s\", 'office', 'claimed', 'teaches', 'LGBTQ+', 'inclusion', '4-year-olds', '.']                                                                                                                                                             34  ['The', 's', 'in', 'a', 'from', 'the', 'and', 'that', 'the', 'is', 'on', 'and', 'and', 'that', 'to']                                                                     15                                         0.31                  1\n",
      "Sentence 18             29  ['sections', ',', 'according', 'copy', '881-page', 'book', 'obtained', 'Associated', 'Press', ',', 'discuss', 'combating', 'bias', 'making', 'sure', 'children', 'feel', 'welcome', '.']                                                                                                                                                                                                                                                                                                 19  ['Those', 'to', 'a', 'of', 'the', 'by', 'The', 'and', 'that', 'all']                                                                                                     10                                         0.34                  1\n",
      "Sentence 19             16  ['Story', 'continues', '“', 'Early', 'childhood', 'programs', 'also', 'serve', 'welcome', 'families', 'represent', 'many', 'compositions', '.']                                                                                                                                                                                                                                                                                                                                          14  ['and', 'that']                                                                                                                                                           2                                         0.12                  1\n",
      "Sentence 20             36  ['Children', 'families', '(', 'e.g.', ',', 'single', 'parent', ',', 'grandparent-led', ',', 'foster', ',', 'LGBTQIA+', ')', 'need', 'hear', 'see', 'messages', 'promote', 'equality', ',', 'dignity', ',', 'worth', ',', '”', 'book', 'states', '.']                                                                                                                                                                                                                                     29  ['from', 'all', 'to', 'and', 'that', 'and', 'the']                                                                                                                        7                                         0.19                  1\n",
      "Sentence 21             37  ['section', 'structural', 'racism', 'states', '“', 'systemic', 'structural', 'racism', '...', 'permeated', 'every', 'institution', 'system', 'policies', 'practices', 'position', 'people', 'color', 'oppressive', ',', 'repressive', ',', 'menial', 'positions', '.']                                                                                                                                                                                                                   25  ['The', 'on', 'that', 'and', 'has', 'and', 'through', 'and', 'that', 'of', 'in', 'and']                                                                                  12                                         0.32                  1\n",
      "Sentence 22             45  ['early', 'education', 'system', 'immune', 'forces.', '”', 'says', 'preschool', 'one', 'place', 'children', '“', 'begin', 'see', 'represented', 'society', '”', 'classroom', 'place', '``', 'affirmation', 'healing', '.', \"''\"]                                                                                                                                                                                                                                                         24  ['The', 'is', 'not', 'to', 'these', 'It', 'is', 'where', 'to', 'how', 'they', 'are', 'in', 'and', 'that', 'the', 'should', 'be', 'a', 'of', 'and']                       21                                         0.47                  2\n",
      "Sentence 23             19  ['NAEYC', 'national', 'accrediting', 'board', 'works', 'provide', 'high-quality', 'education', 'materials', 'resources', 'young', 'children', '.']                                                                                                                                                                                                                                                                                                                                       13  ['is', 'a', 'that', 'to', 'and', 'for']                                                                                                                                   6                                         0.32                  1\n",
      "Sentence 24             28  ['emailed', 'response', 'Associated', 'Press', ',', 'group', 'address', 'Ivey', \"'s\", 'statements', 'said', 'book', 'research-based', 'resource', 'educators', '.']                                                                                                                                                                                                                                                                                                                      16  ['In', 'an', 'to', 'The', 'the', 'did', 'not', 'but', 'the', 'is', 'a', 'for']                                                                                           12                                         0.43                  2\n",
      "Sentence 25             37  ['“', 'nearly', 'four', 'decades', ',', 'partnership', 'hundreds', 'thousands', 'families', 'educators', ',', 'Developmentally', 'Appropriate', 'Practice', 'served', 'foundation', 'high-quality', 'early', 'childhood', 'education', 'across', 'states', 'communities', '.']                                                                                                                                                                                                           24  ['For', 'and', 'in', 'with', 'of', 'of', 'and', 'has', 'as', 'the', 'for', 'all', 'and']                                                                                 13                                         0.35                  2\n",
      "Sentence 26             43  ['curriculum', ',', 'responsive', ',', 'educator-developed', ',', 'educator-informed', ',', 'research-based', 'resource', 'honed', 'multiple', 'generations', 'support', 'teachers', 'helping', 'children', 'thrive', 'reach', 'full', 'potential', ',', \"''\", 'statement', 'read', '.']                                                                                                                                                                                                 26  ['While', 'not', 'a', 'it', 'is', 'a', 'and', 'that', 'has', 'been', 'over', 'to', 'in', 'all', 'and', 'their', 'the']                                                   17                                         0.4                   1\n",
      "Sentence 27              9  ['Cooper', 'member', 'NAEYC', 'board', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                               5  ['is', 'a', 'of', 'the']                                                                                                                                                  4                                         0.44                  1\n",
      "Sentence 28             61  ['previously', 'published', 'statement', 'organization', \"'s\", 'website', 'latest', 'edition', 'book', ',', 'Cooper', 'said', 'book', 'teaches', ',', '“', 'applicable', 'skills', 'teaching', 'developmentally', 'appropriate', 'practices', 'build', 'brains', 'critical', 'first', 'five', 'years', 'life.', '”', 'Alabama', \"'s\", 'First', 'Class', 'voluntary', 'pre-kindergarten', 'programs', 'operates', '1,400', 'classrooms', 'across', 'state', '.']                          43  ['In', 'a', 'on', 'the', 'about', 'the', 'of', 'the', 'that', 'for', 'through', 'that', 'during', 'the', 'of', 'more', 'than', 'the']                                    18                                         0.3                   1\n",
      "Sentence 29             15  ['program', 'high', 'ratings', 'National', 'Institute', 'Early', 'Education', 'Research', '.']                                                                                                                                                                                                                                                                                                                                                                                            9  ['The', 'has', 'won', 'from', 'the', 'for']                                                                                                                               6                                         0.4                   2\n",
      "  Total number of words    Total number of stop words    Maximum number of stop words per sentence    Minimum number of stop words per sentence    Average number of stop words per article\n",
      "-----------------------  ----------------------------  -------------------------------------------  -------------------------------------------  ------------------------------------------\n",
      "                    871                           301                                           22                                            0                                        0.34\n",
      "  Total adjectives    Average number of adjectives in the article\n",
      "------------------  ---------------------------------------------\n",
      "                59                                           0.07\n",
      "  Stanza Average of sentiment score for all sentences    Stanza Maximum sentiment score    Stanza Minimum sentiment score    Stanza Standard deviation  Vader average scores                Vader maximum scores    Vader minimum scores    Vader standard deviation scores       MPQA average scores    MPQA maximum scores    MPQA minimum scores    MPQA standard deviation scores    Sentiwordnet score\n",
      "-----------------------------------------------------  --------------------------------  --------------------------------  ---------------------------  ----------------------------------  ----------------------  ----------------------  ----------------------------------  ---------------------  ---------------------  ---------------------  --------------------------------  --------------------\n",
      "                                              1.10345                                 2                                 0                     0.488791  [0.04834483 0.90672414 0.045     ]  [0.314 1.    0.222]     [0.    0.686 0.   ]     [0.07102126 0.09209886 0.0765709 ]              0.0952381                      1                     -1                          0.839771            0.00733696\n",
      "  Flesch-Kincaid score    Estimated reading level of the article    Flesch-Reading score  The article is classified as      Dale-Chall Readability score  The estimated comprehension level for different grade levels      Automated Readability Index (ARI) score  It corresponds to a grade level of    This means that the text can be read by someone who is around      Coleman-Liau Index Score    Estimated Grade Level    Gunning Fog score  The estimated grade level for comprehension is      SPACHE score    This corresponds to a grade level of    Linsear Write Index score    Approximate grade level equivalent    Perplexity (how well the LDA model predicts the corpus) of the article    Coherence (how coherent the topics are) of the article\n",
      "----------------------  ----------------------------------------  ----------------------  ------------------------------  ------------------------------  --------------------------------------------------------------  -----------------------------------------  ------------------------------------  ---------------------------------------------------------------  --------------------------  -----------------------  -------------------  ------------------------------------------------  --------------  --------------------------------------  ---------------------------  ------------------------------------  ------------------------------------------------------------------------  --------------------------------------------------------\n",
      "               15.9661                                        16                 27.5729  very_confusing                                         11.1017  ['college_graduate']                                                                              17.0138  ['college_graduate']                  [24, 100]                                                                           13.9616                       14              17.2164  college_graduate                                         8.54468                                       9                      19.7759                                    20                                                                  -4.35408                                                  0.506633\n",
      "  Max tree depth  Words at max depth    ,       Average tree length    Maximum tree length    Minimum tree length\n",
      "----------------  --------------------  ----  ---------------------  ---------------------  ---------------------\n",
      "              13  ousted, comes                              7.2963                     13                      2\n",
      "Sentence        Total words  Filtered words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Number of filtered words  Stop words                                                                                                                                                                                                                                      Number of stop words    Average number of stop words per sentence    Sentiment score\n",
      "------------  -------------  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ----------------------  -------------------------------------------  -----------------\n",
      "Sentence 1               39  ['Samantha', 'Cameron', ':', '‘', 'remind', 'David', 'steer', 'clear', 'Aldi', 'middle', 'aisle', '’', 'Every', 'morning', ',', 'Samantha', 'Cameron', 'wakes', '5.45am', 'soothing', 'tones', 'Radio', '4', '’', 'Farming', 'Today', '.']                                                                                                                                                                                                                                                                                                                                     27  ['I', 'have', 'to', 'to', 'of', 'the', 'up', 'at', 'to', 'the', 'of', 's']                                                                                                                                                                                        12                                         0.31                  0\n",
      "Sentence 2               21  ['first', 'activity', 'morning', 'used', 'Ashtanga', 'yoga', ',', 'days', '’', 'busy', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    11  ['Her', 'of', 'the', 'to', 'be', 'but', 'these', 'she', 's', 'too']                                                                                                                                                                                               10                                         0.48                  0\n",
      "Sentence 3               87  ['“', 'know', 'lot', 'milk', 'yields', ',', '”', 'says', ',', 'setting', 'two', 'glasses', 'water', 'eight-seater', 'catering', 'dining', 'table', 'bought', 'temporary', 'stopgap', 'Camerons', 'abruptly', 'left', 'Downing', 'Street', 'seven', 'years', 'ago', 'moved', 'house', ',', 'minds', 'tabloids', ',', 'forever', 'Notting', 'Hil', 'Samantha', 'Cameron', '-', 'Clara', 'Molden', 'Every', 'morning', ',', 'Samantha', 'Cameron', 'wakes', '5.45am', 'soothing', 'tones', 'Radio', '4', '’', 'Farming', 'Today', '.']                                            57  ['I', 'a', 'about', 'she', 'down', 'of', 'on', 'the', 'she', 'as', 'a', 'when', 'the', 'and', 'into', 'the', 'that', 'will', 'in', 'the', 'of', 'the', 'be', 'in', 'up', 'at', 'to', 'the', 'of', 's']                                                            30                                         0.34                  0\n",
      "Sentence 4               21  ['first', 'activity', 'morning', 'used', 'Ashtanga', 'yoga', ',', 'days', '’', 'busy', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    11  ['Her', 'of', 'the', 'to', 'be', 'but', 'these', 'she', 's', 'too']                                                                                                                                                                                               10                                         0.48                  1\n",
      "Sentence 5               68  ['“', 'know', 'lot', 'milk', 'yields', ',', '”', 'says', ',', 'setting', 'two', 'glasses', 'water', 'eight-seater', 'catering', 'dining', 'table', 'bought', 'temporary', 'stopgap', 'Camerons', 'abruptly', 'left', 'Downing', 'Street', 'seven', 'years', 'ago', 'moved', 'house', ',', 'minds', 'tabloids', ',', 'forever', 'Notting', 'Hill', 'actually', 'north', 'Kensington', '.']                                                                                                                                                                                      41  ['I', 'a', 'about', 'she', 'down', 'of', 'on', 'the', 'she', 'as', 'a', 'when', 'the', 'and', 'into', 'the', 'that', 'will', 'in', 'the', 'of', 'the', 'be', 'in', 'but', 'is', 'in']                                                                             27                                         0.4                   0\n",
      "Sentence 6               10  ['’', 'similar', '12-seater', 'basement', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  5  ['There', 's', 'a', 'in', 'the']                                                                                                                                                                                                                                   5                                         0.5                   1\n",
      "Sentence 7               25  ['“', 'idea', 'test-drive', ',', 'see', 'size', 'worked', 'best', ',', 'buy', 'smart', 'version', ',', '”', 'explains', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                   16  ['The', 'was', 'to', 'them', 'both', 'which', 'and', 'a', 'she']                                                                                                                                                                                                   9                                         0.36                  0\n",
      "Sentence 8                9  ['Samantha', 'still', '’', 'found', 'time', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                6  ['hasn', 't', 'the']                                                                                                                                                                                                                                               3                                         0.33                  1\n",
      "Sentence 9               27  ['“', 'could', 'work', 'every', 'day', 'still', '’', 'enough', '–', '’', 'reality', 'running', 'business', '”', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                           15  ['I', 'and', 'it', 'wouldn', 't', 'be', 'that', 's', 'the', 'of', 'your', 'own']                                                                                                                                                                                  12                                         0.44                  1\n",
      "Sentence 10              10  ['past', 'couple', 'years', 'particularly', 'challenging', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 6  ['The', 'of', 'have', 'been']                                                                                                                                                                                                                                      4                                         0.4                   1\n",
      "Sentence 11              28  ['Steering', 'Cefinn', ',', 'fashion', 'label', 'set', '2017', ',', 'pandemic', 'changing', 'post-lockdown', 'landscape', 'walk', 'park', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                 15  ['the', 'she', 'up', 'in', 'through', 'the', 'and', 'the', 'was', 'not', 'a', 'in', 'the']                                                                                                                                                                        13                                         0.46                  0\n",
      "Sentence 12              35  ['Greensill', 'lobbying', 'scandal', 'engulfed', 'husband', '(', 'revealed', 'former', 'prime', 'minister', 'tried', 'secure', 'government', 'loans', 'now-collapsed', 'finance', 'company', ')', '.']                                                                                                                                                                                                                                                                                                                                                                         19  ['Then', 'there', 'was', 'the', 'that', 'her', 'in', 'which', 'it', 'was', 'that', 'the', 'had', 'to', 'for', 'a']                                                                                                                                                16                                         0.46                  0\n",
      "Sentence 13              17  ['David', 'Cameron', '’', 'brother', 'Alex', ',', 'died', ',', 'aged', '59', ',', 'cancer', 'last', 'month', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                              15  ['s', 'of']                                                                                                                                                                                                                                                        2                                         0.12                  1\n",
      "Sentence 14              19  ['eldest', 'daughter', ',', 'Nancy', ',', 'aged', '20', ',', 'left', 'home', 'university', 'study', 'fine', 'art', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                        15  ['And', 'their', 'for', 'to']                                                                                                                                                                                                                                      4                                         0.21                  1\n",
      "Sentence 15              16  ['Camerons', 'two', 'children', '–', 'Arthur', ',', '17', ',', 'Florence', ',', '12', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     12  ['The', 'have', 'other', 'and']                                                                                                                                                                                                                                    4                                         0.25                  0\n",
      "Sentence 16              10  ['first', 'child', 'Ivan', ',', 'tragically', 'died', '2009', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              8  ['Their', 'in']                                                                                                                                                                                                                                                    2                                         0.2                   0\n",
      "Sentence 17              25  ['Samantha', ',', 'one', 'eight', 'siblings', ',', 'despite', 'different', 'parentage', ',', 'close', ',', 'found', 'Nancy', '’', 'departure', 'hard', '.']                                                                                                                                                                                                                                                                                                                                                                                                                    18  ['as', 'of', 'who', 'their', 'are', 'all', 's']                                                                                                                                                                                                                    7                                         0.28                  1\n",
      "Sentence 18               6  ['speak', 'every', 'day', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  4  ['They', 'other']                                                                                                                                                                                                                                                  2                                         0.33                  1\n",
      "Sentence 19              40  ['dissonant', 'murmur', 'say', 'love', 'clothes', 'designs', 'Cefinn', '’', 'bring', 'buy', 'husband', '’', 'hand', 'Brexit', '’', 'particularly', 'bother', '.']                                                                                                                                                                                                                                                                                                                                                                                                              18  ['The', 'from', 'those', 'who', 'they', 'the', 'she', 'for', 'but', 'can', 't', 'themselves', 'to', 'them', 'because', 'of', 'her', 's', 'in', 'doesn', 't', 'her']                                                                                               22                                         0.55                  1\n",
      "Sentence 20              23  ['part', 'huge', 'family', 'trained', 'tune-out', 'noise', '–', 'work', 'anywhere', ',', 'including', 'kitchen', 'breakfast', 'bar', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                      15  ['Being', 'of', 'a', 'her', 'to', 'she', 'can', 'their']                                                                                                                                                                                                           8                                         0.35                  1\n",
      "Sentence 21              11  ['think', 'also', 'means', 'ignore', 'negativity', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         6  ['But', 'I', 'it', 'she', 'can']                                                                                                                                                                                                                                   5                                         0.45                  0\n",
      "Sentence 22              21  ['“', 'One', 'thing', 'develop', '’', 'married', 'someone', 'politics', 'thick', 'skin', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  11  ['you', 'have', 'to', 'if', 'you', 're', 'to', 'in', 'is', 'a']                                                                                                                                                                                                   10                                         0.48                  1\n",
      "Sentence 23              13  ['everyone', '’', 'going', 'like', ',', 'husband', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         7  ['Not', 's', 'to', 'you', 'or', 'your']                                                                                                                                                                                                                            6                                         0.46                  1\n",
      "Sentence 24              27  ['Story', 'continues', '“', 'irk', 'people', 'assume', '’', 'kind', 'rich', 'dilettante', 'dabbling', 'business', ',', '”', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                       16  ['What', 'does', 'me', 'is', 'when', 'I', 'm', 'some', 'of', 'in', 'she']                                                                                                                                                                                         11                                         0.41                  1\n",
      "Sentence 25              79  ['“', '’', 'deadly', 'serious', 'building', 'credible', ',', 'decent', 'British', 'business.', '”', 'Camerons', 'leaving', 'Downing', 'Street', '2016', '-', 'David', 'Rose', 'end', 'last', 'year', ',', 'money', 'young', 'enterprises', 'hard', 'come', ',', 'raised', 'additional', '£1.2', 'million', 'investors', ',', 'used', 'hire', 'staff', '(', '20', ',', 'although', 'remains', 'sole', 'designer', ')', 'produce', 'stock', '.']                                                                                                                                 49  ['I', 'm', 'about', 'a', 'The', 'in', 'At', 'the', 'of', 'when', 'for', 'was', 'to', 'by', 'she', 'an', 'from', 'which', 'she', 'has', 'to', 'more', 'she', 'now', 'has', 'she', 'the', 'and', 'to', 'more']                                                      30                                         0.38                  0\n",
      "Sentence 26              16  ['child', 'always', 'trying', 'sell', 'stuff', '–', 'adulthood', 'succeeded', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              9  ['As', 'a', 'she', 'was', 'to', 'and', 'in']                                                                                                                                                                                                                       7                                         0.44                  1\n",
      "Sentence 27              29  ['creative', 'stewardship', ',', 'Smythson', ',', 'worked', 'two', 'decades', ',', 'went', 'slightly', 'quaint', ',', 'top-drawer', 'stationery', 'company', 'hot', 'leather-goods', 'house', '.']                                                                                                                                                                                                                                                                                                                                                                             20  ['Under', 'her', 'where', 'she', 'for', 'from', 'a', 'to', 'a']                                                                                                                                                                                                    9                                         0.31                  0\n",
      "Sentence 28              18  ['thinks', 'Rishi', 'Sunak', 'good', 'job', '–', '’', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              9  ['She', 'is', 'doing', 'a', 'or', 'that', 's', 'what', 'she']                                                                                                                                                                                                      9                                         0.5                   2\n",
      "Sentence 29              45  ['“', 'Government', 'really', 'wants', 'help', 'business', ',', 'be-all', 'end-all', 'getting', 'inflation', 'control.', '”', 'mother', ',', 'Lady', 'Annabel', 'Astor', ',', 'major', 'business', 'mentor', ',', 'whose', 'influence', 'extended', 'Samantha', '’', 'wardrobe', '.']                                                                                                                                                                                                                                                                                          30  ['But', 'if', 'the', 'to', 'the', 'and', 'is', 'under', 'Her', 'is', 'a', 'of', 'hers', 'to', 's']                                                                                                                                                                15                                         0.33                  2\n",
      "Sentence 30              51  ['“', 'mum', 'wore', 'lot', 'floaty', 'boho', '1970s', 'Downing', 'Street', ',', 'style', 'icon', 'Bianca', 'Jagger', ',', 'Studio', '54', 'days.', '”', 'children', '’', 'style', 'never', 'really', 'able', 'control', ',', 'sighs', '.']                                                                                                                                                                                                                                                                                                                                    29  ['My', 'a', 'of', 'in', 'the', 'and', 'when', 'I', 'was', 'in', 'my', 'was', 'in', 'her', 'Her', 'own', 's', 'she', 'has', 'been', 'to', 'she']                                                                                                                   22                                         0.43                  1\n",
      "Sentence 31              20  ['“', 'Florence', 'went', 'terrible', 'pink', 'phase', 'insisted', 'wearing', 'fancy', 'dress', 'lot', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                    12  ['through', 'a', 'and', 'all', 'of', 'them', 'on', 'a']                                                                                                                                                                                                            8                                         0.4                   0\n",
      "Sentence 32              19  ['One', 'French', 'mother', 'school', 'overhead', 'wondering', 'could', 'let', 'children', 'go', 'like', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                  12  ['at', 'was', 'how', 'I', 'my', 'out', 'that']                                                                                                                                                                                                                     7                                         0.37                  1\n",
      "Sentence 33              57  ['’', 'love', 'know', 'stopped', 'hers.', '”', 'adds', ':', '“', '’', 'strict', 'parents', 'mind', 'lot', 'manners.', '”', '’', 'told', 'ask', 'husband', 'children', ',', '10', 'minutes', ',', 'chatting', '.']                                                                                                                                                                                                                                                                                                                                                              27  ['I', 'd', 'to', 'how', 'she', 'She', 'then', 'We', 're', 'not', 'but', 'we', 'a', 'about', 'I', 've', 'been', 'not', 'to', 'about', 'her', 'or', 'the', 'but', 'in', 'here', 'we', 'are', 'about', 'both']                                                       30                                         0.53                  1\n",
      "Sentence 34              16  ['’', 'makes', 'likeable', '–', 'categorically', 'robot', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  7  ['It', 's', 'what', 'her', 'so', 'she', 'is', 'not', 'a']                                                                                                                                                                                                          9                                         0.56                  0\n",
      "Sentence 35              24  ['Annabel', 'Jones', ',', 'mother', ',', '21', 'Samantha', ',', 'first', 'five', 'children', 'two', 'marriages', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                          14  ['her', 'was', 'only', 'when', 'she', 'had', 'the', 'of', 'her', 'from']                                                                                                                                                                                          10                                         0.42                  1\n",
      "Sentence 36              19  ['(', 'Sir', 'Reginald', 'Sheffield', ',', 'Samantha', '’', 'father', ',', 'another', 'three', 'second', 'wife', ')', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                     15  ['s', 'had', 'with', 'his']                                                                                                                                                                                                                                        4                                         0.21                  1\n",
      "Sentence 37              38  ['Samantha', '’', 'younger', 'sister', ',', 'Emily', ',', 'journalist', 'worked', 'British', 'Vogue', 'decade', 'recently', 'edited', 'London', 'Evening', 'Standard', 'George', 'Osborne', 'stood', 'role', '.']                                                                                                                                                                                                                                                                                                                                                              22  ['s', 'is', 'a', 'who', 'at', 'for', 'more', 'than', 'a', 'and', 'more', 'the', 'after', 'down', 'from', 'that']                                                                                                                                                  16                                         0.42                  0\n",
      "Sentence 38              16  ['serial', 'entrepreneur', ',', 'Annabel', 'co-founded', 'Oka', ',', 'hugely', 'successful', 'furniture', 'company', '1999', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                              13  ['A', 'the', 'in']                                                                                                                                                                                                                                                 3                                         0.19                  1\n",
      "Sentence 39              26  ['“', '’', 'know', 'us', 'three', 'five', 'children', 'run', 'businesses', ',', '”', 'observes', 'Samantha', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                              14  ['I', 'don', 't', 'what', 'she', 'did', 'to', 'but', 'of', 'her', 'our', 'own']                                                                                                                                                                                   12                                         0.46                  1\n",
      "Sentence 40              82  ['Samantha', 'Cameron', '-', 'Clara', 'Molden', 'Despite', 'father', '8th', 'Baronet', 'Sutton', 'Park', '(', 'Grade', 'listed', 'slice', 'Georgian', 'loveliness', ',', 'recently', 'used', 'location', 'BBC', 'hit', 'series', 'Gentleman', 'Jack', ')', 'related', ',', 'mother', '’', 'second', 'marriage', ',', 'sprawling', ',', 'wealthy', 'Astor', 'clan', ',', 'Samantha', 'Cameron', 'never', 'portrayed', 'media', 'latter-day', 'Marie', 'Antoinette', ',', 'unlike', 'Carrie', 'Johnson', ',', 'chippy', 'like', 'Cherie', 'Blair', '.']                          58  ['her', 'being', 'the', 'of', 'a', 'I', 'of', 'most', 'as', 'a', 'in', 'the', 'and', 'through', 'her', 's', 'to', 'the', 'was', 'in', 'the', 'as', 'a', 'nor']                                                                                                    24                                         0.29                  1\n",
      "Sentence 41              15  ['get', 'flak', 'wearing', 'designer', 'outfits', 'immediate', 'predecessors', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             8  ['Nor', 'did', 'she', 'for', 'more', 'than', 'her']                                                                                                                                                                                                                7                                         0.47                  1\n",
      "Sentence 42              29  ['justified', 'official', 'ambassador', 'London', 'Fashion', 'Week', '–', 'promoting', 'British', 'Fashion', ',', 'media', 'left', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                        14  ['She', 'them', 'by', 'being', 'an', 'for', 'she', 'was', 'after', 'all', 'and', 'the', 'it', 'at', 'that']                                                                                                                                                       15                                         0.52                  1\n",
      "Sentence 43              29  ['clothes', 'occupy', 'wardrobe', 'cottage', 'near', 'Chipping', 'Norton', 'Cotswolds', ',', 'formal', 'current', 'life', ',', 'although', 'Nancy', 'sometimes', 'borrows', '.']                                                                                                                                                                                                                                                                                                                                                                                               18  ['The', 'now', 'a', 'in', 'their', 'in', 'the', 'too', 'for', 'her', 'them']                                                                                                                                                                                      11                                         0.38                  1\n",
      "Sentence 44              45  ['Probably', 'posh', 'prepared', 'enjoy', 'good', 'parts', ',', 'Samantha', 'found', 'Downing', 'Street', 'years', 'positive', 'experience', ',', '’', 'overcome', 'concerns', 'moving', 'children', 'away', 'normal', 'lives', 'First', 'Family', 'bubble', '.']                                                                                                                                                                                                                                                                                                              27  ['because', 'she', 'is', 'and', 'to', 'the', 'the', 'a', 'once', 'she', 'd', 'her', 'about', 'the', 'from', 'their', 'into', 'a']                                                                                                                                 18                                         0.4                   2\n",
      "Sentence 45              11  ['“', 'Living', '11', 'Downing', 'Street', 'actually', 'highlight', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        8  ['in', 'was', 'a']                                                                                                                                                                                                                                                 3                                         0.27                  0\n",
      "Sentence 46              12  ['meant', 'Dave', 'got', 'see', 'lot', 'children', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         7  ['It', 'to', 'a', 'of', 'the']                                                                                                                                                                                                                                     5                                         0.42                  0\n",
      "Sentence 47              23  ['would', 'get', '5', ',', 'start', 'work', ',', 'pop', 'back', 'breakfast', 'work', '8', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 13  ['He', 'up', 'at', 'then', 'for', 'and', 'be', 'at', 'again', 'by']                                                                                                                                                                                               10                                         0.43                  1\n",
      "Sentence 48              17  ['flat', 'huge', ',', 'like', 'house', 'within', 'house', ',', 'quiet', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   10  ['The', 'there', 'is', 'a', 'a', 'and', 'so']                                                                                                                                                                                                                      7                                         0.41                  1\n",
      "Sentence 49               5  ['rooms', 'beautiful', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     3  ['The', 'are']                                                                                                                                                                                                                                                     2                                         0.4                   1\n",
      "Sentence 50              15  ['end', ',', 'thing', 'children', 'moaned', 'bedrooms', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    7  ['In', 'the', 'the', 'only', 'the', 'about', 'was', 'their']                                                                                                                                                                                                       8                                         0.53                  0\n",
      "Sentence 51               3  ['big', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2  ['Too']                                                                                                                                                                                                                                                            1                                         0.33                  2\n",
      "Sentence 52               8  ['friends', 'cosy', 'little', 'attics', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    5  ['All', 'their', 'had']                                                                                                                                                                                                                                            3                                         0.38                  2\n",
      "Sentence 53              32  ['used', 'tell', ',', '‘', '’', 'worry', ',', '’', 'tiny', 'bedrooms', 'soon', 'enough', '’', '.', '”', 'regrets', 'time', '?']                                                                                                                                                                                                                                                                                                                                                                                                                                                18  ['I', 'to', 'them', 'Don', 't', 'you', 'll', 'be', 'in', 'So', 'no', 'about', 'her', 'there']                                                                                                                                                                     14                                         0.44                  0\n",
      "Sentence 54              17  ['“', 'think', 'got', 'wardrobe', 'pretty', 'right', 'terrified', 'public', 'speaking', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   10  ['I', 'I', 'the', 'but', 'I', 'was', 'of']                                                                                                                                                                                                                         7                                         0.41                  1\n",
      "Sentence 55              11  ['Michelle', 'Obama', 'not.', '”', 'worshipped', 'Michelle', 'Obama', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      8  ['I', 'was', 'She']                                                                                                                                                                                                                                                3                                         0.27                  0\n",
      "Sentence 56              21  ['“', '’', 'charismatic', 'naturally', 'engage', 'audience.', '”', 'Angela', 'Merkel', '“', 'huge', 'fun', '”', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                           14  ['She', 's', 'so', 'and', 'can', 'an', 'is']                                                                                                                                                                                                                       7                                         0.33                  2\n",
      "Sentence 57              14  ['Cherie', 'Blair', '“', 'really', 'helpful', 'whenever', 'asked', 'advice', '”', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         10  ['was', 'I', 'her', 'for']                                                                                                                                                                                                                                         4                                         0.29                  1\n",
      "Sentence 58               3  ['Carla', 'Bruni', '?']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         3  []                                                                                                                                                                                                                                                                 0                                         0                     1\n",
      "Sentence 59              31  ['“', 'nightmare', 'standing', 'next', '’', 'five', 'months', '’', 'pregnant', ',', 'manners', 'incredible', 'always', 'top', 'brief', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                    16  ['A', 'to', 'her', 'when', 'you', 're', 'but', 'her', 'are', 'and', 'she', 'was', 'on', 'of', 'her']                                                                                                                                                              15                                         0.48                  1\n",
      "Sentence 60              30  ['Also', ',', 'sounds', 'corny', ',', 'hosting', 'charity', 'events', '10', 'meet', 'amazing', 'people', 'away', 'spotlight.', '”', 'pauses', '.']                                                                                                                                                                                                                                                                                                                                                                                                                             17  ['it', 'but', 'at', 'No', 'you', 'the', 'most', 'doing', 'it', 'all', 'from', 'the', 'She']                                                                                                                                                                       13                                         0.43                  1\n",
      "Sentence 61              61  ['“', 'seems', 'like', 'dream', 'now.', '”', 'Cameron', 'Michelle', 'Obama', '2015', 'visit', '-', 'Geoff', 'Pugh', 'One', 'youngest', 'ever', 'prime', 'ministerial', 'wives', ',', '45', ',', 'dressed', 'swirly-patterned', 'Roksanda', 'dress', '’', 'hurriedly', 'bought', 'online', 'event', ',', 'walked', 'Downing', 'Street', 'last', 'time', '.']                                                                                                                                                                                                                    39  ['It', 'all', 'a', 'and', 'during', 'a', 'of', 'the', 'she', 'was', 'when', 'in', 'a', 'she', 'd', 'for', 'the', 'she', 'out', 'of', 'for', 'the']                                                                                                                22                                         0.36                  1\n",
      "Sentence 62              13  ['’', ',', 'must', 'said', ',', 'look', 'distraught', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      8  ['She', 'didn', 't', 'it', 'be']                                                                                                                                                                                                                                   5                                         0.38                  0\n",
      "Sentence 63              43  ['Maybe', ',', 'gone', 'part-time', 'creative', 'director', 'role', 'Smythson', 'ensure', 'transition', 'life', 'Downing', 'Street', 'would', 'smooth', 'possible', 'young', 'family', ',', 'looking', 'forward', 'stepping', 'career', '?']                                                                                                                                                                                                                                                                                                                                   24  ['having', 'in', 'her', 'at', 'to', 'the', 'to', 'in', 'be', 'as', 'as', 'for', 'their', 'she', 'was', 'to', 'up', 'her', 'again']                                                                                                                                19                                         0.44                  1\n",
      "Sentence 64              32  ['transpired', '’', 'preparing', '“', 'life', 'outside', '”', 'still', 'Number', '11', ',', 'taking', 'online', 'pattern-cutting', 'course', 'hiring', 'teacher', 'help', 'practise', '.']                                                                                                                                                                                                                                                                                                                                                                                     20  ['It', 'she', 'd', 'been', 'for', 'while', 'in', 'an', 'and', 'a', 'to', 'her']                                                                                                                                                                                   12                                         0.38                  0\n",
      "Sentence 65              41  ['“', 'whole', 'time', ',', 'Dave', 'aware', 'going', 'end', 'point', ',', 'determined', 'keep', 'things', 'normal', 'possible', ',', '”', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                        19  ['The', 'we', 'were', 'there', 'and', 'I', 'were', 'very', 'that', 'it', 'was', 'all', 'to', 'at', 'some', 'so', 'we', 'were', 'to', 'as', 'as', 'she']                                                                                                           22                                         0.54                  0\n",
      "Sentence 66              15  ['“', 'children', 'stayed', 'schools', ',', 'kept', 'friends', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             8  ['The', 'at', 'the', 'same', 'we', 'the', 'same']                                                                                                                                                                                                                  7                                         0.47                  1\n",
      "Sentence 67              39  ['helpful', 'get', 'paranoid', 'deciding', 'whether', 'trust', 'people.', '”', 'Despite', 'jokes', 'shepherds', '’', 'huts', 'golf', 'awaydays', ',', 'Camerons', 'appeared', 'adjusting', 'well', 'civvy', 'street', '.']                                                                                                                                                                                                                                                                                                                                                     23  ['That', 'was', 'because', 'you', 'can', 'or', 'not', 'you', 'can', 'the', 'about', 'and', 'the', 'to', 'be', 'to']                                                                                                                                               16                                         0.41                  2\n",
      "Sentence 68              79  ['Kensington', 'red-brick', 'terraced', 'house', ',', 'nowhere', 'grand', 'Blairs', '’', 'Georgian', 'pile', 'north', 'Hyde', 'Park', ',', 'airy', 'stylish', '–', 'black', 'Crittall', 'wooden', 'floors', 'onto', 'juicy-looking', 'lawn', ',', 'slightly', 'industrial', 'shelving', 'Vitsoe', 'see', 'every', 'architect', '’', 'home', ',', 'next', 'luxe-looking', ',', 'yellow', 'upholstered', 'sofas', '“', 'forever', '”', 'wicker', 'armchair', 'bought', 'points', 'earned', 'Soho', 'House', 'membership', '.']                                                   54  ['Their', 'while', 'as', 'as', 'the', 'just', 'off', 'is', 'and', 'a', 'that', 'from', 'you', 'in', 's', 'to', 'she', 'has', 'had', 'and', 'a', 'she', 'with', 'from', 'her']                                                                                     25                                         0.32                  1\n",
      "Sentence 69              40  ['’', 'Lynn', 'Chadwick', 'abstract', 'print', '–', 'present', 'David', ',', 'rather', 'good', 'drawings', 'children', ',', 'including', 'one', 'son', 'Arthur', 'two', 'surviving', 'chickens', ',', 'next', 'David', 'Hockney', 'print', '.']                                                                                                                                                                                                                                                                                                                                27  ['There', 's', 'a', 'a', 'from', 'by', 'her', 'by', 'her', 'of', 'their', 'to', 'a']                                                                                                                                                                              13                                         0.33                  1\n",
      "Sentence 70              70  ['another', 'shelf', ',', '’', 'Matryoshka', 'doll', 'picture', 'Theresa', 'May', '’', 'face', 'front', '(', 'present', 'mischievous', 'friend', ')', ',', 'one', 'mini', 'waving', 'Queen', 'Elizabeth', 'statues', 'kneeling', 'Winston', 'Churchill', ',', 'gold', 'table', 'lamp', 'Tom', 'Dixon', 'designed', 'Habitat', ',', 'lots', 'books', ',', 'political', 'novels', '.']                                                                                                                                                                                           42  ['On', 'there', 's', 'a', 'with', 'a', 'of', 's', 'on', 'the', 'a', 'from', 'a', 'of', 'those', 'll', 'with', 'a', 'a', 'that', 'when', 'he', 'was', 'at', 'and', 'of', 'both', 'and']                                                                            28                                         0.4                   2\n",
      "Sentence 71              21  ['senior', 'Camerons', 'read', 'voraciously', '–', 'Samantha', 'problems', 'learning', '’', 'master', 'seven', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                            12  ['Both', 'had', 'and', 'didn', 't', 'it', 'until', 'she', 'was']                                                                                                                                                                                                   9                                         0.43                  1\n",
      "Sentence 72              20  ['spent', 'months', 'teaching', 'school', 'dyslexics', ',', 'children', 'dyslexic', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        9  ['She', 'once', 'a', 'few', 'at', 'a', 'for', 'and', 'all', 'their', 'are']                                                                                                                                                                                       11                                         0.55                  1\n",
      "Sentence 73              17  ['Tellingly', ',', 'finally', 'learned', 'read', ',', 'would', 'devour', '10', 'books', 'week', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                           12  ['once', 'she', 'to', 'she', 'a']                                                                                                                                                                                                                                  5                                         0.29                  0\n",
      "Sentence 74              13  ['’', 'finished', 'Barbara', 'Kingsolver', '’', 'excellent', 'Demon', 'Copperhead', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        9  ['She', 's', 'just', 's']                                                                                                                                                                                                                                          4                                         0.31                  1\n",
      "Sentence 75              32  ['Hanging', 'open-plan', 'kitchen', ':', 'David', 'Mellor', 'saucepans', 'given', 'wedding', '1996', 'hallway', ',', 'glossy', 'black-and-white', 'photographs', 'children', '.']                                                                                                                                                                                                                                                                                                                                                                                              17  ['in', 'the', 'some', 'they', 'were', 'for', 'their', 'in', 'and', 'in', 'the', 'of', 'them', 'with', 'the']                                                                                                                                                      15                                         0.47                  0\n",
      "Sentence 76              17  ['home', 'perfect', 'compendium', 'old', ',', 'new', 'vintage', ',', 'high', 'low', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       11  ['Their', 'is', 'a', 'of', 'and', 'and']                                                                                                                                                                                                                           6                                         0.35                  1\n",
      "Sentence 77              16  ['David', 'Cameron', ',', 'transpires', ',', 'loves', 'shop', 'Chipping', 'Norton', '’', 'Aldi', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                          12  ['it', 'to', 'in', 's']                                                                                                                                                                                                                                            4                                         0.25                  1\n",
      "Sentence 78              33  ['“', '’', 'quite', 'good', 'steering', 'away', 'middle', 'aisle', '[', 'plastic', 'foot', 'spas', 'junk', ']', 'sometimes', 'remind', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                    17  ['He', 's', 'at', 'from', 'the', 'where', 'all', 'the', 'and', 'other', 'are', 'but', 'I', 'have', 'to', 'him']                                                                                                                                                   16                                         0.48                  1\n",
      "Sentence 79              33  ['favourite', 'activity', 'food', 'shopping', 'cooking', 'kids.', '”', 'David', 'Cameron', 'Samantha', 'Cameron', '-', 'Ricky', 'Vigil', ',', 'meanwhile', ',', 'probably', 'browsing', 'vintage', 'furniture', 'website', 'vinterior.co', '.']                                                                                                                                                                                                                                                                                                                                24  ['His', 'is', 'and', 'with', 'the', 'and', 'Hers', 'is', 'on']                                                                                                                                                                                                     9                                         0.27                  1\n",
      "Sentence 80              21  ['another', 'life', ',', 'could', 'successful', 'interior', 'designer', '–', 'kind', 'finds', 'pretty', 'cushions', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                       13  ['In', 'she', 'be', 'a', 'not', 'the', 'that', 'just']                                                                                                                                                                                                             8                                         0.38                  2\n",
      "Sentence 81               9  ['obsessed', 'mathematics', 'design', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      4  ['She', 'is', 'with', 'the', 'of']                                                                                                                                                                                                                                 5                                         0.56                  1\n",
      "Sentence 82              33  ['’', 'one', 'measured', 'kitchen', ',', 'cereal', 'drawer', ',', 'made', 'sure', 'right', 'height', 'every', 'known', 'brand', 'cereal', 'packet', '.']                                                                                                                                                                                                                                                                                                                                                                                                                       18  ['She', 's', 'the', 'who', 'out', 'their', 'down', 'to', 'the', 'which', 'she', 'was', 'the', 'for', 'of']                                                                                                                                                        15                                         0.45                  2\n",
      "Sentence 83              34  [',', '’', 'key', 'insight', 'brain', 'works', 'wanted', 'start', 'Cefinn', ',', 'always', 'said', '“', 'problem', 'solving', '”', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                        17  ['For', 'me', 'that', 's', 'a', 'into', 'how', 'her', 'and', 'why', 'she', 'to', 'which', 'she', 'has', 'is', 'about']                                                                                                                                            17                                         0.5                   1\n",
      "Sentence 84              57  ['intelligent', 'edit', 'smart', 'expensive', 'workwear', 'women', 'aged', '35', '55', ',', 'want', 'come', 'across', 'professional', 'sleekly', 'modern', '(', '“', 'kind', 'thing', 'struggled', 'find', '10', ')', '”', ',', 'without', 'looking', 'corporate', ',', 'label', 'well', 'received', 'start', '.']                                                                                                                                                                                                                                                             35  ['With', 'its', 'of', 'but', 'not', 'too', 'for', 'to', 'who', 'to', 'as', 'and', 'the', 'of', 'I', 'to', 'in', 'No', 'the', 'was', 'from', 'the']                                                                                                                22                                         0.39                  1\n",
      "Sentence 85              21  ['came', 'Covid', ',', 'bad', 'anyone', 'selling', 'clothes', ',', 'breakpoint', 'someone', 'selling', 'stylish', 'office', 'clothes', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                    15  ['Then', 'which', 'was', 'for', 'but', 'for']                                                                                                                                                                                                                      6                                         0.29                  1\n",
      "Sentence 86              15  ['“', 'definitely', 'put', 'spanner', 'original', 'forecasts', ',', '”', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          10  ['It', 'a', 'in', 'my', 'she']                                                                                                                                                                                                                                     5                                         0.33                  1\n",
      "Sentence 87               6  ['“', 'pivoted', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           3  ['But', 'then', 'we']                                                                                                                                                                                                                                              3                                         0.5                   1\n",
      "Sentence 88              33  ['started', 'knitwear.', '”', 'One', 'item', 'particular', ',', 'ribbed', 'roll-neck', 'became', 'huge', 'bestseller', 'expanded', 'range', 'knits', 'accounts', '27', 'per', 'cent', 'sales', '.']                                                                                                                                                                                                                                                                                                                                                                            21  ['We', 'doing', 'more', 'in', 'a', 'a', 'and', 'their', 'of', 'now', 'for', 'of']                                                                                                                                                                                 12                                         0.36                  0\n",
      "Sentence 89              14  ['introduced', 'casual', 'cotton', 'dresses', 'hit', ',', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  7  ['She', 'more', 'and', 'they', 'were', 'a', 'too']                                                                                                                                                                                                                 7                                         0.5                   1\n",
      "Sentence 90              36  ['past', 'year', ',', 'branched', 'special', 'occasion', 'items', '–', 'kind', 'pretty', 'silk', 'viscose', 'dresses', 'could', 'wear', 'heels', 'wedding', '–', 'Coronation', '.']                                                                                                                                                                                                                                                                                                                                                                                            20  ['In', 'the', 'she', 'has', 'into', 'more', 'the', 'of', 'and', 'you', 'with', 'to', 'a', 'or', 'to', 'a']                                                                                                                                                        16                                         0.44                  2\n",
      "Sentence 91               5  ['Camerons', 'going', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      3  ['The', 'are']                                                                                                                                                                                                                                                     2                                         0.4                   0\n",
      "Sentence 92              11  ['“', 'really', 'quite', 'thrilled', ',', '”', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     8  ['I', 'am', 'she']                                                                                                                                                                                                                                                 3                                         0.27                  0\n",
      "Sentence 93              23  ['“', 'might', 'able', 'see', 'much', 'love', 'Westminster', 'Abbey', '–', 'much', 'nicer', 'St', 'Paul', '’', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                            15  ['We', 'not', 'be', 'to', 'but', 'I', 'than', 's']                                                                                                                                                                                                                 8                                         0.35                  1\n",
      "Sentence 94              29  ['’', 'wonderful', 'part', 'history.', '”', '’', 'wearing', 'Cefinn', ',', 'course', ',', 'millinery', 'friend', 'Jess', 'Collett', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                       16  ['And', 'it', 's', 'to', 'be', 'of', 'She', 'll', 'be', 'of', 'and', 'by', 'her']                                                                                                                                                                                 13                                         0.45                  0\n",
      "Sentence 95              29  ['(', 'famously', '’', 'wear', 'hat', 'Kate', 'William', '’', 'wedding', ',', 'Anna', 'Wintour', 'approved', ',', 'traditionalists', 'turned', 'purple', ')', '.']                                                                                                                                                                                                                                                                                                                                                                                                             19  ['She', 'didn', 't', 'a', 'to', 'and', 's', 'and', 'while', 'the']                                                                                                                                                                                                10                                         0.34                  0\n",
      "Sentence 96              31  ['David', 'Cameron', ',', 'Samantha', 'Cameron', ',', 'Nick', 'Clegg', 'Miriam', 'Gonzalez', 'Durantez', '-', 'ANTHONY', 'DEVLIN/AFP', '“', 'People', 'want', 'clothes', 'work', 'much', 'harder', 'days', ',', '”', 'notes', '.']                                                                                                                                                                                                                                                                                                                                             26  ['and', 'their', 'to', 'these', 'she']                                                                                                                                                                                                                             5                                         0.16                  2\n",
      "Sentence 97              86  ['“', 'sister', 'Lucy', '[', 'Sir', 'Reginald', '’', 'second', 'marriage', ']', ',', '’', '11', 'years', 'younger', ',', 'wears', 'green', 'Cefinn', 'party', 'dress', 'work', 'jacket', 'flat', 'boots', '’', 'always', 'complimented', 'Tube.', '”', 'outfit', 'Samantha', '’', 'wearing', 'meet', '–', 'navy', 'silk', 'skirt', 'matching', 'blouse', 'attached', 'navy', 'tank', 'top', '–', 'precisely', 'kind', 'dressed', '.']                                                                                                                                          50  ['My', 'from', 's', 'who', 's', 'than', 'me', 'a', 'to', 'with', 'a', 'and', 'and', 'she', 's', 'being', 'on', 'the', 'The', 's', 'when', 'we', 'a', 'with', 'a', 'with', 'an', 'is', 'the', 'that', 'can', 'all', 'be', 'up', 'or', 'down']                      36                                         0.42                  1\n",
      "Sentence 98              65  ['’', 'blinged', 'chunky', 'gold', 'hoops', 'Sezane', ',', 'fashion', 'cognoscenti', '’', 'favourite', 'French', 'brand', ',', 'cream', 'Stella', 'McCartney-esque', 'flatform', 'brogues', 'found', 'Aldo', '–', '’', 'sucker', 'shoes', ',', 'says', '–', '’', 'pay', 'big', 'money', 'Zara', 'Mango', '.']                                                                                                                                                                                                                                                                  35  ['She', 's', 'it', 'up', 'with', 'some', 'from', 'the', 's', 'and', 'that', 'she', 'in', 'she', 's', 'a', 'for', 'she', 'but', 'won', 't', 'for', 'them', 'so', 'most', 'of', 'hers', 'are', 'from', 'or']                                                        30                                         0.46                  1\n",
      "Sentence 99              28  ['Eventually', 'plans', 'launch', 'shoe', 'line', 'see', 'gap', 'stylish', 'shoes', 'kind', 'prices', 'wants', 'pay', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                     14  ['she', 'to', 'her', 'own', 'because', 'she', 'can', 'a', 'for', 'at', 'the', 'of', 'she', 'to']                                                                                                                                                                  14                                         0.5                   2\n",
      "Sentence 100             22  ['“', 'Ultimately', '’', 'like', 'Cefinn', 'brand', 'women', 'come', 'style', 'solutions', '”', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                           12  ['I', 'd', 'to', 'be', 'a', 'where', 'can', 'for', 'all', 'their']                                                                                                                                                                                                10                                         0.45                  2\n",
      "Sentence 101             11  ['summer', 'launching', 'range', 'holiday', 'dresses', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     6  ['This', 'she', 'is', 'a', 'of']                                                                                                                                                                                                                                   5                                         0.45                  1\n",
      "Sentence 102             46  ['never', 'seen', 'without', 'impeccably', 'applied', 'make-up', '(', '“', 'terrible', 'acne', 'young', '’', 'always', 'worn', 'make-up', '”', ')', ',', 'plans', 'Victoria', 'Beckham', 'launch', 'beauty', 'range', '.']                                                                                                                                                                                                                                                                                                                                                     25  ['But', 'while', 'I', 'have', 'her', 'I', 'had', 'when', 'I', 'was', 'so', 'I', 've', 'she', 'has', 'no', 'to', 'do', 'a', 'and', 'a']                                                                                                                            21                                         0.46                  1\n",
      "Sentence 103             11  ['gets', 'huge', 'kick', 'seeing', 'women', 'wearing', 'clothes', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          8  ['She', 'a', 'her']                                                                                                                                                                                                                                                3                                         0.27                  1\n",
      "Sentence 104             44  ['Sophie', 'Raworth', ',', 'Fiona', 'Bruce', ',', 'Princess', 'Wales', ',', 'Queen', 'Camilla', ',', 'Queen', 'Rania', 'Jordan', ',', 'Gillian', 'Anderson', ',', 'Keeley', 'Hawes', ',', 'Amy', 'Schumer', ',', 'Olivia', 'Colman', 'spotted', 'Cefinn', '–', 'Samantha', 'volunteers', 'information', '.']                                                                                                                                                                                                                                                                   34  ['the', 'of', 'of', 'have', 'all', 'been', 'in', 'not', 'that', 'this']                                                                                                                                                                                           10                                         0.23                  1\n",
      "Sentence 105             15  ['reticent', 'blabbing', 'wears', 'clothes', 'case', 'looks', 'grabby', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    8  ['She', 'is', 'about', 'who', 'her', 'in', 'it']                                                                                                                                                                                                                   7                                         0.47                  1\n",
      "Sentence 106             56  ['biggest', '“', 'get', '”', 'recently', 'Sienna', 'Miller', ',', 'fabulously', 'stylish', 'Cefinn', '(', 'Max', 'Mara', 'Row', ')', 'Anatomy', 'Scandal', ',', 'Netflix', 'hit', 'fictional', 'Tory', 'PM', 'whose', 'bad', 'behaviour', 'member', 'notorious', 'drinking', 'club', 'Oxford', 'catches', '.']                                                                                                                                                                                                                                                                 34  ['The', 'was', 'in', 'and', 'and', 'The', 'in', 'of', 'a', 'the', 'about', 'a', 'while', 'he', 'was', 'a', 'of', 'a', 'at', 'up', 'with', 'him']                                                                                                                  22                                         0.39                  1\n",
      "Sentence 107             13  ['“', 'Remind', 'anyone', '?', '”', 'Theresa', 'May', 'might', 'ask', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     10  ['you', 'of', 'as']                                                                                                                                                                                                                                                3                                         0.23                  0\n",
      "Sentence 108             32  ['Princess', 'Wales', 'wearing', 'Cefinn', 'shirt', 'visit', 'Glasgow', '2022', '-', 'Chris', 'Jackson', 'Samantha', 'watch', 'Sienna', 'Miller', '’', 'chic', 'descent', 'cuckolded', 'wife', 'hell', '?']                                                                                                                                                                                                                                                                                                                                                                    22  ['The', 'of', 'a', 'on', 'a', 'to', 'in', 'Did', 's', 'into']                                                                                                                                                                                                     10                                         0.31                  1\n",
      "Sentence 109             35  ['Yes', ',', 'says', ',', 'deftly', 'steering', 'conversation', 'latest', 'TV', 'addiction', '–', 'Fleishman', 'Trouble', ',', 'based', 'piercing', 'New', 'York', 'Times', 'best-seller', 'divorced', 'middle-aged', 'Manhattan', 'couple', '.']                                                                                                                                                                                                                                                                                                                              25  ['she', 'the', 'to', 'her', 'Is', 'in', 'on', 'the', 'about', 'a']                                                                                                                                                                                                10                                         0.29                  1\n",
      "Sentence 110              7  ['’', 'smooth', 'operator', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                4  ['She', 's', 'a']                                                                                                                                                                                                                                                  3                                         0.43                  2\n",
      "Sentence 111             39  ['jobs', ',', '’', 'met', 'many', 'times', '–', 'long', 'Downing', 'Street', '–', 'although', 'always', 'seems', 'preternaturally', 'calm', ',', 'underneath', ',', 'think', '’', 'probably', 'quite', 'lot', 'agonising', '.']                                                                                                                                                                                                                                                                                                                                                26  ['Through', 'our', 'I', 've', 'her', 'before', 'and', 'she', 'I', 'there', 's', 'a', 'of']                                                                                                                                                                        13                                         0.33                  2\n",
      "Sentence 112             20  ['dust', 'parents', '’', 'divorce', 'settled', ',', 'exes', 'new', 'spouses', 'became', 'great', 'friends', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                               13  ['Once', 'the', 'of', 'her', 'the', 'and', 'their']                                                                                                                                                                                                                7                                         0.35                  0\n",
      "Sentence 113             19  ['two', 'families', 'would', 'holiday', 'together', 'Astors', '’', 'estate', 'Scotland', 'caravan', 'children', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                           12  ['The', 'at', 'the', 'in', 'with', 'their', 'of']                                                                                                                                                                                                                  7                                         0.37                  1\n",
      "Sentence 114             20  ['“', 'Bringing', 'new', 'boyfriends', 'back', 'meet', 'opinionated', 'siblings', 'quite', 'test', ',', '”', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                      14  ['to', 'all', 'these', 'was', 'a', 'she']                                                                                                                                                                                                                          6                                         0.3                   0\n",
      "Sentence 115             30  ['“', 'first', 'ever', 'boyfriend', 'spent', 'entire', 'evening', 'shaking.', '”', 'David', ',', 'initially', 'met', 'sister', 'Clare', ',', 'passed', 'flying', 'colours', ',', 'course', '.']                                                                                                                                                                                                                                                                                                                                                                                22  ['My', 'the', 'whom', 'she', 'through', 'his', 'with', 'of']                                                                                                                                                                                                       8                                         0.27                  1\n",
      "Sentence 116             24  ['“', '’', 'large', 'family', 'too.', '”', 'love', '“', 'ferally', '”', 'cousins', 'get', 'together', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                     14  ['He', 's', 'from', 'a', 'They', 'both', 'it', 'when', 'all', 'the']                                                                                                                                                                                              10                                         0.42                  2\n",
      "Sentence 117             17  ['sounds', 'solid', 'wonder', 'recipe', 'long', 'happy', 'marriage', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       8  ['It', 'all', 'so', 'I', 'what', 'her', 'is', 'for', 'a']                                                                                                                                                                                                          9                                         0.53                  1\n",
      "Sentence 118             21  ['“', 'Try', 'remember', 'kind', 'respectful…', '’', 'lucky', 'neither', 'us', 'confrontational', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                         11  ['to', 'to', 'be', 'and', 'we', 're', 'in', 'that', 'of', 'is']                                                                                                                                                                                                   10                                         0.48                  2\n",
      "Sentence 119              8  ['really', '’', 'row', 'much', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             5  ['We', 'don', 't']                                                                                                                                                                                                                                                 3                                         0.38                  0\n",
      "Sentence 120             18  ['’', 'argumentative', '’', 'like', 'go', 'bed', 'quarrel', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                8  ['I', 'm', 'but', 'I', 'don', 't', 'to', 'to', 'on', 'a']                                                                                                                                                                                                         10                                         0.56                  1\n",
      "Sentence 121             15  ['think', '’', 'one', 'eight', 'learn', 'conciliatory', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    7  ['I', 'when', 'you', 're', 'of', 'you', 'to', 'be']                                                                                                                                                                                                                8                                         0.53                  1\n",
      "Sentence 122             24  ['observer', 'also', 'know', 'make', 'heard', 'necessary.', '”', 'Camerons', 'sticklers', 'routine', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                      11  ['You', 'have', 'to', 'be', 'an', 'but', 'how', 'to', 'yourself', 'when', 'Both', 'are', 'for']                                                                                                                                                                   13                                         0.54                  0\n",
      "Sentence 123             24  ['“', 'Without', ',', 'big', 'family', ',', 'mealtimes', 'would', 'never', 'happen.', '”', 'upsides', 'one', 'eight', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                     15  ['it', 'in', 'a', 'Those', 'are', 'the', 'of', 'being', 'of']                                                                                                                                                                                                      9                                         0.38                  1\n",
      "Sentence 124             14  ['downsides', ',', 'says', ',', 'tend', 'greedy', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          7  ['The', 'she', 'are', 'that', 'you', 'to', 'be']                                                                                                                                                                                                                   7                                         0.5                   0\n",
      "Sentence 125             12  ['’', 'never', 'known', 'diet', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            5  ['I', 've', 'not', 'her', 'be', 'on', 'a']                                                                                                                                                                                                                         7                                         0.58                  0\n",
      "Sentence 126              8  ['currently', '5:2', 'diet', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               4  ['She', 'is', 'on', 'the']                                                                                                                                                                                                                                         4                                         0.5                   1\n",
      "Sentence 127             27  ['looks', 'extremely', 'slender', ',', 'claims', '“', 'half-stone', 'put', 'menopause', 'much', 'harder', 'shift', '’', '52', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                             15  ['She', 'but', 'that', 'you', 'on', 'in', 'is', 'so', 'to', 'now', 'I', 'm']                                                                                                                                                                                      12                                         0.44                  1\n",
      "Sentence 128             35  ['Picking', 'people', '’', 'plates', 'probably', '’', 'help.', '”', 'looks', 'slim', ',', 'says', ',', '’', 'flattering', 'cut', 'Cefinn', '’', 'clothes', '.']                                                                                                                                                                                                                                                                                                                                                                                                                20  ['off', 'other', 's', 'doesn', 't', 'If', 'she', 'she', 'it', 's', 'because', 'of', 'the', 'of', 's']                                                                                                                                                             15                                         0.43                  1\n",
      "Sentence 129              3  ['Neat', 'segue', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3  []                                                                                                                                                                                                                                                                 0                                         0                     0\n",
      "Sentence 130             38  ['laboured', 'ages', 'silhouettes', '–', 'Cefinn', '’', 'return', 'rate', 'trousers', 'far', 'lower', 'industry', 'average', 'sales', 'increased', '51', 'per', 'cent', 'past', '12', 'months', '.']                                                                                                                                                                                                                                                                                                                                                                           22  ['She', 'for', 'over', 'the', 's', 'for', 'is', 'than', 'the', 'and', 'of', 'them', 'have', 'by', 'in', 'the']                                                                                                                                                    16                                         0.42                  2\n",
      "Sentence 131             18  ['“', '’', 'proper', 'designer', ',', '”', 'shoe', 'designer', 'Rupert', 'Sanderson', 'told', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                             12  ['She', 's', 'a', 'the', 'once', 'me']                                                                                                                                                                                                                             6                                         0.33                  0\n",
      "Sentence 132             28  ['“', 'slaves', 'finishes', 'make', 'difference.', '”', 'Dresses', 'blouses', 'always', 'exactly', 'right', 'fastening', '’', 'gape', 'anywhere', '.']                                                                                                                                                                                                                                                                                                                                                                                                                         16  ['She', 'over', 'the', 'that', 'the', 'and', 'have', 'the', 'so', 'they', 'don', 't']                                                                                                                                                                             12                                         0.43                  0\n",
      "Sentence 133             25  ['knows', 'precisely', 'much', 'button', 'adds', 'cost', ',', 'would', 'rather', 'spend', 'lots', 'different', 'contrasting', 'linings', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                  15  ['She', 'how', 'each', 'to', 'the', 'but', 'on', 'them', 'than', 'of']                                                                                                                                                                                            10                                         0.4                   2\n",
      "Sentence 134             40  ['team', 'test-drive', 'everything', 'repeatedly', 'almost', 'always', 'uses', 'black', 'navy', 'piping', 'makes', 'sure', '’', 'black', 'navy', 'pattern', 'finding', 'shoes', 'go', 'simple', '.']                                                                                                                                                                                                                                                                                                                                                                           21  ['She', 'and', 'her', 'and', 'she', 'or', 'or', 'there', 's', 'some', 'or', 'in', 'a', 'so', 'that', 'to', 'with', 'it', 'is']                                                                                                                                    19                                         0.47                  1\n",
      "Sentence 135             25  ['Last', 'year', ',', 'Cefinn', 'posted', 'loss', '£166,000', '–', 'fall', 'previous', 'year', 'sales', 'increased', '£3.8', 'million', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                   16  ['a', 'of', 'a', 'from', 'the', 'on', 'that', 'had', 'to']                                                                                                                                                                                                         9                                         0.36                  1\n",
      "Sentence 136              8  ['Building', 'fashion', 'brands', 'long', 'game', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          6  ['is', 'a']                                                                                                                                                                                                                                                        2                                         0.25                  0\n",
      "Sentence 137             59  ['“', 'spend', 'lot', 'time', 'developing', 'designs', 'really', 'start', 'make', 'money', 'scale', 'up.', '”', 'first', 'five', 'months', '2023', ',', 'sales', 'running', '25', 'per', 'cent', 'ahead', 'period', 'last', 'year', '–', 'seems', 'exciting', 'getting', 'carried', 'away', '.']                                                                                                                                                                                                                                                                               34  ['You', 'have', 'to', 'a', 'of', 'your', 'and', 'you', 'only', 'to', 'once', 'you', 'can', 'In', 'the', 'of', 'are', 'of', 'the', 'same', 'that', 'but', 'she', 'is', 'not']                                                                                      25                                         0.42                  1\n",
      "Sentence 138             23  ['“', 'best', 'advice', 'anyone', 'ever', 'gave', 'break', 'things', 'small', ',', 'doable', 'actions', ',', '”', 'says', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                 16  ['The', 'me', 'is', 'to', 'down', 'into', 'she']                                                                                                                                                                                                                   7                                         0.3                   0\n",
      "Sentence 139              9  ['“', 'Thinking', 'far', 'ahead', 'intimidating', '.']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          6  ['too', 'can', 'be']                                                                                                                                                                                                                                               3                                         0.33                  2\n",
      "Sentence 140             24  ['always', 'find', 'five', 'reasons', 'something', ',', 'sometimes', '’', 'got', 'go', '.', '”']                                                                                                                                                                                                                                                                                                                                                                                                                                                                               12  ['You', 'can', 'not', 'to', 'do', 'but', 'you', 've', 'just', 'to', 'for', 'it']                                                                                                                                                                                  12                                         0.5                   2\n",
      "  Total number of words    Total number of stop words    Maximum number of stop words per sentence    Minimum number of stop words per sentence    Average number of stop words per article\n",
      "-----------------------  ----------------------------  -------------------------------------------  -------------------------------------------  ------------------------------------------\n",
      "                   3722                          1470                                           36                                            0                                        0.39\n",
      "  Total adjectives    Average number of adjectives in the article\n",
      "------------------  ---------------------------------------------\n",
      "               315                                           0.08\n",
      "  Stanza Average of sentiment score for all sentences    Stanza Maximum sentiment score    Stanza Minimum sentiment score    Stanza Standard deviation  Vader average scores                Vader maximum scores    Vader minimum scores    Vader standard deviation scores       MPQA average scores    MPQA maximum scores    MPQA minimum scores    MPQA standard deviation scores    Sentiwordnet score\n",
      "-----------------------------------------------------  --------------------------------  --------------------------------  ---------------------------  ----------------------------------  ----------------------  ----------------------  ----------------------------------  ---------------------  ---------------------  ---------------------  --------------------------------  --------------------\n",
      "                                             0.815476                                 2                                 0                     0.644088  [0.04357857 0.85687857 0.09958571]  [0.549 1.    0.75 ]     [0.   0.25 0.  ]        [0.09920355 0.14929652 0.12940926]               0.183746                      1                     -1                          0.811675             0.0127948\n",
      "  Flesch-Kincaid score    Estimated reading level of the article    Flesch-Reading score  The article is classified as      Dale-Chall Readability score  The estimated comprehension level for different grade levels      Automated Readability Index (ARI) score  It corresponds to a grade level of    This means that the text can be read by someone who is around      Coleman-Liau Index Score    Estimated Grade Level    Gunning Fog score  The estimated grade level for comprehension is      SPACHE score    This corresponds to a grade level of    Linsear Write Index score    Approximate grade level equivalent    Perplexity (how well the LDA model predicts the corpus) of the article    Coherence (how coherent the topics are) of the article\n",
      "----------------------  ----------------------------------------  ----------------------  ------------------------------  ------------------------------  --------------------------------------------------------------  -----------------------------------------  ------------------------------------  ---------------------------------------------------------------  --------------------------  -----------------------  -------------------  ------------------------------------------------  --------------  --------------------------------------  ---------------------------  ------------------------------------  ------------------------------------------------------------------------  --------------------------------------------------------\n",
      "               10.6198                                        11                 60.2183  standard                                                9.8817  ['college']                                                                                       10.6751  ['11']                                [16, 17]                                                                            7.97599                        8              12.5842  college                                                  7.19489                                       7                      14.6357                                    15                                                                  -4.53796                                                  0.609045\n",
      "  Max tree depth  Words at max depth    ,       Average tree length    Maximum tree length    Minimum tree length\n",
      "----------------  --------------------  ----  ---------------------  ---------------------  ---------------------\n",
      "              15  wakes, received                           4.98214                     15                      1\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://www.foxnews.com/politics/republicans-respond-after-irs-whistleblower-says-hunter-biden-investigation-being-mishandled',\n",
    "        'https://news.yahoo.com/alabama-education-director-ousted-over-234450832.html',\n",
    "        'https://news.yahoo.com/samantha-cameron-remind-david-steer-050000235.html']\n",
    "\n",
    "calculate_scores(urls, directory='processed articles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

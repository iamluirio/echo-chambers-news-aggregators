{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Pre-processing Text Article, and saving the score in a txt file for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21955d6ed1f48fb8b53cbede28a2687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:12:35 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-05-02 16:12:36 INFO: File exists: /home/pierluigi/stanza_resources/en/default.zip\n",
      "2023-05-02 16:12:42 INFO: Finished downloading models and saved to /home/pierluigi/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')  # Download the English model\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "import spacy\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import newspaper\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:12:44 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f75b2c158c4bbea13016e1991cb1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 16:12:45 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-05-02 16:12:45 INFO: Using device: cpu\n",
      "2023-05-02 16:12:45 INFO: Loading: tokenize\n",
      "2023-05-02 16:12:45 INFO: Loading: sentiment\n",
      "2023-05-02 16:12:46 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Setting the use_gpu=False, it uses the CPU instead of the GPU for calculating stuff, and also for printing the results. And it couldn't run out of memory.\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=False, max_split_size_mb=15, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MPQA lexicon\n",
    "lexicon = pd.read_csv(\"/home/pierluigi/Documents/echo_chambers_intership/Code analysis/NLP/Single modules/subjclueslen1-HLTEMNLP05.tff\", sep=\" \", header=None, \n",
    "                      names=[\"type\", \"len\", \"word\", \"pos\", \"stemmed\", \"polarity\", \"strength\"])\n",
    "\n",
    "lexicon[\"type\"] = lexicon[\"type\"].str[5:]\n",
    "lexicon[\"word\"] = lexicon[\"word\"].str[len(\"word1=\"):]\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].str[len(\"priorpolarity=\"):]\n",
    "cols_to_remove = [\"len\", \"pos\", \"stemmed\", \"strength\"]\n",
    "lexicon = lexicon.drop(columns=cols_to_remove)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"weaksubj\", 1)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"strongsubj\", 2)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"negative\", -1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"positive\", 1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"both\", 0)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"neutral\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(url):\n",
    "    # Create a newspaper Article object\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    # Download and parse the article\n",
    "    article.download()\n",
    "    article.parse()\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title = article.title.strip()\n",
    "    subtitle = article.meta_data.get(\"description\", \"\").strip()\n",
    "    description = article.meta_description.strip()\n",
    "    text = article.text.strip()\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{text}\"\n",
    "\n",
    "    # Return the concatenated string\n",
    "    return article_text, title, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(article):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    num_stop_words_per_sentence = []\n",
    "    stop_words_per_sentence = []\n",
    "    filtered_sentences = []\n",
    "    filtered_words = []\n",
    "    num_words_per_sentence = []\n",
    "    avg_stop_words_per_sentence = []\n",
    "    total_words = 0\n",
    "    total_adjectives = 0\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Tokenize the sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        all_words = len(words)\n",
    "        total_words += all_words\n",
    "        \n",
    "        # Identify the stop words in the sentence\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words_found = [word for word in words if word.lower() in stop_words]\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        \n",
    "        # Add the number of stop words and filtered sentence to the output\n",
    "        num_stop_words = all_words - len(filtered_words)\n",
    "        num_stop_words_per_sentence.append(num_stop_words)\n",
    "        stop_words_per_sentence.append(stop_words_found)\n",
    "        filtered_sentences.append(\" \".join(filtered_words))\n",
    "        num_words_per_sentence.append(all_words)\n",
    "        \n",
    "        # Calculate the average number of stop words per sentence\n",
    "        avg_stop_words_per_sentence.append(num_stop_words / all_words)\n",
    "\n",
    "        #POS tagging calculations\n",
    "        tagged_words = pos_tag(words)\n",
    "        num_adjectives = len([word for word, tag in tagged_words if tag.startswith('JJ')])\n",
    "        total_adjectives += num_adjectives\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    num_stop_words = sum(num_stop_words_per_sentence)\n",
    "    max_stop_words_per_sentence = max(num_stop_words_per_sentence)\n",
    "    min_stop_words_per_sentence = min(num_stop_words_per_sentence)\n",
    "    \n",
    "    # Calculate the average number of stop words per article\n",
    "    avg_stop_words_per_sentence_avg = sum(avg_stop_words_per_sentence) / len(avg_stop_words_per_sentence)\n",
    "    \n",
    "    # POS tagging \n",
    "    avg_adjectives = total_adjectives / total_words\n",
    "\n",
    "    return sentences, filtered_words, filtered_sentences, stop_words_per_sentence, num_stop_words_per_sentence, avg_stop_words_per_sentence, total_words, num_stop_words, max_stop_words_per_sentence, min_stop_words_per_sentence, avg_stop_words_per_sentence_avg, num_words_per_sentence, total_adjectives, avg_adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_sentiment_analysis(text):\n",
    "    doc = nlp(text)\n",
    "    s_sentiment_scores = []\n",
    "\n",
    "    # Sentiment analysis using Stanza library\n",
    "    for sentence in doc.sentences:\n",
    "        s_sentiment_scores.append(sentence.sentiment)\n",
    "    \n",
    "    return s_sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_sentiment_analysis(sentences):\n",
    "    # initialize the Vader sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    v_scores_list = []\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        v_scores = analyzer.polarity_scores(sentence)\n",
    "        v_score_list = [v_scores['neg'], v_scores['neu'], v_scores['pos']]\n",
    "        v_scores_list.append(v_score_list)\n",
    "    \n",
    "    # Vader scores\n",
    "    v_scores_array = np.array(v_scores_list)\n",
    "    v_avg_scores = np.mean(v_scores_array, axis=0)\n",
    "    v_max_scores = np.max(v_scores_array, axis=0)\n",
    "    v_min_scores = np.min(v_scores_array, axis=0)\n",
    "    v_std_scores = np.std(v_scores_array, axis=0)\n",
    "\n",
    "    return v_avg_scores, v_max_scores, v_min_scores, v_std_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpqa_sentiment_analysis(article):\n",
    "    mpqa_scores = []\n",
    "\n",
    "    for word in article.split():\n",
    "        word = word.strip().lower()\n",
    "        if word in lexicon.word.tolist():\n",
    "            polarity = lexicon[lexicon.word == word].polarity.values[0]\n",
    "            mpqa_scores.append(polarity)\n",
    "        \n",
    "    # MPQA scores\n",
    "    mpqa_avg_score = np.mean(mpqa_scores)\n",
    "    mpqa_max_score = np.max(mpqa_scores)\n",
    "    mpqa_min_score = np.min(mpqa_scores)\n",
    "    mpqa_sd_score = np.std(mpqa_scores)\n",
    "\n",
    "    return mpqa_avg_score, mpqa_max_score, mpqa_min_score, mpqa_sd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiwordnet_sentiment_analysis(article):\n",
    "    sentiwordnet_final_score = 0\n",
    "\n",
    "    # Loop through each word in the text\n",
    "    sentiment_score = 0\n",
    "    num_synsets = 0\n",
    "\n",
    "    for word in article.split():\n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) > 0:\n",
    "            synset = synsets[0]\n",
    "            senti_synset = swn.senti_synset(synset.name())\n",
    "            sentiment_score += senti_synset.pos_score() - senti_synset.neg_score()\n",
    "            num_synsets += 1\n",
    "    \n",
    "    # Calculate final score        \n",
    "    if num_synsets > 0:\n",
    "        sentiwordnet_final_score = sentiment_score / num_synsets\n",
    "    else:\n",
    "        sentiwordnet_final_score = 0\n",
    "    \n",
    "    return sentiwordnet_final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability_analysis(article):\n",
    "    read = Readability(article)\n",
    "    metrics = {}\n",
    "\n",
    "    # Flesch Kincaid\n",
    "    metrics['flesch_kincaid'] = read.flesch_kincaid()\n",
    "\n",
    "    # Flesch Reading Ease\n",
    "    metrics['flesch_reading'] = read.flesch()\n",
    "\n",
    "    # Dale Chall Readability\n",
    "    metrics['dale_chall'] = read.dale_chall()\n",
    "\n",
    "    # Automated Readability Index (ARI)\n",
    "    metrics['ari'] = read.ari()\n",
    "\n",
    "    # Coleman Liau Index\n",
    "    metrics['coleman_liau'] = read.coleman_liau()\n",
    "\n",
    "    # Gunning Fog\n",
    "    metrics['gunning_fog'] = read.gunning_fog()\n",
    "\n",
    "    # SMOG: at least 30 sentences required. Uncomment if needed.\n",
    "    # metrics['smog'] = read.smog()\n",
    "\n",
    "    # SPACHE\n",
    "    metrics['spache'] = read.spache()\n",
    "\n",
    "    # Linsear Write\n",
    "    metrics['linsear_write'] = read.linsear_write()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_lda_algorithm(filtered_words):\n",
    "    # Gensim-LDA analysis\n",
    "    bigrams = list(nltk.bigrams(filtered_words))\n",
    "    lemmatized_bigrams = []\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        lemma1 = lemmatizer.lemmatize(bigram[0])\n",
    "        lemma2 = lemmatizer.lemmatize(bigram[1])\n",
    "        lemmatized_bigrams.append([lemma1, lemma2])\n",
    "    \n",
    "    # Create Dictionary \n",
    "    id2word = corpora.Dictionary(lemmatized_bigrams) \n",
    "\n",
    "    # Create Corpus \n",
    "    texts = lemmatized_bigrams\n",
    "\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    doc_lda = lda_model[corpus]\n",
    "\n",
    "    # Compute perplexity\n",
    "    perplexity_lda = lda_model.log_perplexity(corpus)\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts = lemmatized_bigrams, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "    return lda_model, perplexity_lda, coherence_lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_tree(node, depth):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return max([walk_tree(child, depth + 1) for child in node.children], default=depth)\n",
    "    else:\n",
    "        return depth\n",
    "    \n",
    "def build_dependency_tree(article):\n",
    "    doc = nlp_spacy(article)\n",
    "    depths = {}\n",
    "    tree_lengths = {}\n",
    "    for sent in doc.sents:\n",
    "        root = sent.root\n",
    "        depth = walk_tree(root, 0)\n",
    "        depths[root.orth_] = depth\n",
    "        tree_lengths[sent.text.strip()] = depth\n",
    "\n",
    "    lengths = list(tree_lengths.values())\n",
    "    avg_length = sum(lengths) / len(lengths)\n",
    "    max_length = max(lengths)\n",
    "    min_length = min(lengths)\n",
    "    max_depth = max(depths.values())\n",
    "    max_depth_words = [word for word, depth in depths.items() if depth == max_depth]\n",
    "    return tree_lengths, max_depth, max_depth_words, avg_length, max_length, min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(url):\n",
    "    article, title, text =  get_article_info(url)\n",
    "    sentences, filtered_words, filtered_sentences, stop_words_per_sentence, num_stop_words_per_sentence, avg_stop_words_per_sentence, total_words, num_stop_words, max_stop_words_per_sentence, min_stop_words_per_sentence, avg_stop_words_per_sentence_avg, num_words_per_sentence, total_adjectives, avg_adjectives  = preprocess_text(article)\n",
    "    s_sentiment_scores = stanza_sentiment_analysis(text)\n",
    "    v_avg_scores, v_max_scores, v_min_scores, v_std_scores = vader_sentiment_analysis(sentences)\n",
    "    mpqa_avg_score, mpqa_max_score, mpqa_min_score, mpqa_sd_score = mpqa_sentiment_analysis(article)\n",
    "    sentiwordnet_final_score = sentiwordnet_sentiment_analysis(article)\n",
    "    metrics = readability_analysis(article)\n",
    "    lda_model, perplexity_lda, coherence_lda = gensim_lda_algorithm(filtered_words)\n",
    "    tree_lengths, max_depth, max_depth_words, avg_length, max_length, min_length = build_dependency_tree(article)\n",
    "    return {\n",
    "        'title': title,\n",
    "        'num_stop_words': num_stop_words,\n",
    "        'total_words': total_words,\n",
    "        'max_stop_words_per_sentence': max_stop_words_per_sentence,\n",
    "        'min_stop_words_per_sentence': min_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_sentence': avg_stop_words_per_sentence,\n",
    "        'avg_stop_words_per_sentence_avg': avg_stop_words_per_sentence_avg,\n",
    "        'filtered_sentences': filtered_sentences,\n",
    "        'stop_words_per_sentence': stop_words_per_sentence,\n",
    "        'num_words_per_sentence': num_words_per_sentence,\n",
    "        'num_stop_words_per_sentence': num_stop_words_per_sentence,\n",
    "        'total_adjectives': total_adjectives,\n",
    "        'avg_adjectives': avg_adjectives,\n",
    "        's_sentiment_scores': s_sentiment_scores,\n",
    "        'v_avg_scores': v_avg_scores,\n",
    "        'v_max_scores': v_max_scores,\n",
    "        'v_min_scores': v_min_scores,\n",
    "        'v_std_scores': v_std_scores,\n",
    "        'mpqa_avg_score': mpqa_avg_score,\n",
    "        'mpqa_max_score': mpqa_max_score,\n",
    "        'mpqa_min_score': mpqa_min_score,\n",
    "        'mpqa_sd_score': mpqa_sd_score,\n",
    "        'sentiwordnet_final_score': sentiwordnet_final_score,\n",
    "        'metrics': metrics,\n",
    "        'lda_model': lda_model,\n",
    "        'perplexity_lda': perplexity_lda,\n",
    "        'coherence_lda': coherence_lda,\n",
    "        'tree_lengths': tree_lengths,\n",
    "        'max_depth': max_depth,\n",
    "        'max_depth_words': max_depth_words,\n",
    "        'avg_length': avg_length,\n",
    "        'max_length': max_length,\n",
    "        'min_length': min_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(urls, directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        results = process_article(url)\n",
    "        # Write preprocessed article to a separate file for each URL\n",
    "        file_path = f'{directory}/{results[\"title\"]}.txt'\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            # Save the information for each sentence to the file\n",
    "            for i, sentence in enumerate(results['filtered_sentences']):\n",
    "                f.write(f\"Sentence {i+1}: {sentence}\\n\")\n",
    "                f.write(f\"Total words: {results['num_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Filtered words: {sentence.split()}\\n\")\n",
    "                f.write(f\"Number of filtered words: {len(sentence.split())}\\n\")\n",
    "                f.write(f\"Stop words: {results['stop_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Number of stop words: {results['num_stop_words_per_sentence'][i]}\\n\")\n",
    "                f.write(f\"Average number of stop words per sentence: {round(results['avg_stop_words_per_sentence'][i], 2)}\\n\")\n",
    "                f.write(f\"Sentiment score: {results['s_sentiment_scores'][i]}\\n\\n\")\n",
    "                #f.write(f\"Depth: {results['tree_lengths'][i]}\\n\")\n",
    "                \n",
    "\n",
    "            # Save the general statistics on stop words to the file\n",
    "            f.write(f\"Total number of words: {results['total_words']}\\n\")\n",
    "            f.write(f\"Total number of stop words: {results['num_stop_words']}\\n\")\n",
    "            f.write(f\"Maximum number of stop words per sentence: {results['max_stop_words_per_sentence']}\\n\")\n",
    "            f.write(f\"Minimum number of stop words per sentence: {results['min_stop_words_per_sentence']}\\n\")\n",
    "            f.write(f\"Average number of stop words per article: {round(results['avg_stop_words_per_sentence_avg'], 2)}\\n\")\n",
    "\n",
    "            # Print POS tagging operations\n",
    "            f.write(f\"Total adjectives: {results['total_adjectives']}\\n\")\n",
    "            f.write(f\"Average number of adjectives in the article: {results['avg_adjectives']:.2f}\\n\\n\")\n",
    "            \n",
    "            # Stanza sentiment scores\n",
    "            f.write(f\"Stanza Average of sentiment score for all sentences: {sum(results['s_sentiment_scores']) / len(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Maximum sentiment score: {max(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Minimum sentiment score: {min(results['s_sentiment_scores'])}\\n\")\n",
    "            f.write(f\"Stanza Standard deviation: {statistics.stdev(results['s_sentiment_scores'])}\\n\\n\")\n",
    "\n",
    "            # Vader sentiment scores\n",
    "            f.write(f\"Vader average scores: {results['v_avg_scores']}\\n\")\n",
    "            f.write(f\"Vader maximum scores: {results['v_max_scores']}\\n\")\n",
    "            f.write(f\"Vader minimum scores: {results['v_min_scores']}\\n\")\n",
    "            f.write(f\"Vader standard deviation scores: {results['v_std_scores']}\\n\\n\")\n",
    "\n",
    "            # MPQA sentiment scores\n",
    "            f.write(f\"MPQA average scores: {results['mpqa_avg_score']}\\n\")\n",
    "            f.write(f\"MPQA maximum scores: {results['mpqa_max_score']}\\n\")\n",
    "            f.write(f\"MPQA minimum scores: {results['mpqa_min_score']}\\n\")\n",
    "            f.write(f\"MPQA standard deviation scores: {results['mpqa_sd_score']}\\n\\n\")\n",
    "\n",
    "            # Sentiword sentiment scores\n",
    "            f.write(f\"Sentiwordnet score: {results['sentiwordnet_final_score']} (from -1 to 1, and score of 0 indicates a neutral sentiment.)\\n\\n\")\n",
    "            \n",
    "            # Flesch_Kincaid scores\n",
    "            f.write(f\"Flesch-Kincaid score: {results['metrics']['flesch_kincaid'].score}\\n\")\n",
    "            f.write(f\"The estimated reading level of the article is: {results['metrics']['flesch_kincaid'].grade_level}\\n\\n\") \n",
    "\n",
    "            # Flesch Reading ease scores\n",
    "            f.write(f\"Flesch Reading Ease score: {results['metrics']['flesch_reading'].score}\\n\")\n",
    "            f.write(f\"The article is classified as: {results['metrics']['flesch_reading'].ease}\\n\\n\")\n",
    "\n",
    "            # Print the Dale-Chall scores\n",
    "            f.write(f\"Dale-Chall Readability score: {results['metrics']['dale_chall'].score}\\n\")\n",
    "            # Print the estimated grade levels for comprehension\n",
    "            f.write(f\"The estimated comprehension level for different grade levels is: {results['metrics']['dale_chall'].grade_levels}\\n\\n\")\n",
    "\n",
    "            # Print the ARI scores\n",
    "            f.write(f\"Automated Readability Index (ARI) score: {results['metrics']['ari'].score}, which corresponds to a grade level of {results['metrics']['ari'].grade_levels}.\\n\")\n",
    "            f.write(f\"This means that the text can be read by someone who is around {results['metrics']['ari'].ages} years old.\\n\\n\")\n",
    "\n",
    "            # Print the Coleman-Liau scores\n",
    "            f.write(f\"Coleman-Liau Index Score: {results['metrics']['coleman_liau'].score}\\n\")\n",
    "            f.write(f\"Estimated Grade Level: {results['metrics']['coleman_liau'].grade_level}\\n\\n\")\n",
    "\n",
    "            # Print the Gunning Fog scores\n",
    "            f.write(f\"Gunning Fog score: {results['metrics']['gunning_fog'].score}\\n\")\n",
    "            f.write(f\"The estimated grade level for comprehension is: {results['metrics']['gunning_fog'].grade_level}\\n\\n\")\n",
    "\n",
    "            # Print the SMOG scores\n",
    "            #f.write(f\"SMOG score: {results['metrics']['smog'].score}. This corresponds to a grade level of {results['metrics']['smog'].grade_level}.\")\n",
    "            \n",
    "            # Print the SPACHE scores\n",
    "            f.write(f\"SPACHE score: {results['metrics']['spache'].score}\\n\")\n",
    "            f.write(f\"This corresponds to a grade level of {results['metrics']['spache'].grade_level}.\\n\\n\")\n",
    "\n",
    "            # Print the Linsear Write Index scores\n",
    "            f.write(f\"Linsear Write Index score: {results['metrics']['linsear_write'].score}\\n\")\n",
    "            f.write(\"Approximate grade level equivalent: {}\\n\\n\".format(results['metrics']['linsear_write'].grade_level))\n",
    "\n",
    "            # Gensim-LDA analysis\n",
    "            f.write(f\"Perplexity (how well the LDA model predicts the corpus) of the article: {results['perplexity_lda']}\\n\")\n",
    "            f.write(f\"Coherence (how coherent the topics are) of the article: {results['coherence_lda']}\\n\\n\")\n",
    "\n",
    "            # Dependency tree height\n",
    "            f.write(f\"Max tree depth: {results['max_depth']}\\n\")\n",
    "            f.write(f\"Words at max depth: {', '.join(results['max_depth_words'])}\\n\")\n",
    "            f.write(f\"Average tree length: {results['avg_length']:.2f}\\n\")\n",
    "            f.write(f\"Maximum tree length: {results['max_length']}\\n\")\n",
    "            f.write(f\"Minimum tree length: {results['min_length']}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.foxnews.com/politics/republicans-respond-after-irs-whistleblower-says-hunter-biden-investigation-being-mishandled',\n",
    "        'https://news.yahoo.com/alabama-education-director-ousted-over-234450832.html',\n",
    "        'https://news.yahoo.com/samantha-cameron-remind-david-steer-050000235.html']\n",
    "\n",
    "calculate_scores(urls, directory='processed articles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

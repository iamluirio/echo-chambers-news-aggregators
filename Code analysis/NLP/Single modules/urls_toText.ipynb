{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbd7b678cd74c1ea2fa2c185c24b9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 12:17:03 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-06-02 12:17:04 INFO: File exists: /home/pierluigi/stanza_resources/en/default.zip\n",
      "2023-06-02 12:17:10 INFO: Finished downloading models and saved to /home/pierluigi/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from openpyxl import load_workbook\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')  # Download the English model\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "import spacy\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "import newspaper\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from openpyxl import Workbook\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 12:17:10 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f095fbef3e624d698d9beec0210c5166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 12:17:11 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-06-02 12:17:11 INFO: Using device: cpu\n",
      "2023-06-02 12:17:11 INFO: Loading: tokenize\n",
      "2023-06-02 12:17:11 INFO: Loading: sentiment\n",
      "2023-06-02 12:17:12 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=False, max_split_size_mb=16, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MPQA lexicon\n",
    "lexicon = pd.read_csv(\"/home/pierluigi/Documents/echo_chambers_intership/Code analysis/NLP/Single modules/subjclueslen1-HLTEMNLP05.tff\", sep=\" \", header=None, \n",
    "                      names=[\"type\", \"len\", \"word\", \"pos\", \"stemmed\", \"polarity\", \"strength\"])\n",
    "\n",
    "lexicon[\"type\"] = lexicon[\"type\"].str[5:]\n",
    "lexicon[\"word\"] = lexicon[\"word\"].str[len(\"word1=\"):]\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].str[len(\"priorpolarity=\"):]\n",
    "cols_to_remove = [\"len\", \"pos\", \"stemmed\", \"strength\"]\n",
    "lexicon = lexicon.drop(columns=cols_to_remove)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"weaksubj\", 1)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"strongsubj\", 2)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"negative\", -1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"positive\", 1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"both\", 0)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"neutral\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article_text(url):\n",
    "    # Set headers to mimic a web browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL with headers\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title_element = soup.find('title')\n",
    "    title = title_element.text.strip() if title_element else \"\"\n",
    "\n",
    "    subtitle_element = soup.find('meta', attrs={'name': 'description'})\n",
    "    subtitle = subtitle_element['content'].strip() if subtitle_element and 'content' in subtitle_element.attrs else \"\"\n",
    "\n",
    "    description_element = soup.find('meta', attrs={'name': 'og:description'})\n",
    "    description = description_element['content'].strip() if description_element and 'content' in description_element.attrs else \"\"\n",
    "\n",
    "    # Find and exclude unwanted elements by class names or content patterns\n",
    "    unwanted_elements = soup.find_all(['script', 'style', 'a', 'div', 'span'], class_=['follow-us', 'newsletter', 'advertisement'])\n",
    "    patterns_to_exclude = ['next article', 'read next', 'correlated']\n",
    "    for element in unwanted_elements:\n",
    "        if any(pattern in str(element).lower() for pattern in patterns_to_exclude):\n",
    "            element.extract()\n",
    "\n",
    "    # Find and exclude footer container and \"All rights reserved\" text\n",
    "    footer_elements = soup.find_all(['footer', 'div'], class_=['footer', 'bottom-footer'])\n",
    "    for element in footer_elements:\n",
    "        element.extract()\n",
    "    all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
    "    for element in all_rights_reserved_elements:\n",
    "        element.extract()\n",
    "\n",
    "    # Find the main text element(s) based on the HTML structure of the page\n",
    "    main_text_elements = soup.find_all('p')\n",
    "    main_text = \"\\n\\n\".join([element.text.strip() for element in main_text_elements if element.text.strip()])\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{main_text}\"\n",
    "\n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_real_url(google_news_url):\n",
    "    response = requests.get(google_news_url, cookies = {'CONSENT' : 'YES+'})\n",
    "    real_url = response.url\n",
    "    return real_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_dict):\n",
    "    processed_data = {}\n",
    "    \n",
    "    for sheet_name, data_list in data_dict.items():\n",
    "        sheet_data = {}\n",
    "        \n",
    "        for index, url in enumerate(data_list, start=1):\n",
    "            try:\n",
    "                article_url = extract_real_url(url)\n",
    "                article_text = save_article_text(article_url)\n",
    "                key = f\"article{index}\"\n",
    "                sheet_data[key] = article_text\n",
    "            except (requests.exceptions.RequestException, requests.exceptions.HTTPError) as e:\n",
    "                # Handle the exception and continue with the next URL\n",
    "                print(f\"Error processing URL: {url}\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        processed_data[sheet_name] = sheet_data\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stanza_sentiment_scores(data_dict, nlp):\n",
    "    sentiment_data = {}  # Dictionary to store sentiment scores for each article\n",
    "    \n",
    "    for sheet_name, sheet_data in data_dict.items():\n",
    "        sheet_sentiments = []  # List to store sentiment scores for articles in a sheet\n",
    "        \n",
    "        for article_key, article_text in sheet_data.items():\n",
    "            doc = nlp(article_text)\n",
    "            article_sentiments = []\n",
    "            \n",
    "            for sentence in doc.sentences:\n",
    "                article_sentiments.append(sentence.sentiment)\n",
    "            \n",
    "            if len(article_sentiments) > 0:\n",
    "                article_scores = {\n",
    "                    'average': sum(article_sentiments) / len(article_sentiments),\n",
    "                    'maximum': max(article_sentiments),\n",
    "                    'sd': statistics.stdev(article_sentiments),\n",
    "                    'minimum': min(article_sentiments)\n",
    "                }\n",
    "            else:\n",
    "                article_scores = None\n",
    "            \n",
    "            sentiment_data[(sheet_name, article_key)] = article_scores\n",
    "        \n",
    "        # Store the sentiment scores for the articles in the sheet\n",
    "        sentiment_data[sheet_name] = sheet_sentiments\n",
    "    \n",
    "    return sentiment_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sentiment_scores_to_excel_stanza(processed_data_list, sentiment_scores_list, output_file_path):\n",
    "    # Create a new workbook\n",
    "    output_workbook = openpyxl.Workbook()\n",
    "    \n",
    "    for i, processed_data in enumerate(processed_data_list):\n",
    "        sentiment_scores = sentiment_scores_list[i]\n",
    "        sheet_name = f\"Sheet {i+1}\"\n",
    "        \n",
    "        # Select the active sheet or create a new sheet\n",
    "        if i == 0:\n",
    "            output_sheet = output_workbook.active\n",
    "            output_sheet.title = sheet_name\n",
    "        else:\n",
    "            output_sheet = output_workbook.create_sheet(title=sheet_name)\n",
    "        \n",
    "        # Write headers to the first row of the sheet\n",
    "        output_sheet['A1'] = 'Date'\n",
    "        \n",
    "        # Write sentiment scores to the sheet\n",
    "        row = 2  # Start from the second row\n",
    "        \n",
    "        for sheet_name, sheet_data in processed_data.items():\n",
    "            output_sheet.cell(row=row, column=1, value=sheet_name)\n",
    "            column = 2  # Start from column B\n",
    "            \n",
    "            for article_index, (article_key, article_text) in enumerate(sheet_data.items()):\n",
    "                scores = sentiment_scores[(sheet_name, article_key)]\n",
    "                \n",
    "                if scores is not None:\n",
    "                    output_sheet.cell(row=1, column=column, value=f\"Average {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column, value=scores['average'])\n",
    "                    \n",
    "                    output_sheet.cell(row=1, column=column+1, value=f\"Maximum {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column+1, value=scores['maximum'])\n",
    "                    \n",
    "                    output_sheet.cell(row=1, column=column+2, value=f\"sd {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column+2, value=scores['sd'])\n",
    "                    \n",
    "                    output_sheet.cell(row=1, column=column+3, value=f\"Minimum {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column+3, value=scores['minimum'])\n",
    "                else:\n",
    "                    output_sheet.cell(row=1, column=column, value=f\"Average {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column, value='N/A')\n",
    "                    \n",
    "                    output_sheet.cell(row=1, column=column+1, value=f\"Maximum {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column+1, value='N/A')\n",
    "                    \n",
    "                    output_sheet.cell(row=1, column=column+2, value=f\"sd {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column+2, value='N/A')\n",
    "                    \n",
    "                    output_sheet.cell(row=1, column=column+3, value=f\"Minimum {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column+3, value='N/A')\n",
    "                \n",
    "                column += 4  # Move to the next set of columns for the next article\n",
    "            row += 1\n",
    "    \n",
    "    # Save the workbook to a file\n",
    "    output_workbook.save(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_sentiment_scores(data_dict):\n",
    "    sentiment_data = {}  # Dictionary to store sentiment scores for each article\n",
    "    \n",
    "    for sheet_name, sheet_data in data_dict.items():\n",
    "        sheet_sentiments = []\n",
    "        \n",
    "        for article_key, article_text in sheet_data.items():\n",
    "            analyzer = SentimentIntensityAnalyzer()\n",
    "            sentiment_score = 0\n",
    "            no_of_pos_sent = 0\n",
    "            no_of_neg_sent = 0\n",
    "            no_of_neu_sent = 0\n",
    "\n",
    "            article_sentiments = []\n",
    "\n",
    "            sentences = sent_tokenize(article_text)\n",
    "\n",
    "            for sentence in sentences:\n",
    "                scores = analyzer.polarity_scores(sentence)\n",
    "                score_list = [scores['neg'], scores['neu'], scores['pos']]\n",
    "                article_sentiments.append(score_list)\n",
    "\n",
    "                if scores['neg'] > scores['neu'] and scores['neg'] > scores['pos']:\n",
    "                    no_of_neg_sent += 1\n",
    "                    sentiment_score -= scores['neg']\n",
    "\n",
    "                elif scores['pos'] > scores['neu'] and scores['pos'] > scores['neg']:\n",
    "                    no_of_pos_sent += 1\n",
    "                    sentiment_score += scores['pos']\n",
    "\n",
    "                else:\n",
    "                    no_of_neu_sent += 1\n",
    "\n",
    "                article_scores = {\n",
    "                    'sentiment_score': sentiment_score,\n",
    "                    'no_of_pos_sent': no_of_pos_sent,\n",
    "                    'no_of_neg_sent': no_of_neg_sent,\n",
    "                    'no_of_neu_sent': no_of_neu_sent\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                article_scores = None\n",
    "        \n",
    "            sentiment_data[(sheet_name, article_key)] = article_scores\n",
    "        \n",
    "        sentiment_data[sheet_name] = sheet_sentiments\n",
    "    \n",
    "    return sentiment_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sentiment_scores_to_excel_vader(processed_data_list, sentiment_scores_list, output_file_path):\n",
    "    output_workbook = openpyxl.load_workbook(output_file_path)\n",
    "\n",
    "    for i, processed_data in enumerate(processed_data_list):\n",
    "        sentiment_scores = sentiment_scores_list[i]\n",
    "        sheet_name = f\"Sheet {i+1}\"\n",
    "\n",
    "        # Check if the sheet already exists in the workbook\n",
    "        if sheet_name in output_workbook.sheetnames:\n",
    "            output_sheet = output_workbook[sheet_name]\n",
    "        else:\n",
    "            raise ValueError(f\"Sheet '{sheet_name}' does not exist in the workbook.\")\n",
    "\n",
    "        # Write Vader sentiment score headers in the new columns\n",
    "        output_sheet['F1'] = 'Vader Average Score'\n",
    "        output_sheet['G1'] = 'Vader Maximum Score'\n",
    "        output_sheet['H1'] = 'Vader Standard Deviation'\n",
    "        output_sheet['I1'] = 'Vader Minimum Score'\n",
    "\n",
    "        # Write Vader sentiment scores to the sheet\n",
    "        row = 2  # Start from the second row\n",
    "\n",
    "        for sheet_name, sheet_data in processed_data.items():\n",
    "            for article_key, article_text in sheet_data.items():\n",
    "                scores = sentiment_scores[(sheet_name, article_key)]\n",
    "                if scores is not None:\n",
    "                    output_sheet.cell(row=row, column=6, value=str(scores['average']))  # Column F\n",
    "                    output_sheet.cell(row=row, column=7, value=str(scores['maximum']))  # Column J\n",
    "                    output_sheet.cell(row=row, column=8, value=str(scores['sd']))       # Column H\n",
    "                    output_sheet.cell(row=row, column=9, value=str(scores['minimum']))  # Column I\n",
    "                else:\n",
    "                    output_sheet.cell(row=row, column=6, value='N/A')  # Column F\n",
    "                    output_sheet.cell(row=row, column=7, value='N/A')  # Column J\n",
    "                    output_sheet.cell(row=row, column=8, value='N/A')       # Column H\n",
    "                    output_sheet.cell(row=row, column=9, value='N/A')  # Column I\n",
    "                row += 1\n",
    "\n",
    "    output_workbook.save(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    workbook = load_workbook('/home/pierluigi/Downloads/Text Analytics.xlsx')\n",
    "\n",
    "    data_U1 = {}  # Dictionary to store data from range 1 - U1\n",
    "    data_U2 = {}  # Dictionary to store data from range 2 - U2\n",
    "    data_U3 = {}  # Dictionary to store data from range 3 - U3\n",
    "    data_U4 = {}  # Dictionary to store data from range 4 - U4\n",
    "\n",
    "    # Iterate over each sheet in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "\n",
    "        # Specify the range of cells for data_U1\n",
    "        range1_start_cell = 'C2'  # Replace with the starting cell of range 1\n",
    "        range1_end_cell = 'L2'  # Replace with the ending cell of range 1\n",
    "        \n",
    "        data_list1 = []\n",
    "        \n",
    "        # Iterate over the cells within range 1\n",
    "        for row in worksheet[range1_start_cell:range1_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list1.append(cell.value)\n",
    "        \n",
    "        data_U1[sheet_name] = data_list1\n",
    "\n",
    "        # Specify the range of cells for data_U2\n",
    "        range2_start_cell = 'C3'  # Replace with the starting cell of range 2\n",
    "        range2_end_cell = 'L3'  # Replace with the ending cell of range 2\n",
    "        \n",
    "        data_list2 = []\n",
    "        \n",
    "        # Iterate over the cells within range 2\n",
    "        for row in worksheet[range2_start_cell:range2_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list2.append(cell.value)\n",
    "        \n",
    "        data_U2[sheet_name] = data_list2\n",
    "\n",
    "        # Specify the range of cells for data_U3\n",
    "        range3_start_cell = 'C4'  # Replace with the starting cell of range 3\n",
    "        range3_end_cell = 'L4'  # Replace with the ending cell of range 3\n",
    "        \n",
    "        data_list3 = []\n",
    "        \n",
    "        # Iterate over the cells within range 3\n",
    "        for row in worksheet[range3_start_cell:range3_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list3.append(cell.value)\n",
    "        \n",
    "        data_U3[sheet_name] = data_list3\n",
    "\n",
    "        # Specify the range of cells for data_U4\n",
    "        range4_start_cell = 'C5'  # Replace with the starting cell of range 4\n",
    "        range4_end_cell = 'L5'  # Replace with the ending cell of range 4\n",
    "        \n",
    "        data_list4 = []\n",
    "        \n",
    "        # Iterate over the cells within range 4\n",
    "        for row in worksheet[range4_start_cell:range4_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list4.append(cell.value)\n",
    "        \n",
    "        data_U4[sheet_name] = data_list4\n",
    "\n",
    "    workbook.close()\n",
    "\n",
    "    # Process the data\n",
    "    processed_data1 = process_data(data_U1)\n",
    "    processed_data2 = process_data(data_U2)\n",
    "    processed_data3 = process_data(data_U3)\n",
    "    processed_data4 = process_data(data_U4)\n",
    "\n",
    "    # Stanza sentiment score\n",
    "    stanza_sentiment_scores1 = get_stanza_sentiment_scores(processed_data1, nlp)\n",
    "    stanza_sentiment_scores2 = get_stanza_sentiment_scores(processed_data2, nlp)\n",
    "    stanza_sentiment_scores3 = get_stanza_sentiment_scores(processed_data3, nlp)\n",
    "    stanza_sentiment_scores4 = get_stanza_sentiment_scores(processed_data4, nlp)\n",
    "\n",
    "    processed_data_list = [processed_data1, processed_data2, processed_data3, processed_data4]\n",
    "    stanza_sentiment_scores_list = [stanza_sentiment_scores1, stanza_sentiment_scores2, stanza_sentiment_scores3, stanza_sentiment_scores4]    \n",
    "    \n",
    "    output_file_path = '/home/pierluigi/Desktop/sentiment.xlsx'\n",
    "\n",
    "    save_sentiment_scores_to_excel_stanza(processed_data_list, stanza_sentiment_scores_list, output_file_path)\n",
    "\n",
    "    # Vader sentiment score\n",
    "    # vader_sentiment_scores1 = get_vader_sentiment_scores(processed_data1)\n",
    "    # vader_sentiment_scores2 = get_vader_sentiment_scores(processed_data2)\n",
    "    # vader_sentiment_scores3 = get_vader_sentiment_scores(processed_data3)\n",
    "    # vader_sentiment_scores4 = get_vader_sentiment_scores(processed_data4)\n",
    "\n",
    "    # vader_sentiment_scores_list = [vader_sentiment_scores1, vader_sentiment_scores2, vader_sentiment_scores3, vader_sentiment_scores4]    \n",
    "\n",
    "    # save_sentiment_scores_to_excel_vader(processed_data_list, vader_sentiment_scores_list, output_file_path)\n",
    "\n",
    "\n",
    "    # for sheet_name, sheet_data in processed_data1.items():\n",
    "    #     print(f\"Sheet: {sheet_name}\")\n",
    "    #     for article_key, article_text in sheet_data.items():\n",
    "    #         print(f\"Article {article_key}:\")\n",
    "    #         print(article_text)\n",
    "    #         print(\"Sentiment Scores:\")\n",
    "    #         scores = vader_sentiment_scores1[(sheet_name, article_key)]\n",
    "    #         if scores is not None:\n",
    "    #             print(f\"Average: {scores['average']}\")\n",
    "    #             print(f\"Maximum: {scores['maximum']}\")\n",
    "    #             print(f\"Standard Deviation: {scores['sd']}\")\n",
    "    #             print(f\"Minimum: {scores['minimum']}\")\n",
    "    #         else:\n",
    "    #             print(\"No sentiment scores available.\")\n",
    "    #         print(\"---\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiSGh0dHBzOi8vd3d3LmxpZmVzdHlsZWFzaWEuY29tL2tsL3N0eWxlL2Zhc2hpb24vbWV0LWdhbGEtMjAyMy1iZXN0LW1lbWVzL9IBTGh0dHBzOi8vd3d3LmxpZmVzdHlsZWFzaWEuY29tL2tsL3N0eWxlL2Zhc2hpb24vbWV0LWdhbGEtMjAyMy1iZXN0LW1lbWVzL2FtcC8?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: 403 Client Error: Forbidden for url: https://www.lifestyleasia.com/kl/style/fashion/met-gala-2023-best-memes/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiUmh0dHBzOi8vc2NyZWVucmFudC5jb20vdmFuZGVycHVtcC1ydWxlcy10b20tc2FuZG92YWwtZGlzZGFpbi1rYXRpZS1kZWVwZXItbWVhbmluZy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiUWh0dHBzOi8vbmV3cy55YWhvby5jb20vc2VuYXRlLXJlcHVibGljYW5zLWluY2x1ZGluZy1tY2Nvbm5lbGwtZGVidC0yMjAwMzg1ODYuaHRtbNIBWWh0dHBzOi8vbmV3cy55YWhvby5jb20vYW1waHRtbC9zZW5hdGUtcmVwdWJsaWNhbnMtaW5jbHVkaW5nLW1jY29ubmVsbC1kZWJ0LTIyMDAzODU4Ni5odG1s?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: 404 Client Error: Not Found for url: https://news.yahoo.com/senate-republicans-including-mcconnell-debt-220038586.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiamh0dHBzOi8vd3d3LndhdnkuY29tL25ld3MvbWlsaXRhcnkva2lnZ2Fucy1kaXNwdXRlcy1jbGFpbXMtdGhhdC1idWRnZXQtcGxhbi13b3VsZC1zbGFzaC12ZXRlcmFucy1iZW5lZml0cy_SAW5odHRwczovL3d3dy53YXZ5LmNvbS9uZXdzL21pbGl0YXJ5L2tpZ2dhbnMtZGlzcHV0ZXMtY2xhaW1zLXRoYXQtYnVkZ2V0LXBsYW4td291bGQtc2xhc2gtdmV0ZXJhbnMtYmVuZWZpdHMvYW1wLw?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: 451 Client Error: Unavailable For Legal Reasons for url: https://www.wavy.com/news/military/kiggans-disputes-claims-that-budget-plan-would-slash-veterans-benefits/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_4837/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

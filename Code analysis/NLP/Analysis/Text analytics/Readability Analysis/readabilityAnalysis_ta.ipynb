{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2883f0ceb846abb98a44ccb45e14e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:16:11 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-06-05 17:16:12 INFO: File exists: /home/pierluigi/stanza_resources/en/default.zip\n",
      "2023-06-05 17:16:19 INFO: Finished downloading models and saved to /home/pierluigi/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from openpyxl import load_workbook\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from readability.exceptions import ReadabilityException\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')  # Download the English model\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "import spacy\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "import newspaper\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from openpyxl import Workbook\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:16:20 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0df523df17d4985a5d18615f9482614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:16:21 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-06-05 17:16:21 INFO: Using device: cpu\n",
      "2023-06-05 17:16:21 INFO: Loading: tokenize\n",
      "2023-06-05 17:16:21 INFO: Loading: sentiment\n",
      "2023-06-05 17:16:22 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', tokenize_no_ssplit=False, max_split_size_mb=16, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MPQA lexicon\n",
    "lexicon = pd.read_csv(\"/home/pierluigi/Documents/echo_chambers_intership/Code analysis/NLP/Single modules/subjclueslen1-HLTEMNLP05.tff\", sep=\" \", header=None, \n",
    "                      names=[\"type\", \"len\", \"word\", \"pos\", \"stemmed\", \"polarity\", \"strength\"])\n",
    "\n",
    "lexicon[\"type\"] = lexicon[\"type\"].str[5:]\n",
    "lexicon[\"word\"] = lexicon[\"word\"].str[len(\"word1=\"):]\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].str[len(\"priorpolarity=\"):]\n",
    "cols_to_remove = [\"len\", \"pos\", \"stemmed\", \"strength\"]\n",
    "lexicon = lexicon.drop(columns=cols_to_remove)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"weaksubj\", 1)\n",
    "lexicon[\"type\"] = lexicon[\"type\"].replace(\"strongsubj\", 2)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"negative\", -1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"positive\", 1)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"both\", 0)\n",
    "lexicon[\"polarity\"] = lexicon[\"polarity\"].replace(\"neutral\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article_text(url):\n",
    "    # Set headers to mimic a web browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL with headers\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the title, subtitle, description, and main text\n",
    "    title_element = soup.find('title')\n",
    "    title = title_element.text.strip() if title_element else \"\"\n",
    "\n",
    "    subtitle_element = soup.find('meta', attrs={'name': 'description'})\n",
    "    subtitle = subtitle_element['content'].strip() if subtitle_element and 'content' in subtitle_element.attrs else \"\"\n",
    "\n",
    "    description_element = soup.find('meta', attrs={'name': 'og:description'})\n",
    "    description = description_element['content'].strip() if description_element and 'content' in description_element.attrs else \"\"\n",
    "\n",
    "    # Find and exclude unwanted elements by class names or content patterns\n",
    "    unwanted_elements = soup.find_all(['script', 'style', 'a', 'div', 'span'], class_=['follow-us', 'newsletter', 'advertisement'])\n",
    "    patterns_to_exclude = ['next article', 'read next', 'correlated']\n",
    "    for element in unwanted_elements:\n",
    "        if any(pattern in str(element).lower() for pattern in patterns_to_exclude):\n",
    "            element.extract()\n",
    "\n",
    "    # Find and exclude footer container and \"All rights reserved\" text\n",
    "    footer_elements = soup.find_all(['footer', 'div'], class_=['footer', 'bottom-footer'])\n",
    "    for element in footer_elements:\n",
    "        element.extract()\n",
    "    all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
    "    for element in all_rights_reserved_elements:\n",
    "        element.extract()\n",
    "\n",
    "    # Find the main text element(s) based on the HTML structure of the page\n",
    "    main_text_elements = soup.find_all('p')\n",
    "    main_text = \"\\n\\n\".join([element.text.strip() for element in main_text_elements if element.text.strip()])\n",
    "\n",
    "    # Set the subtitle to the description if it is empty\n",
    "    if not subtitle:\n",
    "        subtitle = description.strip()\n",
    "\n",
    "    # Concatenate the extracted strings\n",
    "    article_text = f\"{title}\\n\\n{subtitle}\\n\\n{main_text}\"\n",
    "\n",
    "    return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_real_url(google_news_url):\n",
    "    response = requests.get(google_news_url, cookies = {'CONSENT' : 'YES+'})\n",
    "    real_url = response.url\n",
    "    return real_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_dict):\n",
    "    processed_data = {}\n",
    "    \n",
    "    for sheet_name, data_list in data_dict.items():\n",
    "        sheet_data = {}\n",
    "        \n",
    "        for index, url in enumerate(data_list, start=1):\n",
    "            try:\n",
    "                article_url = extract_real_url(url)\n",
    "                article_text = save_article_text(article_url)\n",
    "                key = f\"article{index}\"\n",
    "                sheet_data[key] = article_text\n",
    "            except (requests.exceptions.RequestException, requests.exceptions.HTTPError) as e:\n",
    "                # Handle the exception and continue with the next URL\n",
    "                print(f\"Error processing URL: {url}\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        processed_data[sheet_name] = sheet_data\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flesch_grading_levels_readability_scores(data_dict):\n",
    "    readability_data = {}  # Dictionary to store sentiment scores for each article\n",
    "    \n",
    "    for sheet_name, sheet_data in data_dict.items():\n",
    "        sheet_readability = []\n",
    "        \n",
    "        for article_key, article_text in sheet_data.items():\n",
    "            word_count = len(article_text.split())\n",
    "\n",
    "            if word_count < 100:\n",
    "                # Skip articles with less than 100 words\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                r = Readability(article_text)\n",
    "                f = r.flesch()\n",
    "                score = f.score\n",
    "                \n",
    "                if score >= 0 and score <= 29:\n",
    "                    grade = {'grade': 'F6'}\n",
    "                elif score >= 30 and score <= 49:\n",
    "                    grade = {'grade': 'F5'}\n",
    "                elif score >= 50 and score <= 59:\n",
    "                    grade = {'grade': 'F4'}\n",
    "                elif score >= 60 and score <= 69:\n",
    "                    grade = {'grade': 'F3'}\n",
    "                elif score >= 70 and score <= 79:\n",
    "                    grade = {'grade': 'F2'}\n",
    "                elif score >= 80 and score <= 89:\n",
    "                    grade = {'grade': 'F1'}\n",
    "                else:\n",
    "                    grade = {'grade': 'F0'}\n",
    "                \n",
    "                readability_data[(sheet_name, article_key)] = grade\n",
    "                \n",
    "            except ReadabilityException:\n",
    "                # Skip articles that do not meet the word count requirement\n",
    "                continue\n",
    "\n",
    "        readability_data[sheet_name] = sheet_readability\n",
    "    \n",
    "    return readability_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_readability_scores_to_excel_flesch_reading_ease(processed_data_list, readability_scores_list, output_file_path):\n",
    "    output_workbook = openpyxl.Workbook()\n",
    "    \n",
    "    for i, processed_data in enumerate(processed_data_list):\n",
    "        readability_scores = readability_scores_list[i]\n",
    "        sheet_name = f\"Sheet {i+1}\"\n",
    "        \n",
    "        if i == 0:\n",
    "            output_sheet = output_workbook.active\n",
    "            output_sheet.title = sheet_name\n",
    "        else:\n",
    "            output_sheet = output_workbook.create_sheet(title=sheet_name)\n",
    "        \n",
    "        output_sheet['A1'] = 'Date'\n",
    "        \n",
    "        row = 2\n",
    "        \n",
    "        for sheet_name, sheet_data in processed_data.items():\n",
    "            output_sheet.cell(row=row, column=1, value=sheet_name)\n",
    "            column = 2\n",
    "            \n",
    "            for article_index, (article_key, article_text) in enumerate(sheet_data.items()):\n",
    "                if (sheet_name, article_key) in readability_scores:\n",
    "                    scores = readability_scores[(sheet_name, article_key)]\n",
    "                    output_sheet.cell(row=1, column=column, value=f\"Flesch Reading Ease grade {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column, value=scores['grade'])\n",
    "                else:\n",
    "                    output_sheet.cell(row=1, column=column, value=f\"Flesch Reading Ease grade {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column, value='N/A')\n",
    "                \n",
    "                column += 1\n",
    "            row += 1\n",
    "    \n",
    "    output_workbook.save(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dale_chall_levels_readability_scores(data_dict):\n",
    "    readability_data = {}  # Dictionary to store sentiment scores for each article\n",
    "    \n",
    "    for sheet_name, sheet_data in data_dict.items():\n",
    "        sheet_readability = []\n",
    "        \n",
    "        for article_key, article_text in sheet_data.items():\n",
    "            word_count = len(article_text.split())\n",
    "\n",
    "            if word_count < 100:\n",
    "                # Skip articles with less than 100 words\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                r = Readability(article_text)\n",
    "                dc = r.dale_chall()\n",
    "                score = dc.score\n",
    "                \n",
    "                if score >= 0 and score <= 4.9:\n",
    "                    grade = {'grade': 'D0'}\n",
    "                elif score >= 5.0 and score <= 5.9:\n",
    "                    grade = {'grade': 'D1'}\n",
    "                elif score >= 6.0 and score <= 6.9:\n",
    "                    grade = {'grade': 'D2'}\n",
    "                elif score >= 7.0 and score <= 7.9:\n",
    "                    grade = {'grade': 'D3'}\n",
    "                elif score >= 8.0 and score <= 8.9:\n",
    "                    grade = {'grade': 'D4'}\n",
    "                elif score >= 9.0 and score <= 9.9:\n",
    "                    grade = {'grade': 'D5'}\n",
    "                else:\n",
    "                    grade = {'grade': 'D6'}\n",
    "                \n",
    "                readability_data[(sheet_name, article_key)] = grade\n",
    "                \n",
    "            except ReadabilityException:\n",
    "                # Skip articles that do not meet the word count requirement\n",
    "                continue\n",
    "\n",
    "        readability_data[sheet_name] = sheet_readability\n",
    "    \n",
    "    return readability_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_readability_scores_to_excel_dale_chall(processed_data_list, readability_scores_list, output_file_path):\n",
    "    output_workbook = openpyxl.load_workbook(output_file_path)\n",
    "    \n",
    "    for i, processed_data in enumerate(processed_data_list):\n",
    "        readability_scores = readability_scores_list[i]\n",
    "        sheet_name = f\"Sheet {i+1}\"\n",
    "        \n",
    "        # Check if the sheet already exists in the workbook\n",
    "        if sheet_name in output_workbook.sheetnames:\n",
    "            output_sheet = output_workbook[sheet_name]\n",
    "        else:\n",
    "            raise ValueError(f\"Sheet '{sheet_name}' does not exist in the workbook.\")\n",
    "        \n",
    "        row = 2\n",
    "        \n",
    "        for sheet_name, sheet_data in processed_data.items():\n",
    "            output_sheet.cell(row=row, column=1, value=sheet_name)\n",
    "            column = 12\n",
    "            \n",
    "            for article_index, (article_key, article_text) in enumerate(sheet_data.items()):\n",
    "                if (sheet_name, article_key) in readability_scores:\n",
    "                    scores = readability_scores[(sheet_name, article_key)]\n",
    "                    output_sheet.cell(row=1, column=column, value=f\"Dale Chall grade {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column, value=scores['grade'])\n",
    "                else:\n",
    "                    output_sheet.cell(row=1, column=column, value=f\"Dale Chall grade {article_index+1}\")\n",
    "                    output_sheet.cell(row=row, column=column, value='N/A')\n",
    "                \n",
    "                column += 1\n",
    "            row += 1\n",
    "    \n",
    "    output_workbook.save(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_to_csv(excel_file):\n",
    "    # Load the Excel file\n",
    "    xls = pd.ExcelFile(excel_file)\n",
    "\n",
    "    # Get the sheet names\n",
    "    sheet_names = xls.sheet_names\n",
    "\n",
    "    # Iterate over each sheet and convert to CSV\n",
    "    for sheet_name in sheet_names:\n",
    "        # Read the sheet as a DataFrame\n",
    "        df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "\n",
    "        # Generate the CSV file name\n",
    "        csv_file = f\"{sheet_name}.csv\"\n",
    "\n",
    "        # Save the DataFrame as a CSV file\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "        print(f\"CSV file '{csv_file}' created for sheet '{sheet_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    workbook = load_workbook('/home/pierluigi/Documents/echo_chambers_intership/Code analysis/NLP/Analysis/Text analytics/Text Analytics.xlsx')\n",
    "\n",
    "    data_U1 = {}  # Dictionary to store data from range 1 - U1\n",
    "    data_U2 = {}  # Dictionary to store data from range 2 - U2\n",
    "    data_U3 = {}  # Dictionary to store data from range 3 - U3\n",
    "    data_U4 = {}  # Dictionary to store data from range 4 - U4\n",
    "\n",
    "    # Iterate over each sheet in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "\n",
    "        # Specify the range of cells for data_U1\n",
    "        range1_start_cell = 'C2'  # Replace with the starting cell of range 1\n",
    "        range1_end_cell = 'L2'  # Replace with the ending cell of range 1\n",
    "        \n",
    "        data_list1 = []\n",
    "        \n",
    "        # Iterate over the cells within range 1\n",
    "        for row in worksheet[range1_start_cell:range1_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list1.append(cell.value)\n",
    "        \n",
    "        data_U1[sheet_name] = data_list1\n",
    "\n",
    "        # Specify the range of cells for data_U2\n",
    "        range2_start_cell = 'C3'  # Replace with the starting cell of range 2\n",
    "        range2_end_cell = 'L3'  # Replace with the ending cell of range 2\n",
    "        \n",
    "        data_list2 = []\n",
    "        \n",
    "        # Iterate over the cells within range 2\n",
    "        for row in worksheet[range2_start_cell:range2_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list2.append(cell.value)\n",
    "        \n",
    "        data_U2[sheet_name] = data_list2\n",
    "\n",
    "        # Specify the range of cells for data_U3\n",
    "        range3_start_cell = 'C4'  # Replace with the starting cell of range 3\n",
    "        range3_end_cell = 'L4'  # Replace with the ending cell of range 3\n",
    "        \n",
    "        data_list3 = []\n",
    "        \n",
    "        # Iterate over the cells within range 3\n",
    "        for row in worksheet[range3_start_cell:range3_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list3.append(cell.value)\n",
    "        \n",
    "        data_U3[sheet_name] = data_list3\n",
    "\n",
    "        # Specify the range of cells for data_U4\n",
    "        range4_start_cell = 'C5'  # Replace with the starting cell of range 4\n",
    "        range4_end_cell = 'L5'  # Replace with the ending cell of range 4\n",
    "        \n",
    "        data_list4 = []\n",
    "        \n",
    "        # Iterate over the cells within range 4\n",
    "        for row in worksheet[range4_start_cell:range4_end_cell]:\n",
    "            for cell in row:\n",
    "                data_list4.append(cell.value)\n",
    "        \n",
    "        data_U4[sheet_name] = data_list4\n",
    "\n",
    "    workbook.close()\n",
    "\n",
    "    # Process the data\n",
    "    processed_data1 = process_data(data_U1)\n",
    "    processed_data2 = process_data(data_U2)\n",
    "    processed_data3 = process_data(data_U3)\n",
    "    processed_data4 = process_data(data_U4)\n",
    "\n",
    "    # Flesch Reading Ease readability scores\n",
    "    flesch_reading_ease_readability_scores1 = get_flesch_grading_levels_readability_scores(processed_data1)\n",
    "    flesch_reading_ease_readability_scores2 = get_flesch_grading_levels_readability_scores(processed_data2)\n",
    "    flesch_reading_ease_readability_scores3= get_flesch_grading_levels_readability_scores(processed_data3)\n",
    "    flesch_reading_ease_readability_scores4 = get_flesch_grading_levels_readability_scores(processed_data4)\n",
    "\n",
    "    processed_data_list = [processed_data1, processed_data2, processed_data3, processed_data4]\n",
    "    flesch_reading_ease_scores_list = [flesch_reading_ease_readability_scores1, flesch_reading_ease_readability_scores2, flesch_reading_ease_readability_scores3, flesch_reading_ease_readability_scores4]\n",
    "    \n",
    "    output_file_path = '/home/pierluigi/Desktop/readability.xlsx'\n",
    "\n",
    "    save_readability_scores_to_excel_flesch_reading_ease(processed_data_list, flesch_reading_ease_scores_list, output_file_path)\n",
    "\n",
    "    # Dale Chall readability scores\n",
    "    dale_chall_readability_scores1 = get_dale_chall_levels_readability_scores(processed_data1)\n",
    "    dale_chall_readability_scores2 = get_dale_chall_levels_readability_scores(processed_data2)\n",
    "    dale_chall_readability_scores3 = get_dale_chall_levels_readability_scores(processed_data3)\n",
    "    dale_chall_readability_scores4 = get_dale_chall_levels_readability_scores(processed_data4)\n",
    "\n",
    "    dale_chall_scores_list = [dale_chall_readability_scores1, dale_chall_readability_scores2, dale_chall_readability_scores3, dale_chall_readability_scores4]\n",
    "\n",
    "    save_readability_scores_to_excel_dale_chall(processed_data_list, dale_chall_scores_list, output_file_path)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiSGh0dHBzOi8vd3d3LmxpZmVzdHlsZWFzaWEuY29tL2tsL3N0eWxlL2Zhc2hpb24vbWV0LWdhbGEtMjAyMy1iZXN0LW1lbWVzL9IBTGh0dHBzOi8vd3d3LmxpZmVzdHlsZWFzaWEuY29tL2tsL3N0eWxlL2Zhc2hpb24vbWV0LWdhbGEtMjAyMy1iZXN0LW1lbWVzL2FtcC8?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: 403 Client Error: Forbidden for url: https://www.lifestyleasia.com/kl/style/fashion/met-gala-2023-best-memes/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiUmh0dHBzOi8vc2NyZWVucmFudC5jb20vdmFuZGVycHVtcC1ydWxlcy10b20tc2FuZG92YWwtZGlzZGFpbi1rYXRpZS1kZWVwZXItbWVhbmluZy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiUWh0dHBzOi8vbmV3cy55YWhvby5jb20vc2VuYXRlLXJlcHVibGljYW5zLWluY2x1ZGluZy1tY2Nvbm5lbGwtZGVidC0yMjAwMzg1ODYuaHRtbNIBWWh0dHBzOi8vbmV3cy55YWhvby5jb20vYW1waHRtbC9zZW5hdGUtcmVwdWJsaWNhbnMtaW5jbHVkaW5nLW1jY29ubmVsbC1kZWJ0LTIyMDAzODU4Ni5odG1s?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: 404 Client Error: Not Found for url: https://news.yahoo.com/senate-republicans-including-mcconnell-debt-220038586.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://news.google.com/articles/CBMiamh0dHBzOi8vd3d3LndhdnkuY29tL25ld3MvbWlsaXRhcnkva2lnZ2Fucy1kaXNwdXRlcy1jbGFpbXMtdGhhdC1idWRnZXQtcGxhbi13b3VsZC1zbGFzaC12ZXRlcmFucy1iZW5lZml0cy_SAW5odHRwczovL3d3dy53YXZ5LmNvbS9uZXdzL21pbGl0YXJ5L2tpZ2dhbnMtZGlzcHV0ZXMtY2xhaW1zLXRoYXQtYnVkZ2V0LXBsYW4td291bGQtc2xhc2gtdmV0ZXJhbnMtYmVuZWZpdHMvYW1wLw?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error message: 451 Client Error: Unavailable For Legal Reasons for url: https://www.wavy.com/news/military/kiggans-disputes-claims-that-budget-plan-would-slash-veterans-benefits/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n",
      "/tmp/ipykernel_21844/2363556993.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_rights_reserved_elements = soup.find_all(text=re.compile(r'\\bAll rights reserved\\b', re.IGNORECASE))\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

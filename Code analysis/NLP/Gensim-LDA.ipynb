{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Gensim-LDA in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is technique to extract the hidden topics from large volumes of text. Topic model is a probabilistic model which contain information about the text.\n",
    "\n",
    "Ex: If it is a news paper corpus it may have topics like economics, sports, politics, weather.\n",
    "\n",
    "Topic models are useful for purpose of document clustering, organizing large blocks of textual data, information retrieval from unstructured text and feature selection. Finding good topics depends on the quality of text processing , the choice of the topic modeling algorithm, the number of topics specified in the algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDAâ€™s approach to topic modeling is, it considers each document as a collection of topics and each topic as collection of keywords. Once you provide the algorithm with number of topics all it does is to rearrange the topic distribution within documents and key word distribution within the topics to obtain good composition of topic-keyword distribution.\n",
    "\n",
    "Topics are nothing but collection of prominent keywords or words with highest probability in topic , which helps to identify what the topics are about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierluigi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 'en_core_web_sm' model from spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to preprocess the text data\n",
    "def preprocess(text):\n",
    "    # Create a spaCy doc object\n",
    "    doc = nlp(text)\n",
    "    # Remove stop words and punctuation, and lemmatize the tokens\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return tokens\n",
    "\n",
    "# Function to generate LDA model and topics\n",
    "def generate_lda_topics(text, num_topics=5):\n",
    "    # Preprocess the text data\n",
    "    tokens = preprocess(text)\n",
    "\n",
    "    # Create a dictionary from the preprocessed tokens\n",
    "    dictionary = Dictionary([tokens])\n",
    "\n",
    "    # Create a bag-of-words representation of the preprocessed text data\n",
    "    corpus = [dictionary.doc2bow(tokens)]\n",
    "\n",
    "    # Train the LDA model on the corpus\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "    # Print the topics and their top words\n",
    "    for topic in lda_model.show_topics():\n",
    "        print(topic)\n",
    "\n",
    "    # Compute the coherence score of the LDA model\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=[tokens], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(f'Coherence score: {coherence_score}')\n",
    "\n",
    "    # Visualize the LDA model with pyLDAvis\n",
    "    vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "    pyLDAvis.display(vis)\n",
    "\n",
    "# Get the article URL from user input\n",
    "article_url = input('Enter the URL of the article: ')\n",
    "\n",
    "# Download and extract the article text using the newspaper library\n",
    "article = newspaper.Article(url=article_url)\n",
    "article.download()\n",
    "article.parse()\n",
    "article_text = article.text\n",
    "\n",
    "# Generate the LDA model and topics\n",
    "generate_lda_topics(article_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
